@article{ma_tosem,
  author     = {Ma, Wei and Papadakis, Mike and Tsakmalis, Anestis and Cordy, Maxime and Traon, Yves Le},
  title      = {Test Selection for Deep Learning Systems},
  year       = {2021},
  issue_date = {April 2021},
  publisher  = {Association for Computing Machinery},
  address    = {New York, NY, USA},
  volume     = {30},
  number     = {2},
  issn       = {1049-331X},
  url        = {https://doi.org/10.1145/3417330},
  doi        = {10.1145/3417330},
  journal    = {ACM Transactions on Software Engineering and Methodology (TOSEM)},
  month      = {jan},
  articleno  = {13},
  numpages   = {22},
  keywords   = {Deep learning testing, software testing, software engineering}
}

@inproceedings{qian-etal-2022-controllable,
    title = "Controllable Natural Language Generation with Contrastive Prefixes",
    author = "Qian, Jing  and
      Dong, Li  and
      Shen, Yelong  and
      Wei, Furu  and
      Chen, Weizhu",
    editor = "Muresan, Smaranda  and
      Nakov, Preslav  and
      Villavicencio, Aline",
    booktitle = "Findings of the Association for Computational Linguistics: ACL 2022",
    month = may,
    year = "2022",
    address = "Dublin, Ireland",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2022.findings-acl.229",
    doi = "10.18653/v1/2022.findings-acl.229",
    pages = "2912--2924",
    abstract = "To guide the generation of large pretrained language models (LM), previous work has focused on directly fine-tuning the language model or utilizing an attribute discriminator. In this work, we propose a novel lightweight framework for controllable GPT2 generation, which utilizes a set of small attribute-specific vectors, called prefixes (Li and Liang, 2021), to steer natural language generation. Different from Li and Liang (2021), where each prefix is trained independently, we take the relationship among prefixes into consideration and train multiple prefixes simultaneously. We propose a novel supervised method and also an unsupervised method to train the prefixes for single-aspect control while the combination of these two methods can achieve multi-aspect control. Experimental results on both single-aspect and multi-aspect control show that our methods can guide generation towards the desired attributes while keeping high linguistic quality.",
}

@misc{wang2023adapter,
      title={One Adapter for All Programming Languages? Adapter Tuning for Code Search and Summarization}, 
      author={Deze Wang and Boxing Chen and Shanshan Li and Wei Luo and Shaoliang Peng and Wei Dong and Xiangke Liao},
      year={2023},
      eprint={2303.15822},
      archivePrefix={arXiv},
      primaryClass={cs.SE}
}


@inproceedings{choi-lee-2023-codeprompt,
    title = "{C}ode{P}rompt: Task-Agnostic Prefix Tuning for Program and Language Generation",
    author = "Choi, YunSeok  and
      Lee, Jee-Hyong",
    editor = "Rogers, Anna  and
      Boyd-Graber, Jordan  and
      Okazaki, Naoaki",
    booktitle = "Findings of the Association for Computational Linguistics: ACL 2023",
    month = jul,
    year = "2023",
    address = "Toronto, Canada",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2023.findings-acl.325",
    doi = "10.18653/v1/2023.findings-acl.325",
    pages = "5282--5297",
    abstract = "In order to solve the inefficient parameter update and storage issues of fine-tuning in Natural Language Generation (NLG) tasks, prompt-tuning methods have emerged as lightweight alternatives. Furthermore, efforts to reduce the gap between pre-training and fine-tuning have shown successful results in low-resource settings. As large Pre-trained Language Models (PLMs) for Program and Language Generation (PLG) tasks are constantly being developed, prompt tuning methods are necessary for the tasks. However, due to the gap between pre-training and fine-tuning different from PLMs for natural language, a prompt tuning method that reflects the traits of PLM for program language is needed. In this paper, we propose a Task-Agnostic prompt tuning method for the PLG tasks, CodePrompt, that combines Input-Dependent Prompt Template (to bridge the gap between pre-training and fine-tuning of PLMs for program and language) and Corpus-Specific Prefix Tuning (to update the parameters of PLMs for program and language efficiently).Also, we propose a method to provide richer prefix word information for limited prefix lengths. We prove that our method is effective in three PLG tasks, not only in the full-data setting but also in the low-resource setting and cross-domain setting.",
}

@inproceedings{10.1145/3540250.3549113,
author = {Wang, Chaozheng and Yang, Yuanhang and Gao, Cuiyun and Peng, Yun and Zhang, Hongyu and Lyu, Michael R.},
title = {No More Fine-Tuning? An Experimental Evaluation of Prompt Tuning in Code Intelligence},
year = {2022},
isbn = {9781450394130},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3540250.3549113},
doi = {10.1145/3540250.3549113},
abstract = {Pre-trained models have been shown effective in many code intelligence tasks. These models are pre-trained on large-scale unlabeled corpus and then fine-tuned in downstream tasks. However, as the inputs to pre-training and downstream tasks are in different forms, it is hard to fully explore the knowledge of pre-trained models. Besides, the performance of fine-tuning strongly relies on the amount of downstream data, while in practice, the scenarios with scarce data are common. Recent studies in the natural language processing (NLP) field show that prompt tuning, a new paradigm for tuning, alleviates the above issues and achieves promising results in various NLP tasks. In prompt tuning, the prompts inserted during tuning provide task-specific knowledge, which is especially beneficial for tasks with relatively scarce data. In this paper, we empirically evaluate the usage and effect of prompt tuning in code intelligence tasks. We conduct prompt tuning on popular pre-trained models CodeBERT and CodeT5 and experiment with three code intelligence tasks including defect prediction, code summarization, and code translation. Our experimental results show that prompt tuning consistently outperforms fine-tuning in all three tasks. In addition, prompt tuning shows great potential in low-resource scenarios, e.g., improving the BLEU scores of fine-tuning by more than 26\% on average for code summarization. Our results suggest that instead of fine-tuning, we could adapt prompt tuning for code intelligence tasks to achieve better performance, especially when lacking task-specific data.},
booktitle = {Proceedings of the 30th ACM Joint European Software Engineering Conference and Symposium on the Foundations of Software Engineering},
pages = {382–394},
numpages = {13},
keywords = {prompt tuning, code intelligence, empirical study},
location = {<conf-loc>, <city>Singapore</city>, <country>Singapore</country>, </conf-loc>},
series = {ESEC/FSE 2022}
}

@misc{huang2023bias,
  title         = {Bias Assessment and Mitigation in LLM-based Code Generation},
  author        = {Dong Huang and Qingwen Bu and Jie Zhang and Xiaofei Xie and Junjie Chen and Heming Cui},
  year          = {2023},
  eprint        = {2309.14345},
  archiveprefix = {arXiv},
  primaryclass  = {cs.SE}
}

@misc{ma2023code,
  title         = {Are Code Pre-trained Models Powerful to Learn Code Syntax and Semantics?},
  author        = {Wei Ma and Mengjie Zhao and Xiaofei Xie and Qiang Hu and Shangqing Liu and Jie Zhang and Wenhan Wang and Yang Liu},
  year          = {2023},
  eprint        = {2212.10017},
  archiveprefix = {arXiv},
  primaryclass  = {cs.SE}
}

@inproceedings{8952269,
  author    = {Bui, Nghi D. Q. and Yu, Yijun and Jiang, Lingxiao},
  booktitle = {2019 34th IEEE/ACM International Conference on Automated Software Engineering (ASE)},
  title     = {AutoFocus: Interpreting Attention-Based Neural Networks by Code Perturbation},
  year      = {2019},
  volume    = {},
  number    = {},
  pages     = {38-41},
  doi       = {10.1109/ASE.2019.00014}
}


@inproceedings{10.1145/3524610.3527921,
  author    = {Sharma, Rishab and Chen, Fuxiang and Fard, Fatemeh and Lo, David},
  title     = {An Exploratory Study on Code Attention in BERT},
  year      = {2022},
  isbn      = {9781450392983},
  publisher = {Association for Computing Machinery},
  address   = {New York, NY, USA},
  url       = {https://doi.org/10.1145/3524610.3527921},
  doi       = {10.1145/3524610.3527921},
  abstract  = {Many recent models in software engineering introduced deep neural models based on the Transformer architecture or use transformer-based Pre-trained Language Models (PLM) trained on code. Although these models achieve the state of the arts results in many downstream tasks such as code summarization and bug detection, they are based on Transformer and PLM, which are mainly studied in the Natural Language Processing (NLP) field. The current studies rely on the reasoning and practices from NLP for these models in code, despite the differences between natural languages and programming languages. There is also limited literature on explaining how code is modeled.Here, we investigate the attention behavior of PLM on code and compare it with natural language. We pre-trained BERT, a Transformer based PLM, on code and explored what kind of information it learns, both semantic and syntactic. We run several experiments to analyze the attention values of code constructs on each other and what BERT learns in each layer. Our analyses show that BERT pays more attention to syntactic entities, specifically identifiers and separators, in contrast to the most attended token [CLS] in NLP. This observation motivated us to leverage identifiers to represent the code sequence instead of the [CLS] token when used for code clone detection. Our results show that employing embeddings from identifiers increases the performance of BERT by 605\% and 4\% F1-score in its lower layers and the upper layers, respectively. When identifiers' embeddings are used in CodeBERT, a code-based PLM, the performance is improved by 21--24\% in the F1-score of clone detection. The findings can benefit the research community by using code-specific representations instead of applying the common embeddings used in NLP, and open new directions for developing smaller models with similar performance.},
  booktitle = {Proceedings of the 30th IEEE/ACM International Conference on Program Comprehension},
  pages     = {437–448},
  numpages  = {12},
  keywords  = {pre-trained language models, BERT, CodeBERT, attention},
  location  = {Virtual Event},
  series    = {ICPC '22}
}

@article{JIT2708,
  author   = {Guoqiang Zhuang and Yubin Qu and Long Li and Xianzhen Dou and Mengao Li},
  title    = {An Empirical Study of Gradient-based Explainability Techniques for Self-admitted Technical Debt Detection},
  journal  = {Journal of Internet Technology},
  volume   = {23},
  number   = {3},
  year     = {2022},
  keywords = {Self-Admitted Technical Debt, Deep learning, Explainability, Class imbalance, Focal loss},
  abstract = {Self-Admitted Technical Debt (SATD) is an intentionally introduced software code comment describing potential defects or other technical debt. Currently, deep learning is widely used in fields such as Natural Language Processing. Deep learning can be used for SATD detection, but there is a class imbalance problem and a large number of easily classified SATD instances that may potentially affect the loss value. As a result, we proposed a weighted focal loss function based on particle swarm to address the problem. Meanwhile, there is no empirical research based on local explanations for SATD detection. We have investigated local interpretation models such as Saliency Maps, Integrated Gradients, which are currently widely used in deep learning, and conducted empirical research for shared data sets. The research results show that our proposed weighted focal loss function can achieve the best performance for SATD detection; our model achieves 12.27\%, 5.97\%, and 5.62\% improvement in Precision, Recall, and AUC compared to the baseline model, respectively; Local explanation models, including Saliency Maps and Integrated Gradients can cover nearly half of the manually labeled paradigms; these two interpretation models can also discover potential new paradigms.},
  issn     = {2079-4029},
  pages    = {631--641}
}

@misc{mohammadkhani2023systematic,
  title         = {A Systematic Literature Review of Explainable AI for Software Engineering},
  author        = {Ahmad Haji Mohammadkhani and Nitin Sai Bommi and Mariem Daboussi and Onkar Sabnis and Chakkrit Tantithamthavorn and Hadi Hemmati},
  year          = {2023},
  eprint        = {2302.06065},
  archiveprefix = {arXiv},
  primaryclass  = {cs.SE}
}

@inproceedings{nye2019learning,
  title        = {Learning to infer program sketches},
  author       = {Nye, Maxwell and Hewitt, Luke and Tenenbaum, Joshua and Solar-Lezama, Armando},
  booktitle    = {International Conference on Machine Learning},
  pages        = {4861--4870},
  year         = {2019},
  organization = {PMLR}
}

@inproceedings{10123534,
  author    = {Zhu, Rui and Zhang, Cunming},
  booktitle = {2023 IEEE International Conference on Software Analysis, Evolution and Reengineering (SANER)},
  title     = {How Robust Is a Large Pre-trained Language Model for Code Generationƒ A Case on Attacking GPT2},
  year      = {2023},
  volume    = {},
  number    = {},
  pages     = {708-712},
  doi       = {10.1109/SANER56733.2023.00076}
}

@misc{polosukhin2018neural,
  title         = {Neural Program Search: Solving Programming Tasks from Description and Examples},
  author        = {Illia Polosukhin and Alexander Skidanov},
  year          = {2018},
  eprint        = {1802.04335},
  archiveprefix = {arXiv},
  primaryclass  = {cs.AI}
}

@inproceedings{anand2021adversarial,
  title     = {Adversarial Robustness of Program Synthesis Models},
  author    = {Mrinal Anand and Pratik Kayal and Mayank Singh},
  booktitle = {Advances in Programming Languages and Neurosymbolic Systems Workshop},
  year      = {2021},
  url       = {https://openreview.net/forum?id=17C-dfA5X69}
}

@misc{anand2021adversarial2,
  title         = {On Adversarial Robustness of Synthetic Code Generation},
  author        = {Mrinal Anand and Pratik Kayal and Mayank Singh},
  year          = {2021},
  eprint        = {2106.11629},
  archiveprefix = {arXiv},
  primaryclass  = {cs.LG}
}

@inproceedings{7958570,
  author    = {N. Carlini and D. Wagner},
  booktitle = {2017 IEEE Symposium on Security and Privacy (SP)},
  title     = {Towards Evaluating the Robustness of Neural Networks},
  year      = {2017},
  volume    = {},
  issn      = {2375-1207},
  pages     = {39-57},
  keywords  = {neural networks;robustness;measurement;speech recognition;security;malware;resists},
  doi       = {10.1109/SP.2017.49},
  url       = {https://doi.ieeecomputersociety.org/10.1109/SP.2017.49},
  publisher = {IEEE Computer Society},
  address   = {Los Alamitos, CA, USA},
  month     = {may}
}

@inproceedings{9763729,
  author    = {Chen, Penglong and Li, Zhen and Wen, Yu and Liu, Lili},
  booktitle = {2022 26th International Conference on Engineering of Complex Computer Systems (ICECCS)},
  title     = {Generating Adversarial Source Programs Using Important Tokens-based Structural Transformations},
  year      = {2022},
  volume    = {},
  number    = {},
  pages     = {173-182},
  doi       = {10.1109/ICECCS54210.2022.00029}
}

@article{liu2019deep,
  title   = {Deep gamblers: Learning to abstain with portfolio theory},
  author  = {Liu, Ziyin and Wang, Zhikang and Liang, Paul Pu and Salakhutdinov, Russ R and Morency, Louis-Philippe and Ueda, Masahito},
  journal = {Advances in Neural Information Processing Systems},
  volume  = {32},
  year    = {2019}
}

@inproceedings{bielik2020adversarial,
  title        = {Adversarial robustness for code},
  author       = {Bielik, Pavol and Vechev, Martin},
  booktitle    = {International Conference on Machine Learning},
  pages        = {896--907},
  year         = {2020},
  organization = {PMLR}
}


@misc{coda,
  title         = {Code Difference Guided Adversarial Example Generation for Deep Code Models},
  author        = {Zhao Tian and Junjie Chen and Zhi Jin},
  year          = {2023},
  eprint        = {2301.02412},
  archiveprefix = {arXiv},
  primaryclass  = {cs.CR}
}

@article{SySeVR,
  author    = {Z. Li and D. Zou and S. Xu and H. Jin and Y. Zhu and Z. Chen},
  journal   = {IEEE Transactions on Dependable and Secure Computing},
  title     = {SySeVR: A Framework for Using Deep Learning to Detect Software Vulnerabilities},
  year      = {2022},
  volume    = {19},
  number    = {04},
  issn      = {1941-0018},
  pages     = {2244-2258},
  abstract  = {The detection of software vulnerabilities (or vulnerabilities for short) is an important problem that has yet to be tackled, as manifested by the many vulnerabilities reported on a daily basis. This calls for machine learning methods for vulnerability detection. Deep learning is attractive for this purpose because it alleviates the requirement to manually define features. Despite the tremendous success of deep learning in other application domains, its applicability to vulnerability detection is not systematically understood. In order to fill this void, we propose the first systematic framework for using deep learning to detect vulnerabilities in C/C++ programs with source code. The framework, dubbed Syntax-based, Semantics-based, and Vector Representations (SySeVR), focuses on obtaining program representations that can accommodate syntax and semantic information pertinent to vulnerabilities. Our experiments with four software products demonstrate the usefulness of the framework: we detect 15 vulnerabilities that are not reported in the National Vulnerability Database. Among these 15 vulnerabilities, seven are unknown and have been reported to the vendors, and the other eight have been “silently” patched by the vendors when releasing newer versions of the pertinent software products.},
  keywords  = {deep learning;syntactics;software;semantics;proposals;image processing;big data},
  doi       = {10.1109/TDSC.2021.3051525},
  publisher = {IEEE Computer Society},
  address   = {Los Alamitos, CA, USA},
  month     = {jul}
}


@inproceedings{9724884,
  author    = {Tian, Junfeng and Wang, Chenxin and Li, Zhen and Wen, Yu},
  booktitle = {2021 IEEE 21st International Conference on Software Quality, Reliability and Security (QRS)},
  title     = {Generating Adversarial Examples of Source Code Classification Models via Q-Learning-Based Markov Decision Process},
  year      = {2021},
  volume    = {},
  number    = {},
  pages     = {807-818},
  doi       = {10.1109/QRS54544.2021.00090}
}


@article{electronics12040936,
  author         = {Yu, Xueqi and Li, Zhen and Huang, Xiang and Zhao, Shasha},
  title          = {AdVulCode: Generating Adversarial Vulnerable Code against Deep Learning-Based Vulnerability Detectors},
  journal        = {Electronics},
  volume         = {12},
  year           = {2023},
  number         = {4},
  article-number = {936},
  url            = {https://www.mdpi.com/2079-9292/12/4/936},
  issn           = {2079-9292},
  doi            = {10.3390/electronics12040936}
}





@article{ppl,
  title   = {An empirical study of smoothing techniques for language modeling},
  journal = {Computer Speech and Language},
  volume  = {13},
  number  = {4},
  pages   = {359-394},
  year    = {1999},
  issn    = {0885-2308},
  doi     = {https://doi.org/10.1006/csla.1999.0128},
  url     = {https://www.sciencedirect.com/science/article/pii/S0885230899901286},
  author  = {Stanley F. Chen and Joshua Goodman}
}

@article{terrell2017gender,
  title     = {Gender differences and bias in open source: Pull request acceptance of women versus men},
  author    = {Terrell, Josh and Kofink, Andrew and Middleton, Justin and Rainear, Clarissa and Murphy-Hill, Emerson and Parnin, Chris and Stallings, Jon},
  journal   = {PeerJ Computer Science},
  volume    = {3},
  pages     = {e111},
  year      = {2017},
  publisher = {PeerJ Inc.}
}

@misc{liu2023uncovering,
  title         = {Uncovering and Quantifying Social Biases in Code Generation},
  author        = {Yan Liu and Xiaokang Chen and Yan Gao and Zhe Su and Fengji Zhang and Daoguang Zan and Jian-Guang Lou and Pin-Yu Chen and Tsung-Yi Ho},
  year          = {2023},
  eprint        = {2305.15377},
  archiveprefix = {arXiv},
  primaryclass  = {cs.CL}
}

@inproceedings{papernot2016limitations,
  title        = {The limitations of deep learning in adversarial settings},
  author       = {Papernot, Nicolas and McDaniel, Patrick and Jha, Somesh and Fredrikson, Matt and Celik, Z Berkay and Swami, Ananthram},
  booktitle    = {2016 IEEE European symposium on security and privacy (EuroS\&P)},
  pages        = {372--387},
  year         = {2016},
  organization = {IEEE}
}

@article{papernot2016transferability,
  title   = {Transferability in machine learning: from phenomena to black-box attacks using adversarial samples},
  author  = {Papernot, Nicolas and McDaniel, Patrick and Goodfellow, Ian},
  journal = {arXiv preprint arXiv:1605.07277},
  year    = {2016}
}

@article{9454564,
  author  = {Liu, Qianjun and Ji, Shouling and Liu, Changchang and Wu, Chunming},
  journal = {IEEE Transactions on Information Forensics and Security},
  title   = {A Practical Black-Box Attack on Source Code Authorship Identification Classifiers},
  year    = {2021},
  volume  = {16},
  number  = {},
  pages   = {3620-3633},
  doi     = {10.1109/TIFS.2021.3080507}
}

@inproceedings{ASTNN,
  author    = {Zhang, Jian and Wang, Xu and Zhang, Hongyu and Sun, Hailong and Wang, Kaixuan and Liu, Xudong},
  booktitle = {2019 IEEE/ACM 41st International Conference on Software Engineering (ICSE)},
  title     = {A Novel Neural Source Code Representation Based on Abstract Syntax Tree},
  year      = {2019},
  volume    = {},
  number    = {},
  pages     = {783-794},
  doi       = {10.1109/ICSE.2019.00086}
}


@article{du2023extensive,
  title  = {An Extensive Study on Adversarial Attack against Pre-trained Models of Code},
  author = {Du, Xiaohu and Wen, Ming and Wei, Zichao and Wang, Shangwen and Jin, Hai},
  year   = {2023}
}

@inproceedings{TBCCD,
  author    = {Yu, Hao and Lam, Wing and Chen, Long and Li, Ge and Xie, Tao and Wang, Qianxiang},
  booktitle = {2019 IEEE/ACM 27th International Conference on Program Comprehension (ICPC)},
  title     = {Neural Detection of Semantic Code Clones Via Tree-Based Convolution},
  year      = {2019},
  volume    = {},
  number    = {},
  pages     = {70-80},
  doi       = {10.1109/ICPC.2019.00021}
}



@misc{li2022closer,
  title         = {A Closer Look into Transformer-Based Code Intelligence Through Code Transformation: Challenges and Opportunities},
  author        = {Yaoxian Li and Shiyi Qi and Cuiyun Gao and Yun Peng and David Lo and Zenglin Xu and Michael R. Lyu},
  year          = {2022},
  eprint        = {2207.04285},
  archiveprefix = {arXiv},
  primaryclass  = {cs.SE}
}

@inproceedings{OJClone,
  author    = {Mou, Lili and Li, Ge and Zhang, Lu and Wang, Tao and Jin, Zhi},
  title     = {Convolutional Neural Networks over Tree Structures for Programming Language Processing},
  year      = {2016},
  publisher = {AAAI Press},
  abstract  = {Programming language processing (similar to natural language processing) is a hot research topic in the field of software engineering; it has also aroused growing interest in the artificial intelligence community. However, different from a natural language sentence, a program contains rich, explicit, and complicated structural information. Hence, traditional NLP models may be inappropriate for programs. In this paper, we propose a novel tree-based convolutional neural network (TBCNN) for programming language processing, in which a convolution kernel is designed over programs' abstract syntax trees to capture structural information. TBCNN is a generic architecture for programming language processing; our experiments show its effectiveness in two different program analysis tasks: classifying programs according to functionality, and detecting code snippets of certain patterns. TBCNN outperforms baseline methods, including several neural models for NLP.},
  booktitle = {Proceedings of the Thirtieth AAAI Conference on Artificial Intelligence},
  pages     = {1287–1293},
  numpages  = {7},
  location  = {Phoenix, Arizona},
  series    = {AAAI'16}
}

@article{10028657,
  author  = {Zhang, Weiwei and Guo, Shengjian and Zhang, Hongyu and Sui, Yulei and Xue, Yinxing and Xu, Yun},
  journal = {IEEE Transactions on Software Engineering},
  title   = {Challenging Machine Learning-Based Clone Detectors via Semantic-Preserving Code Transformations},
  year    = {2023},
  volume  = {49},
  number  = {5},
  pages   = {3052-3070},
  doi     = {10.1109/TSE.2023.3240118}
}


@inproceedings{10.1145/3579990.3580012,
  author    = {Dam\'{a}sio, Tha\'{\i}s and Canesche, Michael and Pacheco, Vin\'{\i}cius and Botacin, Marcus and Faustino da Silva, Anderson and Quint\~{a}o Pereira, Fernando M.},
  title     = {A Game-Based Framework to Compare Program Classifiers and Evaders},
  year      = {2023},
  isbn      = {9798400701016},
  publisher = {Association for Computing Machinery},
  address   = {New York, NY, USA},
  url       = {https://doi.org/10.1145/3579990.3580012},
  doi       = {10.1145/3579990.3580012},
  abstract  = {Algorithm classification consists in determining which algorithm a program implements, given a finite set of candidates. Classifiers are used in applications such malware identification and plagiarism detection. There exist many ways to implement classifiers. There are also many ways to implement evaders to deceive the classifiers. This paper analyzes the state-of-the-art classification and evasion techniques. To organize this analysis, this paper brings forward a system of four games that matches classifiers and evaders. Games vary according to the amount of information that is given to each player. This setup lets us analyze a space formed by the combination of nine program encodings; seven obfuscation passes; and six stochastic classification models. Observations from this study include: (i) we could not measure substantial advantages of recent vector-based program representations over simple histograms of opcodes; (ii) deep neural networks recently proposed for program classification are no better than random forests; (iii) program optimizations are almost as effective as classic obfuscation techniques to evade classifiers; (iv) off-the-shelf code optimizations can completely remove the evasion power of na\"{\i}ve obfuscators; (v) control-flow flattening and bogus-control flow tend to resist the normalizing power of code optimizations.},
  booktitle = {Proceedings of the 21st ACM/IEEE International Symposium on Code Generation and Optimization},
  pages     = {108–121},
  numpages  = {14},
  keywords  = {algorithm classification, obfuscation},
  location  = {Montr\'{e}al, QC, Canada},
  series    = {CGO 2023}
}

@article{8465996,
  author  = {Mathew, George and Agrawal, Amritanshu and Menzies, Tim},
  journal = {IEEE Transactions on Software Engineering},
  title   = {Finding Trends in Software Research},
  year    = {2023},
  volume  = {49},
  number  = {4},
  pages   = {1397-1410},
  doi     = {10.1109/TSE.2018.2870388}
}



@article{10.1145/3363562,
  author     = {Chen, Junjie and Patra, Jibesh and Pradel, Michael and Xiong, Yingfei and Zhang, Hongyu and Hao, Dan and Zhang, Lu},
  title      = {A Survey of Compiler Testing},
  year       = {2020},
  issue_date = {January 2021},
  publisher  = {Association for Computing Machinery},
  address    = {New York, NY, USA},
  volume     = {53},
  number     = {1},
  issn       = {0360-0300},
  url        = {https://doi.org/10.1145/3363562},
  doi        = {10.1145/3363562},
  abstract   = {Virtually any software running on a computer has been processed by a compiler or a compiler-like tool. Because compilers are such a crucial piece of infrastructure for building software, their correctness is of paramount importance. To validate and increase the correctness of compilers, significant research efforts have been devoted to testing compilers. This survey article provides a comprehensive summary of the current state-of-the-art of research on compiler testing. The survey covers different aspects of the compiler testing problem, including how to construct test programs, what test oracles to use for determining whether a compiler behaves correctly, how to execute compiler tests efficiently, and how to help compiler developers take action on bugs discovered by compiler testing. Moreover, we survey work that empirically studies the strengths and weaknesses of current compiler testing research and practice. Based on the discussion of existing work, we outline several open challenges that remain to be addressed in future work.},
  journal    = {ACM Comput. Surv.},
  month      = {feb},
  articleno  = {4},
  numpages   = {36},
  keywords   = {test oracle, Compiler testing, test program generation, test optimization, compiler debugging}
}

@article{chen2022fairness,
  title   = {Fairness testing: A comprehensive survey and analysis of trends},
  author  = {Chen, Zhenpeng and Zhang, Jie M and Hort, Max and Sarro, Federica and Harman, Mark},
  journal = {arXiv preprint arXiv:2207.10223},
  year    = {2022}
}

@inproceedings{na-etal-2023-dip,
  title     = {{DIP}: Dead code Insertion based Black-box Attack for Programming Language Model},
  author    = {Na, CheolWon  and
               Choi, YunSeok  and
               Lee, Jee-Hyong},
  booktitle = {Proceedings of the 61st Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)},
  month     = jul,
  year      = {2023},
  address   = {Toronto, Canada},
  publisher = {Association for Computational Linguistics},
  url       = {https://aclanthology.org/2023.acl-long.430},
  doi       = {10.18653/v1/2023.acl-long.430},
  pages     = {7777--7791},
  abstract  = {Automatic processing of source code, such as code clone detection and software vulnerability detection, is very helpful to software engineers. Large pre-trained Programming Language (PL) models (such as CodeBERT, GraphCodeBERT, CodeT5, etc.), show very powerful performance on these tasks. However, these PL models are vulnerable to adversarial examples that are generated with slight perturbation. Unlike natural language, an adversarial example of code must be semantic-preserving and compilable. Due to the requirements, it is hard to directly apply the existing attack methods for natural language models. In this paper, we propose DIP (Dead code Insertion based Black-box Attack for Programming Language Model), a high-performance and effective black-box attack method to generate adversarial examples using dead code insertion. We evaluate our proposed method on 9 victim downstream-task large code models. Our method outperforms the state-of-the-art black-box attack in both attack efficiency and attack quality, while generated adversarial examples are compiled preserving semantic functionality.}
}

@inproceedings{9700297,
  author    = {P. Liguori and E. Al-Hossami and V. Orbinato and R. Natella and S. Shaikh and D. Cotroneo and B. Cukic},
  booktitle = {2021 IEEE 32nd International Symposium on Software Reliability Engineering (ISSRE)},
  title     = {EVIL: Exploiting Software via Natural Language},
  year      = {2021},
  volume    = {},
  issn      = {},
  pages     = {321-332},
  abstract  = {Writing exploits for security assessment is a challenging task. The writer needs to master programming and obfuscation techniques to develop a successful exploit. To make the task easier, we propose an approach (EVIL) to automatically generate exploits in assembly/Python language from descriptions in natural language. The approach leverages Neural Machine Translation (NMT) techniques and a dataset that we developed for this work. We present an extensive experimental study to evaluate the feasibility of EVIL, using both automatic and manual analysis, and both at generating individual statements and entire exploits. The generated code achieved high accuracy in terms of syntactic and semantic correctness.},
  keywords  = {training;semantics;neural networks;manuals;syntactics;writing;software},
  doi       = {10.1109/ISSRE52982.2021.00042},
  url       = {https://doi.ieeecomputersociety.org/10.1109/ISSRE52982.2021.00042},
  publisher = {IEEE Computer Society},
  address   = {Los Alamitos, CA, USA},
  month     = {oct}
}


@inproceedings{10.1145/3528588.3528653,
  author    = {Liguori, Pietro and Improta, Cristina and De Vivo, Simona and Natella, Roberto and Cukic, Bojan and Cotroneo, Domenico},
  title     = {Can NMT Understand Me? Towards Perturbation-Based Evaluation of NMT Models for Code Generation},
  year      = {2023},
  isbn      = {9781450393430},
  publisher = {Association for Computing Machinery},
  address   = {New York, NY, USA},
  url       = {https://doi.org/10.1145/3528588.3528653},
  doi       = {10.1145/3528588.3528653},
  abstract  = {Neural Machine Translation (NMT) has reached a level of maturity to be recognized as the premier method for the translation between different languages and aroused interest in different research areas, including software engineering. A key step to validate the robustness of the NMT models consists in evaluating the performance of the models on adversarial inputs, i.e., inputs obtained from the original ones by adding small amounts of perturbation. However, when dealing with the specific task of the code generation (i.e., the generation of code starting from a description in natural language), it has not yet been defined an approach to validate the robustness of the NMT models. In this work, we address the problem by identifying a set of perturbations and metrics tailored for the robustness assessment of such models. We present a preliminary experimental evaluation, showing what type of perturbations affect the model the most and deriving useful insights for future directions.},
  booktitle = {Proceedings of the 1st International Workshop on Natural Language-Based Software Engineering},
  pages     = {59–66},
  numpages  = {8},
  keywords  = {robustness testing, adversarial inputs, neural machine translation, code generation},
  location  = {Pittsburgh, Pennsylvania},
  series    = {NLBSE '22}
}
 


@inproceedings{10.1145/3236024.3264838,
  author    = {Brun, Yuriy and Meliou, Alexandra},
  title     = {Software Fairness},
  year      = {2018},
  isbn      = {9781450355735},
  publisher = {Association for Computing Machinery},
  address   = {New York, NY, USA},
  url       = {https://doi.org/10.1145/3236024.3264838},
  doi       = {10.1145/3236024.3264838},
  abstract  = {A goal of software engineering research is advancing software quality and the success of the software engineering process. However, while recent studies have demonstrated a new kind of defect in software related to its ability to operate in fair and unbiased manner, software engineering has not yet wholeheartedly tackled these new kinds of defects, thus leaving software vulnerable. This paper outlines a vision for how software engineering research can help reduce fairness defects and represents a call to action by the software engineering research community to reify that vision. Modern software is riddled with examples of biased behavior, from automated translation injecting gender stereotypes, to vision systems failing to see faces of certain races, to the US criminal justice sytem relying on biased computational assessments of crime recidivism. While systems may learn bias from biased data, bias can also emerge from ambiguous or incomplete requirement specification, poor design, implementation bugs, and unintended component interactions. We argue that software fairness is analogous to software quality, and that numerous software engineering challenges in the areas of requirements, specification, design, testing, and verification need to be tackled to solve this problem.},
  booktitle = {Proceedings of the 2018 26th ACM Joint Meeting on European Software Engineering Conference and Symposium on the Foundations of Software Engineering},
  pages     = {754–759},
  numpages  = {6},
  keywords  = {software bias, Software fairness, software process},
  location  = {Lake Buena Vista, FL, USA},
  series    = {ESEC/FSE 2018}
}

@inproceedings{10.1145/3194770.3194778,
  author    = {Aydemir, Fatma Ba\c{s}ak and Dalpiaz, Fabiano},
  title     = {A Roadmap for Ethics-Aware Software Engineering},
  year      = {2018},
  isbn      = {9781450357463},
  publisher = {Association for Computing Machinery},
  address   = {New York, NY, USA},
  url       = {https://doi.org/10.1145/3194770.3194778},
  doi       = {10.1145/3194770.3194778},
  abstract  = {Today's software is highly intertwined with our lives, and it possesses an increasing ability to act and influence us. Besides the renown example of self-driving cars and their potential harmfulness, more mundane software such as social networks can introduce bias, break privacy preferences, lead to digital addiction, etc. Additionally, the software engineering (SE) process itself is highly affected by ethical issues, such as diversity and business ethics. This paper introduces ethics-aware SE, a version of SE in which the ethical values of the stakeholders (including developers and users) are captured, analyzed, and reflected in software specifications and in the SE processes. We propose an analytical framework that assists stakeholders in analyzing ethical issues in terms of subject (software artifact or SE process), relevant value (diversity, privacy, autonomy, ...), and threatened object (user, developer, ...). We also define a roadmap that illustrates the necessary steps for the SE research and practice community in order to fully realize ethics-aware SE.},
  booktitle = {Proceedings of the International Workshop on Software Fairness},
  pages     = {15–21},
  numpages  = {7},
  keywords  = {ethics, ethics compliance, ethical design, ethical software engineering, requirements engineering},
  location  = {Gothenburg, Sweden},
  series    = {FairWare '18}
}

@misc{zhang2023code,
      title={Code Membership Inference for Detecting Unauthorized Data Use in Code Pre-trained Language Models}, 
      author={Sheng Zhang and Hui Li},
      year={2023},
      eprint={2312.07200},
      archivePrefix={arXiv},
      primaryClass={cs.SE}
}

@misc{yang2023gotcha,
  title         = {Gotcha! This Model Uses My Code! Evaluating Membership Leakage Risks in Code Models},
  author        = {Zhou Yang and Zhipeng Zhao and Chenyu Wang and Jieke Shi and Dongsum Kim and Donggyun Han and David Lo},
  year          = {2023},
  eprint        = {2310.01166},
  archiveprefix = {arXiv},
  primaryclass  = {cs.SE}
}

@misc{aye2020sequence,
  title         = {Sequence Model Design for Code Completion in the Modern IDE},
  author        = {Gareth Ari Aye and Gail E. Kaiser},
  year          = {2020},
  eprint        = {2004.05249},
  archiveprefix = {arXiv},
  primaryclass  = {cs.SE}
}

@inproceedings{svyatkovskiy2021fast,
  title        = {Fast and memory-efficient neural code completion},
  author       = {Svyatkovskiy, Alexey and Lee, Sebastian and Hadjitofi, Anna and Riechert, Maik and Franco, Juliana Vicente and Allamanis, Miltiadis},
  booktitle    = {2021 IEEE/ACM 18th International Conference on Mining Software Repositories (MSR)},
  pages        = {329--340},
  year         = {2021},
  organization = {IEEE}
}

@inproceedings{CodeReviewer,
  author    = {Li, Zhiyu and Lu, Shuai and Guo, Daya and Duan, Nan and Jannu, Shailesh and Jenks, Grant and Majumder, Deep and Green, Jared and Svyatkovskiy, Alexey and Fu, Shengyu and Sundaresan, Neel},
  title     = {Automating Code Review Activities by Large-Scale Pre-Training},
  year      = {2022},
  isbn      = {9781450394130},
  publisher = {Association for Computing Machinery},
  address   = {New York, NY, USA},
  url       = {https://doi.org/10.1145/3540250.3549081},
  doi       = {10.1145/3540250.3549081},
  abstract  = {Code review is an essential part to software development lifecycle since it aims at guaranteeing the quality of codes. Modern code review activities necessitate developers viewing, understanding and even running the programs to assess logic, functionality, latency, style and other factors. It turns out that developers have to spend far too much time reviewing the code of their peers. Accordingly, it is in significant demand to automate the code review process. In this research, we focus on utilizing pre-training techniques for the tasks in the code review scenario. We collect a large-scale dataset of real-world code changes and code reviews from open-source projects in nine of the most popular programming languages. To better understand code diffs and reviews, we propose CodeReviewer, a pre-trained model that utilizes four pre-training tasks tailored specifically for the code review scenario. To evaluate our model, we focus on three key tasks related to code review activities, including code change quality estimation, review comment generation and code refinement. Furthermore, we establish a high-quality benchmark dataset based on our collected data for these three tasks and conduct comprehensive experiments on it. The experimental results demonstrate that our model outperforms the previous state-of-the-art pre-training approaches in all tasks. Further analysis show that our proposed pre-training tasks and the multilingual pre-training dataset benefit the model on the understanding of code changes and reviews.},
  booktitle = {Proceedings of the 30th ACM Joint European Software Engineering Conference and Symposium on the Foundations of Software Engineering},
  pages     = {1035–1047},
  numpages  = {13},
  keywords  = {pre-training, deep learning, Code review, datasets},
  location  = {Singapore, Singapore},
  series    = {ESEC/FSE 2022}
}

@inproceedings{wei2015submodularity,
  title        = {Submodularity in data subset selection and active learning},
  author       = {Wei, Kai and Iyer, Rishabh and Bilmes, Jeff},
  booktitle    = {International Conference on Machine Learning},
  pages        = {1954--1963},
  year         = {2015},
  organization = {PMLR}
}

@misc{steenhoek2023empirical,
  title         = {An Empirical Study of Deep Learning Models for Vulnerability Detection},
  author        = {Benjamin Steenhoek and Md Mahbubur Rahman and Richard Jiles and Wei Le},
  year          = {2023},
  eprint        = {2212.08109},
  archiveprefix = {arXiv},
  primaryclass  = {cs.SE}
}

@article{T5,
  author  = {Colin Raffel and Noam Shazeer and Adam Roberts and Katherine Lee and Sharan Narang and Michael Matena and Yanqi Zhou and Wei Li and Peter J. Liu},
  title   = {Exploring the Limits of Transfer Learning with a Unified Text-to-Text Transformer},
  journal = {Journal of Machine Learning Research},
  year    = {2020},
  volume  = {21},
  number  = {140},
  pages   = {1--67},
  url     = {http://jmlr.org/papers/v21/20-074.html}
}

@inproceedings{9825895,
  author    = {Henkel, Jordan and Ramakrishnan, Goutham and Wang, Zi and Albarghouthi, Aws and Jha, Somesh and Reps, Thomas},
  booktitle = {2022 IEEE International Conference on Software Analysis, Evolution and Reengineering (SANER)},
  title     = {Semantic Robustness of Models of Source Code},
  year      = {2022},
  volume    = {},
  number    = {},
  pages     = {526-537},
  doi       = {10.1109/SANER53432.2022.00070}
}

@article{hinton2015distilling,
  title={Distilling the knowledge in a neural network},
  author={Hinton, Geoffrey and Vinyals, Oriol and Dean, Jeff},
  journal={arXiv preprint arXiv:1503.02531},
  year={2015}
}

@misc{qi2023badcs,
  title         = {BadCS: A Backdoor Attack Framework for Code search},
  author        = {Shiyi Qi and Yuanhang Yang and Shuzhzeng Gao and Cuiyun Gao and Zenglin Xu},
  year          = {2023},
  eprint        = {2305.05503},
  archiveprefix = {arXiv},
  primaryclass  = {cs.SE}
}


@misc{he2023large,
  title         = {Large Language Models for Code: Security Hardening and Adversarial Testing},
  author        = {Jingxuan He and Martin Vechev},
  year          = {2023},
  eprint        = {2302.05319},
  archiveprefix = {arXiv},
  primaryclass  = {cs.CR}
}

@inproceedings{Sun2023backdoor,
  title     = {Backdooring Neural Code Search},
  author    = {Sun, Weisong  and
               Chen, Yuchen  and
               Tao, Guanhong  and
               Fang, Chunrong  and
               Zhang, Xiangyu  and
               Zhang, Quanjun  and
               Luo, Bin},
  booktitle = {Proceedings of the 61st Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)},
  month     = jul,
  year      = {2023},
  address   = {Toronto, Canada},
  publisher = {Association for Computational Linguistics},
  url       = {https://aclanthology.org/2023.acl-long.540},
  doi       = {10.18653/v1/2023.acl-long.540},
  pages     = {9692--9708},
  abstract  = {Reusing off-the-shelf code snippets from online repositories is a common practice, which significantly enhances the productivity of software developers. To find desired code snippets, developers resort to code search engines through natural language queries. Neural code search models are hence behind many such engines. These models are based on deep learning and gain substantial attention due to their impressive performance. However, the security aspect of these models is rarely studied. Particularly, an adversary can inject a backdoor in neural code search models, which return buggy or even vulnerable code with security/privacy issues. This may impact the downstream software (e.g., stock trading systems and autonomous driving) and cause financial loss and/or life-threatening incidents. In this paper, we demonstrate such attacks are feasible and can be quite stealthy. By simply modifying one variable/function name, the attacker can make buggy/vulnerable code rank in the top 11{\%}. Our attack BADCODE features a special trigger generation and injection procedure, making the attack more effective and stealthy. The evaluation is conducted on two neural code search models and the results show our attack outperforms baselines by 60{\%}. Our user study demonstrates that our attack is more stealthy than the baseline by two times based on the F1 score.}
}

@inproceedings{coffee,
  author    = {Nguyen, Phuong T. and Di Sipio, Claudio and Di Rocco, Juri and Di Penta, Massimiliano and Di Ruscio, Davide},
  booktitle = {2021 36th IEEE/ACM International Conference on Automated Software Engineering (ASE)},
  title     = {Adversarial Attacks to API Recommender Systems: Time to Wake Up and Smell the Coffee?},
  year      = {2021},
  volume    = {},
  number    = {},
  pages     = {253-265},
  doi       = {10.1109/ASE51524.2021.9678946}
}

@inproceedings{10006873,
  author    = {Siddiq, Mohammed Latif and Majumder, Shafayat H. and Mim, Maisha R. and Jajodia, Sourov and Santos, Joanna C. S.},
  booktitle = {2022 IEEE 22nd International Working Conference on Source Code Analysis and Manipulation (SCAM)},
  title     = {An Empirical Study of Code Smells in Transformer-based Code Generation Techniques},
  year      = {2022},
  volume    = {},
  number    = {},
  pages     = {71-82},
  doi       = {10.1109/SCAM55253.2022.00014}
}

@article{sandoval2022security,
  title={Security implications of large language model code assistants: A user study},
  author={Sandoval, Gustavo and Pearce, Hammond and Nys, Teo and Karri, Ramesh and Dolan-Gavitt, Brendan and Garg, Siddharth},
  journal={arXiv preprint arXiv:2208.09727},
  year={2022}
}

@inproceedings{perry2023users,
  title={Do users write more insecure code with AI assistants?},
  author={Perry, Neil and Srivastava, Megha and Kumar, Deepak and Boneh, Dan},
  booktitle={Proceedings of the 2023 ACM SIGSAC Conference on Computer and Communications Security},
  pages={2785--2799},
  year={2023}
}


@inproceedings{DBLP:conf/sp/PearceA0DK22,
  author    = {Hammond Pearce and
               Baleegh Ahmad and
               Benjamin Tan and
               Brendan Dolan{-}Gavitt and
               Ramesh Karri},
  title     = {Asleep at the Keyboard? Assessing the Security of GitHub Copilot's
               Code Contributions},
  booktitle = {43rd {IEEE} Symposium on Security and Privacy, {SP} 2022, San Francisco,
               CA, USA, May 22-26, 2022},
  pages     = {754--768},
  publisher = {{IEEE}},
  year      = {2022},
  url       = {https://doi.org/10.1109/SP46214.2022.9833571},
  doi       = {10.1109/SP46214.2022.9833571},
  timestamp = {Wed, 07 Dec 2022 23:10:41 +0100},
  biburl    = {https://dblp.org/rec/conf/sp/PearceA0DK22.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@inproceedings{9956690,
  author    = {G. Ramakrishnan and A. Albarghouthi},
  booktitle = {2022 26th International Conference on Pattern Recognition (ICPR)},
  title     = {Backdoors in Neural Models of Source Code},
  year      = {2022},
  volume    = {},
  issn      = {},
  pages     = {2892-2899},
  abstract  = {Deep neural networks are vulnerable to a range of adversaries. A particularly pernicious class of vulnerabilities are backdoors, where model predictions diverge in the presence of subtle triggers in inputs. An attacker can implant a backdoor by poisoning the training data to yield a desired target prediction on triggered inputs. We study backdoors in the context of deep-learning for source code. (1) We define a range of backdoor classes for source-code tasks and install backdoors using dataset poisoning. (2) We adapt and improve recent algorithms from robust statistics for our setting, showing that backdoors leave a spectral signature in the learned representation of source code, thus enabling detection of poisoned data. (3) We conduct a thorough evaluation on different architectures and languages, showing the ease of injecting backdoors and our ability to eliminate them.},
  keywords  = {deep learning;codes;source coding;neural networks;training data;implants;predictive models},
  doi       = {10.1109/ICPR56361.2022.9956690},
  url       = {https://doi.ieeecomputersociety.org/10.1109/ICPR56361.2022.9956690},
  publisher = {IEEE Computer Society},
  address   = {Los Alamitos, CA, USA},
  month     = {aug}
}

@inproceedings{7102609,
  author    = {Kochhar, Pavneet Singh and Thung, Ferdian and Nagappan, Nachiappan and Zimmermann, Thomas and Lo, David},
  booktitle = {2015 IEEE 8th International Conference on Software Testing, Verification and Validation (ICST)},
  title     = {Understanding the Test Automation Culture of App Developers},
  year      = {2015},
  volume    = {},
  number    = {},
  pages     = {1-10},
  doi       = {10.1109/ICST.2015.7102609}
}


@inproceedings{shaowei-icst,
  author    = {Wang, Shaowei and Lo, David},
  title     = {Version History, Similar Report, and Structure: Putting Them Together for Improved Bug Localization},
  year      = {2014},
  isbn      = {9781450328791},
  publisher = {Association for Computing Machinery},
  address   = {New York, NY, USA},
  url       = {https://doi.org/10.1145/2597008.2597148},
  doi       = {10.1145/2597008.2597148},
  abstract  = {During the evolution of a software system, a large number of bug reports are submitted. Locating the source code files that need to be fixed to resolve the bugs is a challenging problem. Thus, there is a need for a technique that can automatically figure out these buggy files. A number of bug localization solutions that take in a bug report and output a ranked list of files sorted based on their likelihood to be buggy have been proposed in the literature. However, the accuracy of these tools still need to be improved. In this paper, to address this need, we propose AmaLgam, a new method for locating relevant buggy files that puts together version history, similar reports, and structure. To do this, AmaLgam integrates a bug prediction technique used in Google which analyzes version history, with a bug localization technique named BugLocator which analyzes similar reports from bug report system, and the state-of-the-art bug localization technique BLUiR which considers structure. We perform a large-scale experiment on four open source projects, namely AspectJ, Eclipse, SWT and ZXing to localize more than 3,000 bugs. Compared with a history-aware bug localization solution of Sisman and Kak, our approach achieves a 46.1% improvement in terms of mean average precision (MAP). Compared with BugLocator, our approach achieves a 24.4% improvement in terms of MAP. Compared with BLUiR, our approach achieves a 16.4% improvement in terms of MAP.},
  booktitle = {Proceedings of the 22nd International Conference on Program Comprehension},
  pages     = {53–63},
  numpages  = {11},
  keywords  = {Similar Report, Version History, Structure, Bug Localization},
  location  = {Hyderabad, India},
  series    = {ICPC 2014}
}

@inproceedings{li-etal-2020-bert-attack,
  title     = {{BERT}-{ATTACK}: Adversarial Attack Against {BERT} Using {BERT}},
  author    = {Li, Linyang  and
               Ma, Ruotian  and
               Guo, Qipeng  and
               Xue, Xiangyang  and
               Qiu, Xipeng},
  booktitle = {Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP)},
  month     = nov,
  year      = {2020},
  address   = {Online},
  publisher = {Association for Computational Linguistics},
  url       = {https://aclanthology.org/2020.emnlp-main.500},
  doi       = {10.18653/v1/2020.emnlp-main.500},
  pages     = {6193--6202},
  abstract  = {Adversarial attacks for discrete data (such as texts) have been proved significantly more challenging than continuous data (such as images) since it is difficult to generate adversarial samples with gradient-based methods. Current successful attack methods for texts usually adopt heuristic replacement strategies on the character or word level, which remains challenging to find the optimal solution in the massive space of possible combinations of replacements while preserving semantic consistency and language fluency. In this paper, we propose \textbf{BERT-Attack}, a high-quality and effective method to generate adversarial samples using pre-trained masked language models exemplified by BERT. We turn BERT against its fine-tuned models and other deep neural models in downstream tasks so that we can successfully mislead the target models to predict incorrectly. Our method outperforms state-of-the-art attack strategies in both success rate and perturb percentage, while the generated adversarial samples are fluent and semantically preserved. Also, the cost of calculation is low, thus possible for large-scale generations. The code is available at \url{https://github.com/LinyangLee/BERT-Attack}.}
}

@inproceedings{choi-etal-2022-tabs,
  title     = {{TABS}: Efficient Textual Adversarial Attack for Pre-trained {NL} Code Model Using Semantic Beam Search},
  author    = {Choi, YunSeok  and
               Kim, Hyojun  and
               Lee, Jee-Hyong},
  booktitle = {Proceedings of the 2022 Conference on Empirical Methods in Natural Language Processing},
  month     = dec,
  year      = {2022},
  address   = {Abu Dhabi, United Arab Emirates},
  publisher = {Association for Computational Linguistics},
  url       = {https://aclanthology.org/2022.emnlp-main.369},
  doi       = {10.18653/v1/2022.emnlp-main.369},
  pages     = {5490--5498},
  abstract  = {As pre-trained models have shown successful performance in program language processing as well as natural language processing, adversarial attacks on these models also attract attention. However, previous works on black-box adversarial attacks generated adversarial examples in a very inefficient way with simple greedy search. They also failed to find out better adversarial examples because it was hard to reduce the search space without performance loss. In this paper, we propose TABS, an efficient beam search black-box adversarial attack method. We adopt beam search to find out better adversarial examples, and contextual semantic filtering to effectively reduce the search space. Contextual semantic filtering reduces the number of candidate adversarial words considering the surrounding context and the semantic similarity. Our proposed method shows good performance in terms of attack success rate, the number of queries, and semantic similarity in attacking models for two tasks: NL code search classification and retrieval tasks.}
}

@misc{zhang2022text,
  title         = {Text Revealer: Private Text Reconstruction via Model Inversion Attacks against Transformers},
  author        = {Ruisi Zhang and Seira Hidano and Farinaz Koushanfar},
  year          = {2022},
  eprint        = {2209.10505},
  archiveprefix = {arXiv},
  primaryclass  = {cs.CL}
}

@inproceedings{10.1145/2810103.2813677,
  author    = {Fredrikson, Matt and Jha, Somesh and Ristenpart, Thomas},
  title     = {Model Inversion Attacks That Exploit Confidence Information and Basic Countermeasures},
  year      = {2015},
  isbn      = {9781450338325},
  publisher = {Association for Computing Machinery},
  address   = {New York, NY, USA},
  url       = {https://doi.org/10.1145/2810103.2813677},
  doi       = {10.1145/2810103.2813677},
  abstract  = {Machine-learning (ML) algorithms are increasingly utilized in privacy-sensitive applications such as predicting lifestyle choices, making medical diagnoses, and facial recognition. In a model inversion attack, recently introduced in a case study of linear classifiers in personalized medicine by Fredrikson et al., adversarial access to an ML model is abused to learn sensitive genomic information about individuals. Whether model inversion attacks apply to settings outside theirs, however, is unknown. We develop a new class of model inversion attack that exploits confidence values revealed along with predictions. Our new attacks are applicable in a variety of settings, and we explore two in depth: decision trees for lifestyle surveys as used on machine-learning-as-a-service systems and neural networks for facial recognition. In both cases confidence values are revealed to those with the ability to make prediction queries to models. We experimentally show attacks that are able to estimate whether a respondent in a lifestyle survey admitted to cheating on their significant other and, in the other context, show how to recover recognizable images of people's faces given only their name and access to the ML model. We also initiate experimental exploration of natural countermeasures, investigating a privacy-aware decision tree training algorithm that is a simple variant of CART learning, as well as revealing only rounded confidence values. The lesson that emerges is that one can avoid these kinds of MI attacks with negligible degradation to utility.},
  booktitle = {Proceedings of the 22nd ACM SIGSAC Conference on Computer and Communications Security},
  pages     = {1322–1333},
  numpages  = {12},
  keywords  = {machine learning, privacy, attacks},
  location  = {Denver, Colorado, USA},
  series    = {CCS '15}
}


@inproceedings{yin2020dreaming,
  title     = {Dreaming to Distill: Data-free Knowledge Transfer via DeepInversion},
  author    = {Yin, Hongxu and Molchanov, Pavlo and Alvarez, Jose M. and Li, Zhizhong and Mallya, Arun and Hoiem, Derek and Jha, Niraj K and Kautz, Jan},
  booktitle = {The IEEE/CVF Conf. Computer Vision and Pattern Recognition (CVPR)},
  month     = June,
  year      = {2020}
}

@inproceedings{7299155,
  author    = {A. Mahendran and A. Vedaldi},
  booktitle = {2015 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},
  title     = {Understanding deep image representations by inverting them},
  year      = {2015},
  volume    = {},
  issn      = {1063-6919},
  pages     = {5188-5196},
  abstract  = {Image representations, from SIFT and Bag of Visual Words to Convolutional Neural Networks (CNNs), are a crucial component of almost any image understanding system. Nevertheless, our understanding of them remains limited. In this paper we conduct a direct analysis of the visual information contained in representations by asking the following question: given an encoding of an image, to which extent is it possible to reconstruct the image itself? To answer this question we contribute a general framework to invert representations. We show that this method can invert representations such as HOG more accurately than recent alternatives while being applicable to CNNs too. We then use this technique to study the inverse of recent state-of-the-art CNN image representations for the first time. Among our findings, we show that several layers in CNNs retain photographically accurate information about the image, with different degrees of geometric and photometric invariance.},
  keywords  = {},
  doi       = {10.1109/CVPR.2015.7299155},
  url       = {https://doi.ieeecomputersociety.org/10.1109/CVPR.2015.7299155},
  publisher = {IEEE Computer Society},
  address   = {Los Alamitos, CA, USA},
  month     = {jun}
}


@inproceedings{wang2021variational,
  title     = {Variational Model Inversion Attacks},
  author    = {Kuan-Chieh Wang and YAN FU and Ke Li and Ashish J Khisti and Richard Zemel and Alireza Makhzani},
  booktitle = {Advances in Neural Information Processing Systems},
  editor    = {A. Beygelzimer and Y. Dauphin and P. Liang and J. Wortman Vaughan},
  year      = {2021},
  url       = {https://openreview.net/forum?id=c0O9vBVSvIl}
}

@inproceedings{CoProtector,
  author    = {Sun, Zhensu and Du, Xiaoning and Song, Fu and Ni, Mingze and Li, Li},
  title     = {CoProtector: Protect Open-Source Code against Unauthorized Training Usage with Data Poisoning},
  year      = {2022},
  isbn      = {9781450390965},
  publisher = {Association for Computing Machinery},
  address   = {New York, NY, USA},
  doi       = {10.1145/3485447.3512225},
  abstract  = { Github Copilot, trained on billions of lines of public code, has recently become the buzzword in the computer science research and practice community. Although it is designed to help developers implement safe and effective code with powerful intelligence, practitioners and researchers raise concerns about its ethical and security problems, e.g., should the copyleft licensed code be freely leveraged or insecure code be considered for training in the first place? These problems pose a significant impact on Copilot and other similar products that aim to learn knowledge from large-scale open-source code through deep learning models, which are inevitably on the rise with the fast development of artificial intelligence. To mitigate such impacts, we argue that there is a need to invent effective mechanisms for protecting open-source code from being exploited by deep learning models. Here, we design and implement a prototype, CoProtector, which utilizes data poisoning techniques to arm source code repositories for defending against such exploits. Our large-scale experiments empirically show that CoProtector is effective in achieving its purpose, significantly reducing the performance of Copilot-like deep learning models while being able to stably reveal the secretly embedded watermark backdoors. },
  booktitle = {Proceedings of the ACM Web Conference 2022},
  pages     = {652–660},
  numpages  = {9},
  keywords  = {open-source code, data poisoning, dataset protection, deep learning},
  location  = {Virtual Event, Lyon, France},
  series    = {WWW '22}
}

@article{landis1977measurement,
  title     = {The measurement of observer agreement for categorical data},
  author    = {Landis, J Richard and Koch, Gary G},
  journal   = {biometrics},
  pages     = {159--174},
  year      = {1977},
  publisher = {JSTOR}
}

@article{llama,
  title   = {LLaMA: Open and Efficient Foundation Language Models},
  author  = {Touvron, Hugo and Lavril, Thibaut and Izacard, Gautier and Martinet, Xavier and Lachaux, Marie-Anne and Lacroix, Timoth{\'e}e and Rozi{\`e}re, Baptiste and Goyal, Naman and Hambro, Eric and Azhar, Faisal and Rodriguez, Aurelien and Joulin, Armand and Grave, Edouard and Lample, Guillaume},
  journal = {arXiv preprint arXiv:2302.13971},
  year    = {2023}
}

@article{husain2019codesearchnet,
  title   = {{CodeSearchNet} challenge: Evaluating the state of semantic code search},
  author  = {Husain, Hamel and Wu, Ho-Hsiang and Gazit, Tiferet and Allamanis, Miltiadis and Brockschmidt, Marc},
  journal = {arXiv preprint arXiv:1909.09436},
  year    = {2019}
}

@article{RABIN2023107066,
  title    = {Memorization and generalization in neural code intelligence models},
  journal  = {Information and Software Technology},
  volume   = {153},
  pages    = {107066},
  year     = {2023},
  issn     = {0950-5849},
  doi      = {https://doi.org/10.1016/j.infsof.2022.107066},
  url      = {https://www.sciencedirect.com/science/article/pii/S0950584922001756},
  author   = {Md Rafiqul Islam Rabin and Aftab Hussain and Mohammad Amin Alipour and Vincent J. Hellendoorn},
  keywords = {Machine learning, Software engineering, Memorization and generalization, Empirical results, Models of code}
}

@INPROCEEDINGS {alkaswan2023abuse,
author = {A. Al-Kaswan and M. Izadi},
booktitle = {2023 IEEE/ACM 2nd International Workshop on Natural Language-Based Software Engineering (NLBSE)},
title = {The (ab)use of Open Source Code to Train Large Language Models},
year = {2023},
volume = {},
issn = {},
pages = {9-10},
abstract = {In recent years, Large Language Models (LLMs) have gained significant popularity due to their ability to generate human-like text and their potential applications in various fields, such as Software Engineering. LLMs for Code are commonly trained on large unsanitized corpora of source code scraped from the Internet. The content of these datasets is memorized and emitted by the models, often in a verbatim manner. In this work, we will discuss the security, privacy, and licensing implications of memorization. We argue why the use of copyleft code to train LLMs is a legal and ethical dilemma. Finally, we provide four actionable recommendations to address this issue.},
keywords = {privacy;ethics;codes;law;source coding;conferences;licenses},
doi = {10.1109/NLBSE59153.2023.00008},
url = {https://doi.ieeecomputersociety.org/10.1109/NLBSE59153.2023.00008},
publisher = {IEEE Computer Society},
address = {Los Alamitos, CA, USA},
month = {may}
}



@inproceedings{4151691,
  author    = {Kothari, Jay and Shevertalov, Maxim and Stehle, Edward and Mancoridis, Spiros},
  booktitle = {Fourth International Conference on Information Technology (ITNG'07)},
  title     = {A Probabilistic Approach to Source Code Authorship Identification},
  year      = {2007},
  volume    = {},
  number    = {},
  pages     = {243-248},
  doi       = {10.1109/ITNG.2007.17}
}


@article{DING200449,
  title    = {Extraction of Java program fingerprints for software authorship identification},
  journal  = {Journal of Systems and Software},
  volume   = {72},
  number   = {1},
  pages    = {49-57},
  year     = {2004},
  issn     = {0164-1212},
  doi      = {https://doi.org/10.1016/S0164-1212(03)00049-9},
  url      = {https://www.sciencedirect.com/science/article/pii/S0164121203000499},
  author   = {Haibiao Ding and Mansur H. Samadzadeh},
  keywords = {Authorship, Fingerprint, Java, Software},
  abstract = {Computer programs belong to the authors who design, write, and test them. Authorship identification is concerned with determining the likelihood of a particular author having written some piece(s) of code, usually based on other code samples from the same programmer. Java is a popular object-oriented computer programming language. Programming fingerprints attempt to characterize the features that are unique to each programmer. In this study, we investigated the extraction of a set of software metrics of a given Java source code––by a program written in Visual C++––that could be used as a fingerprint to identify the author of the Java code. The contributions of the selected metrics to authorship identification were measured by a statistical process, namely canonical discriminant analysis, using the statistical software package SAS. Out of the 56 extracted metrics, 48 metrics were identified as being contributive to authorship identification. The authorship of 62.6–67.2% of the Java programs considered could be correctly identified with the extracted metrics. The identification rate could be as high as 85.8%, with derived canonical variates. Moreover, layout metrics played a more important role in authorship identification than the other metrics.}
}

@article{cheers2021evaluating,
  title     = {Evaluating the robustness of source code plagiarism detection tools to pervasive plagiarism-hiding modifications},
  author    = {Cheers, Hayden and Lin, Yuqing and Smith, Shamus P},
  journal   = {Empirical Software Engineering},
  volume    = {26},
  number    = {5},
  pages     = {83},
  year      = {2021},
  publisher = {Springer}
}

@inproceedings{10.5555/2831143.2831160,
  author    = {Caliskan-Islam, Aylin and Harang, Richard and Liu, Andrew and Narayanan, Arvind and Voss, Clare and Yamaguchi, Fabian and Greenstadt, Rachel},
  title     = {De-Anonymizing Programmers via Code Stylometry},
  year      = {2015},
  isbn      = {9781931971232},
  publisher = {USENIX Association},
  address   = {USA},
  abstract  = {Source code authorship attribution is a significant privacy threat to anonymous code contributors. However, it may also enable attribution of successful attacks from code left behind on an infected system, or aid in resolving copyright, copyleft, and plagiarism issues in the programming fields. In this work, we investigate machine learning methods to de-anonymize source code authors of C/C++ using coding style. Our Code Stylometry Feature Set is a novel representation of coding style found in source code that reflects coding style from properties derived from abstract syntax trees.Our random forest and abstract syntax tree-based approach attributes more authors (1,600 and 250) with significantly higher accuracy (94\% and 98\%) on a larger data set (Google Code Jam) than has been previously achieved. Furthermore, these novel features are robust, difficult to obfuscate, and can be used in other programming languages, such as Python. We also find that (i) the code resulting from difficult programming tasks is easier to attribute than easier tasks and (ii) skilled programmers (who can complete the more difficult tasks) are easier to attribute than less skilled programmers.},
  booktitle = {Proceedings of the 24th USENIX Conference on Security Symposium},
  pages     = {255–270},
  numpages  = {16},
  location  = {Washington, D.C.},
  series    = {SEC'15}
}

@inproceedings{10.1007/0-387-34224-9_59,
  author    = {Frantzeskou, Georgia
               and Stamatatos, Efstathios
               and Gritzalis, Stefanos
               and Katsikas, Sokratis},
  editor    = {Maglogiannis, Ilias
               and Karpouzis, Kostas
               and Bramer, Max},
  title     = {Source Code Author Identification Based on N-gram Author Profiles},
  booktitle = {Artificial Intelligence Applications and Innovations},
  year      = {2006},
  publisher = {Springer US},
  address   = {Boston, MA},
  pages     = {508--515},
  abstract  = {Source code author identification deals with the task of identifying the most likely author of a computer program, given a set of predefined author candidates. This is usually. based on the analysis of other program samples of undisputed authorship by the same programmer. There are several cases where the application of such a method could be of a major benefit, such as authorship disputes, proof of authorship in court, tracing the source of code left in the system after a cyber attack, etc. We present a new approach, called the SCAP (Source Code Author Profiles) approach, based on byte-level n-gram profiles in order to represent a source code author's style. Experiments on data sets of different programming language (Java or C++) and varying difficulty (6 to 30 candidate authors) demonstrate the effectiveness of the proposed approach. A comparison with a previous source code authorship identification study based on more complicated information shows that the SCAP approach is language independent and that n-gram author profiles are better able to capture the idiosyncrasies of the source code authors. Moreover the SCAP approach is able to deal surprisingly well with cases where only a limited amount of very short programs per programmer is available for training. It is also demonstrated that the effectiveness of the proposed model is not affected by the absence of comments in the source code, a condition usually met in cyber-crime cases.},
  isbn      = {978-0-387-34224-5}
}


@inproceedings{10.5555/3361338.3361372,
  author    = {Quiring, Erwin and Maier, Alwin and Rieck, Konrad},
  title     = {Misleading Authorship Attribution of Source Code Using Adversarial Learning},
  year      = {2019},
  isbn      = {9781939133069},
  publisher = {USENIX Association},
  address   = {USA},
  abstract  = {In this paper, we present a novel attack against authorship attribution of source code. We exploit that recent attribution methods rest on machine learning and thus can be deceived by adversarial examples of source code. Our attack performs a series of semantics-preserving code transformations that mislead learning-based attribution but appear plausible to a developer. The attack is guided by Monte-Carlo tree search that enables us to operate in the discrete domain of source code. In an empirical evaluation with source code from 204 programmers, we demonstrate that our attack has a substantial effect on two recent attribution methods, whose accuracy drops from over 88\% to 1\% under attack. Furthermore, we show that our attack can imitate the coding style of developers with high accuracy and thereby induce false attributions. We conclude that current approaches for authorship attribution are inappropriate for practical application and there is a need for resilient analysis techniques.},
  booktitle = {Proceedings of the 28th USENIX Conference on Security Symposium},
  pages     = {479–496},
  numpages  = {18},
  location  = {Santa Clara, CA, USA},
  series    = {SEC'19}
}

@article{yang2017authorship,
  title     = {Authorship attribution of source code by using back propagation neural network based on particle swarm optimization},
  author    = {Yang, Xinyu and Xu, Guoai and Li, Qi and Guo, Yanhui and Zhang, Miao},
  journal   = {PloS one},
  volume    = {12},
  number    = {11},
  pages     = {e0187204},
  year      = {2017},
  publisher = {Public Library of Science San Francisco, CA USA}
}

@inproceedings{Matyukhina2019AdversarialAA,
  author    = {Matyukhina, Alina and Stakhanova, Natalia and Dalla Preda, Mila and Perley, Celine},
  title     = {Adversarial Authorship Attribution in Open-Source Projects},
  year      = {2019},
  isbn      = {9781450360999},
  publisher = {Association for Computing Machinery},
  address   = {New York, NY, USA},
  url       = {https://doi.org/10.1145/3292006.3300032},
  doi       = {10.1145/3292006.3300032},
  abstract  = {Open-source software is open to anyone by design, whether it is a community of developers, hackers or malicious users. Authors of open-source software typically hide their identity through nicknames and avatars. However, they have no protection against authorship attribution techniques that are able to create software author profiles just by analyzing software characteristics. In this paper we present an author imitation attack that allows to deceive current authorship attribution systems and mimic a coding style of a target developer. Withing this context we explore the potential of the existing attribution techniques to be deceived. Our results show that we are able to imitate the coding style of the developers based on the data collected from the popular source code repository, GitHub. To subvert author imitation attack, we propose a novel author obfuscation approach that allows us to hide the coding style of the author. Unlike existing obfuscation tools, this new obfuscation technique uses transformations that preserve code readability. We assess the effectiveness of our attacks on several datasets produced by actual developers from GitHub, and participants of the GoogleCodeJam competition. Throughout our experiments we show that the author hiding can be achieved by making sensible transformations which significantly reduce the likelihood of identifying the author's style to 0\% by current authorship attribution systems.},
  booktitle = {Proceedings of the Ninth ACM Conference on Data and Application Security and Privacy},
  pages     = {291–302},
  numpages  = {12},
  keywords  = {imitation, attacks, authorship attribution, open-source software, adversarial, obfuscation},
  location  = {Richardson, Texas, USA},
  series    = {CODASPY '19}
}

@inproceedings{aggarwal2014co,
  title     = {Co-evolution of project documentation and popularity within github},
  author    = {Aggarwal, Karan and Hindle, Abram and Stroulia, Eleni},
  booktitle = {Proceedings of the 11th working conference on mining software repositories},
  pages     = {360--363},
  year      = {2014}
}

@misc{advdoor,
  doi       = {10.48550/ARXIV.2301.02496},
  url       = {https://arxiv.org/abs/2301.02496},
  author    = {Yang, Zhou and Xu, Bowen and Zhang, Jie M. and Kang, Hong Jin and Shi, Jieke and He, Junda and Lo, David},
  title     = {Stealthy Backdoor Attack for Code Models},
  publisher = {arXiv},
  year      = {2023},
  copyright = {Creative Commons Attribution 4.0 International}
}

@misc{improta2023enhancing,
  title         = {Enhancing Robustness of AI Offensive Code Generators via Data Augmentation},
  author        = {Cristina Improta and Pietro Liguori and Roberto Natella and Bojan Cukic and Domenico Cotroneo},
  year          = {2023},
  eprint        = {2306.05079},
  archiveprefix = {arXiv},
  primaryclass  = {cs.LG}
}


@article{zhangcodebert,
  title     = {CodeBERT-Attack: Adversarial attack against source code deep learning models via pre-trained model},
  author    = {Zhang, Huangzhao and Lu, Shuai and Li, Zhuo and Jin, Zhi and Ma, Lei and Liu, Yang and Li, Ge},
  journal   = {Journal of Software: Evolution and Process},
  pages     = {e2571},
  publisher = {Wiley Online Library}
}

@inproceedings{10.1145/3472883.3486995,
  author    = {Suneja, Sahil and Zheng, Yunhui and Zhuang, Yufan and Laredo, Jim A. and Morari, Alessandro},
  title     = {Towards Reliable AI for Source Code Understanding},
  year      = {2021},
  isbn      = {9781450386388},
  publisher = {Association for Computing Machinery},
  address   = {New York, NY, USA},
  url       = {https://doi.org/10.1145/3472883.3486995},
  doi       = {10.1145/3472883.3486995},
  abstract  = {Cloud maturity and popularity have resulted in Open source software (OSS) proliferation. And, in turn, managing OSS code quality has become critical in ensuring sustainable Cloud growth. On this front, AI modeling has gained popularity in source code understanding tasks, promoted by the ready availability of large open codebases. However, we have been observing certain peculiarities with these black-boxes, motivating a call for their reliability to be verified before offsetting traditional code analysis. In this work, we highlight and organize different reliability issues affecting AI-for-code into three stages of an AI pipeline- data collection, model training, and prediction analysis. We highlight the need for concerted efforts from the research community to ensure credibility, accountability, and traceability for AI-for-code. For each stage, we discuss unique opportunities afforded by the source code and software engineering setting to improve AI reliability.},
  booktitle = {Proceedings of the ACM Symposium on Cloud Computing},
  pages     = {403–411},
  numpages  = {9},
  keywords  = {signal awareness, explainability, machine learning, reliability},
  location  = {Seattle, WA, USA},
  series    = {SoCC '21}
}

@misc{hussain2023trojanedcm,
      title={TrojanedCM: A Repository of Trojaned Large Language Models of Code}, 
      author={Aftab Hussain and Md Rafiqul Islam Rabin and Mohammad Amin Alipour},
      year={2023},
      eprint={2311.14850},
      archivePrefix={arXiv},
      primaryClass={cs.SE}
}

@misc{hussain2023survey,
  title         = {A Survey of Trojans in Neural Models of Source Code: Taxonomy and Techniques},
  author        = {Aftab Hussain and Md Rafiqul Islam Rabin and Toufique Ahmed and Navid Ayoobi and Bowen Xu and Prem Devanbu and Mohammad Amin Alipour},
  year          = {2023},
  eprint        = {2305.03803},
  archiveprefix = {arXiv},
  primaryclass  = {cs.SE}
}


@article{zhang2022towards,
  title     = {Towards robustness of deep program processing models—detection, estimation, and enhancement},
  author    = {Zhang, Huangzhao and Fu, Zhiyi and Li, Ge and Ma, Lei and Zhao, Zhehao and Yang, Hua’an and Sun, Yizhe and Liu, Yang and Jin, Zhi},
  journal   = {ACM Transactions on Software Engineering and Methodology (TOSEM)},
  volume    = {31},
  number    = {3},
  pages     = {1--40},
  year      = {2022},
  publisher = {ACM New York, NY}
}

@article{aghakhani2023trojanpuzzle,
  title   = {TrojanPuzzle: Covertly Poisoning Code-Suggestion Models},
  author  = {Aghakhani, Hojjat and Dai, Wei and Manoel, Andre and Fernandes, Xavier and Kharkar, Anant and Kruegel, Christopher and Vigna, Giovanni and Evans, David and Zorn, Ben and Sim, Robert},
  journal = {arXiv preprint arXiv:2301.02344},
  year    = {2023}
}

@article{Asare2023secure,
  author     = {Asare, Owura and Nagappan, Meiyappan and Asokan, N.},
  title      = {Is GitHub’s Copilot as Bad as Humans at Introducing Vulnerabilities in Code?},
  year       = {2023},
  issue_date = {Nov 2023},
  publisher  = {Kluwer Academic Publishers},
  address    = {USA},
  volume     = {28},
  number     = {6},
  issn       = {1382-3256},
  url        = {https://doi.org/10.1007/s10664-023-10380-1},
  doi        = {10.1007/s10664-023-10380-1},
  abstract   = {Several advances in deep learning have been successfully applied to the software development process. Of recent interest is the use of neural language models to build tools, such as Copilot, that assist in writing code. In this paper we perform a comparative empirical analysis of Copilot-generated code from a security perspective. The aim of this study is to determine if Copilot is as bad as human developers. We investigate whether Copilot is just as likely to introduce the same software vulnerabilities as human developers. Using a dataset of C/C++ vulnerabilities, we prompt Copilot to generate suggestions in scenarios that led to the introduction of vulnerabilities by human developers. The suggestions are inspected and categorized in a 2-stage process based on whether the original vulnerability or fix is reintroduced. We find that Copilot replicates the original vulnerable code about 33\% of the time while replicating the fixed code at a 25\% rate. However this behaviour is not consistent: Copilot is more likely to introduce some types of vulnerabilities than others and is also more likely to generate vulnerable code in response to prompts that correspond to older vulnerabilities. Overall, given that in a significant number of cases it did not replicate the vulnerabilities previously introduced by human developers, we conclude that Copilot, despite performing differently across various vulnerability types, is not as bad as human developers at introducing vulnerabilities in code.},
  journal    = {Empirical Softw. Engg.},
  month      = {sep},
  numpages   = {24},
  keywords   = {software engineering, copilot, language models, code security}
}

@inproceedings{ManySStuBs4J,
  author    = {Karampatsis, Rafael-Michael and Sutton, Charles},
  title     = {How Often Do Single-Statement Bugs Occur? The ManySStuBs4J Dataset},
  year      = {2020},
  isbn      = {9781450375177},
  publisher = {Association for Computing Machinery},
  address   = {New York, NY, USA},
  url       = {https://doi.org/10.1145/3379597.3387491},
  doi       = {10.1145/3379597.3387491},
  abstract  = {Program repair is an important but difficult software engineering problem. One way to achieve acceptable performance is to focus on classes of simple bugs, such as bugs with single statement fixes, or that match a small set of bug templates. However, it is very difficult to estimate the recall of repair techniques for simple bugs, as there are no datasets about how often the associated bugs occur in code. To fill this gap, we provide a dataset of 153,652 single statement bug-fix changes mined from 1,000 popular open-source Java projects, annotated by whether they match any of a set of 16 bug templates, inspired by state-of-the-art program repair techniques. In an initial analysis, we find that about 33\% of the simple bug fixes match the templates, indicating that a remarkable number of single-statement bugs can be repaired with a relatively small set of templates. Further, we find that template fitting bugs appear with a frequency of about one bug per 1,600-2,500 lines of code (as measured by the size of the project's latest version). We hope that the dataset will prove a resource for both future work in program repair and studies in empirical software engineering.},
  booktitle = {Proceedings of the 17th International Conference on Mining Software Repositories},
  pages     = {573–577},
  numpages  = {5},
  location  = {Seoul, Republic of Korea},
  series    = {MSR '20}
}

@inproceedings{stupidbug,
  author    = {K. Jesse and T. Ahmed and P. T. Devanbu and E. Morgan},
  booktitle = {2023 IEEE/ACM 20th International Conference on Mining Software Repositories (MSR)},
  title     = {Large Language Models and Simple, Stupid Bugs},
  year      = {2023},
  volume    = {},
  issn      = {},
  pages     = {563-575},
  keywords  = {training;codes;computer bugs;production;writing;programming;software},
  doi       = {10.1109/MSR59073.2023.00082},
  url       = {https://doi.ieeecomputersociety.org/10.1109/MSR59073.2023.00082},
  publisher = {IEEE Computer Society},
  address   = {Los Alamitos, CA, USA},
  month     = {may}
}

@article{Evtikhiev2023bleu,
  title    = {Out of the BLEU: How should we assess quality of the Code Generation models?},
  journal  = {Journal of Systems and Software},
  volume   = {203},
  pages    = {111741},
  year     = {2023},
  issn     = {0164-1212},
  doi      = {https://doi.org/10.1016/j.jss.2023.111741},
  url      = {https://www.sciencedirect.com/science/article/pii/S016412122300136X},
  author   = {Mikhail Evtikhiev and Egor Bogomolov and Yaroslav Sokolov and Timofey Bryksin},
  keywords = {Code generation, Metrics, Neural networks, Code similarity},
  abstract = {In recent years, researchers have created and introduced a significant number of various code generation models. As human evaluation of every new model version is unfeasible, the community adopted automatic evaluation metrics such as BLEU to approximate the results of human judgement. These metrics originate from the machine translation domain and it is unclear whether they are applicable for the code generation tasks and how well they agree with the human evaluation on this task. There are also other metrics, CodeBLEU and RUBY, developed to estimate the similarity of code, that take into account the properties of source code. However, for these metrics there are hardly any studies on their agreement with the human evaluation. Despite all that, minimal differences in the metric scores have been used in recent papers to claim superiority of some code generation models over the others. In this paper, we present a study on the applicability of six metrics—BLEU, ROUGE-L, METEOR, ChrF, CodeBLEU, and RUBY—for evaluation of code generation models. We conduct a study on two different code generation datasets and use human annotators to assess the quality of all models run on these datasets. The results indicate that for the CoNaLa dataset of Python one-liners, none of the metrics can correctly emulate human judgement on which model is better with >95% certainty if the difference in model scores is less than 5 points. For the HearthStone dataset, which consists of classes of a particular structure, a difference in model scores of at least 2 points is enough to claim the superiority of one model over the other. Our findings suggest that the ChrF metric is a better fit for the evaluation of code generation models than the commonly used BLEU and CodeBLEU. Yet, finding a metric for code generation that closely agrees with humans requires additional work.}
}

@misc{erhabor2023measuring,
  title         = {Measuring the Runtime Performance of Code Produced with GitHub Copilot},
  author        = {Daniel Erhabor and Sreeharsha Udayashankar and Meiyappan Nagappan and Samer Al-Kiswany},
  year          = {2023},
  eprint        = {2305.06439},
  archiveprefix = {arXiv},
  primaryclass  = {cs.SE}
}

@misc{sandoval2023lost,
  title         = {Lost at C: A User Study on the Security Implications of Large Language Model Code Assistants},
  author        = {Gustavo Sandoval and Hammond Pearce and Teo Nys and Ramesh Karri and Siddharth Garg and Brendan Dolan-Gavitt},
  year          = {2023},
  eprint        = {2208.09727},
  archiveprefix = {arXiv},
  primaryclass  = {cs.CR}
}

@inproceedings{10172854,
  author    = {Z. Fan and X. Gao and M. Mirchev and A. Roychoudhury and S. Tan},
  booktitle = {2023 IEEE/ACM 45th International Conference on Software Engineering (ICSE)},
  title     = {Automated Repair of Programs from Large Language Models},
  year      = {2023},
  volume    = {},
  issn      = {},
  pages     = {1469-1481},
  abstract  = {Large language models such as Codex, have shown the capability to produce code for many programming tasks. However, the success rate of existing models is low, especially for complex programming tasks. One of the reasons is that language models lack awareness of program semantics, resulting in incorrect programs, or even programs which do not compile. In this paper, we systematically study whether automated program repair (APR) techniques can fix the incorrect solutions produced by language models in LeetCode contests. The goal is to study whether APR techniques can enhance reliability in the code produced by large language models. Our study revealed that: (1) automatically generated code shares common programming mistakes with human-crafted solutions, indicating APR techniques may have potential to fix auto-generated code; (2) given bug location information provided by a statistical fault localization approach, the newly released Codex edit mode, which supports editing code, is similar to or better than existing Java repair tools TBar and Recoder in fixing incorrect solutions. By analyzing the experimental results generated by these tools, we provide several suggestions: (1) enhancing APR tools to surpass limitations in patch space (e.g., introducing more flexible fault localization) is desirable; (2) as large language models can derive more fix patterns by training on more data, future APR tools could shift focus from adding more fix patterns to synthesis/semantics based approaches, (3) combination of language models with APR to curate patch ingredients, is worth studying.},
  keywords  = {location awareness;training;analytical models;codes;semantics;maintenance engineering;programming},
  doi       = {10.1109/ICSE48619.2023.00128},
  url       = {https://doi.ieeecomputersociety.org/10.1109/ICSE48619.2023.00128},
  publisher = {IEEE Computer Society},
  address   = {Los Alamitos, CA, USA},
  month     = {may}
}


@inproceedings{qi-etal-2021-onion,
  title     = {{ONION}: A Simple and Effective Defense Against Textual Backdoor Attacks},
  author    = {Qi, Fanchao  and
               Chen, Yangyi  and
               Li, Mukai  and
               Yao, Yuan  and
               Liu, Zhiyuan  and
               Sun, Maosong},
  booktitle = {Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing},
  month     = nov,
  year      = {2021},
  address   = {Online and Punta Cana, Dominican Republic},
  publisher = {Association for Computational Linguistics},
  doi       = {10.18653/v1/2021.emnlp-main.752},
  pages     = {9558--9566}
}


@misc{he2023largearxiv,
  title         = {Controlling Large Language Models to Generate Secure and Vulnerable Code},
  author        = {Jingxuan He and Martin Vechev},
  year          = {2023},
  eprint        = {2302.05319},
  archiveprefix = {arXiv},
  primaryclass  = {cs.CR}
}

@misc{CodePoisoner,
  doi       = {10.48550/ARXIV.2210.17029},
  url       = {https://arxiv.org/abs/2210.17029},
  author    = {Li, Jia and Li, Zhuo and Zhang, Huangzhao and Li, Ge and Jin, Zhi and Hu, Xing and Xia, Xin},
  keywords  = {Software Engineering (cs.SE), Artificial Intelligence (cs.AI), FOS: Computer and information sciences, FOS: Computer and information sciences},
  title     = {Poison Attack and Defense on Deep Source Code Processing Models},
  publisher = {arXiv},
  year      = {2022},
  copyright = {arXiv.org perpetual, non-exclusive license}
}


@inproceedings{snowball1,
  author    = {Jalali, Samireh and Wohlin, Claes},
  booktitle = {Proceedings of the 2012 ACM-IEEE International Symposium on Empirical Software Engineering and Measurement},
  title     = {Systematic literature studies: Database searches vs. backward snowballing},
  year      = {2012},
  volume    = {},
  number    = {},
  pages     = {29-38},
  doi       = {10.1145/2372251.2372257}
}

@inproceedings{snowball2,
  author    = {Wohlin, Claes},
  title     = {Guidelines for Snowballing in Systematic Literature Studies and a Replication in Software Engineering},
  year      = {2014},
  isbn      = {9781450324762},
  publisher = {Association for Computing Machinery},
  address   = {New York, NY, USA},
  url       = {https://doi.org/10.1145/2601248.2601268},
  doi       = {10.1145/2601248.2601268},
  abstract  = {Background: Systematic literature studies have become common in software engineering, and hence it is important to understand how to conduct them efficiently and reliably.Objective: This paper presents guidelines for conducting literature reviews using a snowballing approach, and they are illustrated and evaluated by replicating a published systematic literature review.Method: The guidelines are based on the experience from conducting several systematic literature reviews and experimenting with different approaches.Results: The guidelines for using snowballing as a way to search for relevant literature was successfully applied to a systematic literature review.Conclusions: It is concluded that using snowballing, as a first search strategy, may very well be a good alternative to the use of database searches.},
  booktitle = {Proceedings of the 18th International Conference on Evaluation and Assessment in Software Engineering},
  articleno = {38},
  numpages  = {10},
  keywords  = {snowballing, systematic mapping studies, systematic literature review, snowball search, replication},
  location  = {London, England, United Kingdom},
  series    = {EASE '14}
}
@inproceedings{you-see,
  author    = {Wan, Yao and Zhang, Shijie and Zhang, Hongyu and Sui, Yulei and Xu, Guandong and Yao, Dezhong and Jin, Hai and Sun, Lichao},
  title     = {You See What I Want You to See: Poisoning Vulnerabilities in Neural Code Search},
  year      = {2022},
  isbn      = {9781450394130},
  publisher = {Association for Computing Machinery},
  address   = {New York, NY, USA},
  url       = {https://doi.org/10.1145/3540250.3549153},
  doi       = {10.1145/3540250.3549153},
  abstract  = {Searching and reusing code snippets from open-source software repositories based on natural-language queries can greatly improve programming productivity.Recently, deep-learning-based approaches have become increasingly popular for code search. Despite substantial progress in training accurate models of code search, the robustness of these models has received little attention so far. In this paper, we aim to study and understand the security and robustness of code search models by answering the following question: Can we inject backdoors into deep-learning-based code search models? If so, can we detect poisoned data and remove these backdoors? This work studies and develops a series of backdoor attacks on the deep-learning-based models for code search, through data poisoning. We first show that existing models are vulnerable to data-poisoning-based backdoor attacks. We then introduce a simple yet effective attack on neural code search models by poisoning their corresponding training dataset. Moreover, we demonstrate that attacks can also influence the ranking of the code search results by adding a few specially-crafted source code files to the training corpus. We show that this type of backdoor attack is effective for several representative deep-learning-based code search systems, and can successfully manipulate the ranking list of searching results. Taking the bidirectional RNN-based code search system as an example, the normalized ranking of the target candidate can be significantly raised from top 50\% to top 4.43\%, given a query containing an attacker targeted word, e.g., file. To defend a model against such attack, we empirically examine an existing popular defense strategy and evaluate its performance. Our results show the explored defense strategy is not yet effective in our proposed backdoor attack for code search systems.},
  booktitle = {Proceedings of the 30th ACM Joint European Software Engineering Conference and Symposium on the Foundations of Software Engineering},
  pages     = {1233–1245},
  numpages  = {13},
  keywords  = {Code search, software vulnerability, deep learning, backdoor attack, data poisoning},
  location  = {Singapore, Singapore},
  series    = {ESEC/FSE 2022}
}


@inproceedings{codegen,
  title     = {CodeGen: An Open Large Language Model for Code with Multi-Turn Program Synthesis},
  author    = {Erik Nijkamp and Bo Pang and Hiroaki Hayashi and Lifu Tu and Huan Wang and Yingbo Zhou and Silvio Savarese and Caiming Xiong},
  booktitle = {The Eleventh International Conference on Learning Representations },
  year      = {2023},
  url       = {https://openreview.net/forum?id=iaYcJKpY2B_}
}

@inproceedings{abdalkareem2017developers,
  title     = {Why do developers use trivial packages? an empirical case study on npm},
  author    = {Abdalkareem, Rabe and Nourry, Olivier and Wehaibi, Sultan and Mujahid, Suhaib and Shihab, Emad},
  booktitle = {Proceedings of the 2017 11th joint meeting on foundations of software engineering},
  pages     = {385--395},
  year      = {2017}
}

@misc{perry2022users,
  title         = {Do Users Write More Insecure Code with AI Assistants?},
  author        = {Neil Perry and Megha Srivastava and Deepak Kumar and Dan Boneh},
  year          = {2022},
  eprint        = {2211.03622},
  archiveprefix = {arXiv},
  primaryclass  = {cs.CR}
}


@article{yang2023code,
  title   = {On Code Reuse from StackOverflow: An Exploratory Study on Jupyter Notebook},
  author  = {Yang, Mingke and Zhou, Yuming and Li, Bixin and Tang, Yutian},
  journal = {arXiv preprint arXiv:2302.11732},
  year    = {2023}
}

@misc{apps,
  title         = {Measuring Coding Challenge Competence With APPS},
  author        = {Dan Hendrycks and Steven Basart and Saurav Kadavath and Mantas Mazeika and Akul Arora and Ethan Guo and Collin Burns and Samir Puranik and Horace He and Dawn Song and Jacob Steinhardt},
  year          = {2021},
  eprint        = {2105.09938},
  archiveprefix = {arXiv},
  primaryclass  = {cs.SE}
}

@article{abdalkareem2017code,
  title     = {On code reuse from stackoverflow: An exploratory study on android apps},
  author    = {Abdalkareem, Rabe and Shihab, Emad and Rilling, Juergen},
  journal   = {Information and Software Technology},
  volume    = {88},
  pages     = {148--158},
  year      = {2017},
  publisher = {Elsevier}
}

@inproceedings{9240619,
  author    = {Wang, Ying and Chen, Bihuan and Huang, Kaifeng and Shi, Bowen and Xu, Congying and Peng, Xin and Wu, Yijian and Liu, Yang},
  booktitle = {2020 IEEE International Conference on Software Maintenance and Evolution (ICSME)},
  title     = {An Empirical Study of Usages, Updates and Risks of Third-Party Libraries in Java Projects},
  year      = {2020},
  volume    = {},
  number    = {},
  pages     = {35-45},
  doi       = {10.1109/ICSME46990.2020.00014}
}


@inproceedings{code-search-reuse,
  author    = {Sadowski, Caitlin and Stolee, Kathryn T. and Elbaum, Sebastian},
  title     = {How Developers Search for Code: A Case Study},
  year      = {2015},
  isbn      = {9781450336758},
  publisher = {Association for Computing Machinery},
  address   = {New York, NY, USA},
  url       = {https://doi.org/10.1145/2786805.2786855},
  doi       = {10.1145/2786805.2786855},
  abstract  = {With the advent of large code repositories and sophisticated search capabilities, code search is increasingly becoming a key software development activity. In this work we shed some light into how developers search for code through a case study performed at Google, using a combination of survey and log-analysis methodologies. Our study provides insights into what developers are doing and trying to learn when per- forming a search, search scope, query properties, and what a search session under different contexts usually entails. Our results indicate that programmers search for code very frequently, conducting an average of five search sessions with 12 total queries each workday. The search queries are often targeted at a particular code location and programmers are typically looking for code with which they are somewhat familiar. Further, programmers are generally seeking answers to questions about how to use an API, what code does, why something is failing, or where code is located.},
  booktitle = {Proceedings of the 2015 10th Joint Meeting on Foundations of Software Engineering},
  pages     = {191–201},
  numpages  = {11},
  keywords  = {user evaluation, developer tools, code search},
  location  = {Bergamo, Italy},
  series    = {ESEC/FSE 2015}
}

@article{simko2018recognizing,
  title   = {Recognizing and Imitating Programmer Style: Adversaries in Program Authorship Attribution.},
  author  = {Simko, Lucy and Zettlemoyer, Luke and Kohno, Tadayoshi},
  journal = {Proc. Priv. Enhancing Technol.},
  volume  = {2018},
  number  = {1},
  pages   = {127--144},
  year    = {2018}
}

@misc{gpt-j,
  author       = {Wang, Ben and Komatsuzaki, Aran},
  title        = {{GPT-J-6B: A 6 Billion Parameter Autoregressive Language Model}},
  howpublished = {\url{https://github.com/kingoflolz/mesh-transformer-jax}},
  year         = 2021,
  month        = May
}

@article{raffel2020exploring,
  title     = {Exploring the limits of transfer learning with a unified text-to-text transformer},
  author    = {Raffel, Colin and Shazeer, Noam and Roberts, Adam and Lee, Katherine and Narang, Sharan and Matena, Michael and Zhou, Yanqi and Li, Wei and Liu, Peter J},
  journal   = {The Journal of Machine Learning Research},
  volume    = {21},
  number    = {1},
  pages     = {5485--5551},
  year      = {2020},
  publisher = {JMLRORG}
}

@article{black2022gpt,
  title   = {Gpt-neox-20b: An open-source autoregressive language model},
  author  = {Black, Sid and Biderman, Stella and Hallahan, Eric and Anthony, Quentin and Gao, Leo and Golding, Laurence and He, Horace and Leahy, Connor and McDonell, Kyle and Phang, Jason and others},
  journal = {arXiv preprint arXiv:2204.06745},
  year    = {2022}
}

@article{LIGUORI2023120073,
  title    = {Who evaluates the evaluators? On automatic metrics for assessing AI-based offensive code generators},
  journal  = {Expert Systems with Applications},
  volume   = {225},
  pages    = {120073},
  year     = {2023},
  issn     = {0957-4174},
  doi      = {https://doi.org/10.1016/j.eswa.2023.120073},
  url      = {https://www.sciencedirect.com/science/article/pii/S0957417423005754},
  author   = {Pietro Liguori and Cristina Improta and Roberto Natella and Bojan Cukic and Domenico Cotroneo},
  keywords = {AI-based code generators, Offensive code, Neural machine translation, Software security, Output similarity metrics},
  abstract = {AI-based code generators are an emerging solution for automatically writing programs starting from descriptions in natural language, by using deep neural networks (Neural Machine Translation, NMT). In particular, code generators have been used for ethical hacking and offensive security testing by generating proof-of-concept attacks. Unfortunately, the evaluation of code generators still faces several issues. The current practice uses output similarity metrics, i.e., automatic metrics that compute the textual similarity of generated code with ground-truth references. However, it is not clear what metric to use, and which metric is most suitable for specific contexts. This work analyzes a large set of output similarity metrics on offensive code generators. We apply the metrics on two state-of-the-art NMT models using two datasets containing offensive assembly and Python code with their descriptions in the English language. We compare the estimates from the automatic metrics with human evaluation and provide practical insights into their strengths and limitations.}
}

@misc{hajipour2023systematically,
  title         = {Systematically Finding Security Vulnerabilities in Black-Box Code Generation Models},
  author        = {Hossein Hajipour and Thorsten Holz and Lea Schönherr and Mario Fritz},
  year          = {2023},
  eprint        = {2302.04012},
  archiveprefix = {arXiv},
  primaryclass  = {cs.CR}
}

@inproceedings{fried2023incoder,
  title     = {InCoder: A Generative Model for Code Infilling and Synthesis},
  author    = {Daniel Fried and Armen Aghajanyan and Jessy Lin and Sida Wang and Eric Wallace and Freda Shi and Ruiqi Zhong and Scott Yih and Luke Zettlemoyer and Mike Lewis},
  booktitle = {The Eleventh International Conference on Learning Representations },
  year      = {2023},
  url       = {https://openreview.net/forum?id=hQwb-lbM6EL}
}

@inproceedings{finepruning,
  author    = {Liu, Kang
               and Dolan-Gavitt, Brendan
               and Garg, Siddharth},
  editor    = {Bailey, Michael
               and Holz, Thorsten
               and Stamatogiannakis, Manolis
               and Ioannidis, Sotiris},
  title     = {Fine-Pruning: Defending Against Backdooring Attacks on Deep Neural Networks},
  booktitle = {Research in Attacks, Intrusions, and Defenses},
  year      = {2018},
  publisher = {Springer International Publishing},
  address   = {Cham},
  pages     = {273--294},
  abstract  = {Deep neural networks (DNNs) provide excellent performance across a wide range of classification tasks, but their training requires high computational resources and is often outsourced to third parties. Recent work has shown that outsourced training introduces the risk that a malicious trainer will return a backdoored DNN that behaves normally on most inputs but causes targeted misclassifications or degrades the accuracy of the network when a trigger known only to the attacker is present. In this paper, we provide the first effective defenses against backdoor attacks on DNNs. We implement three backdoor attacks from prior work and use them to investigate two promising defenses, pruning and fine-tuning. We show that neither, by itself, is sufficient to defend against sophisticated attackers. We then evaluate fine-pruning, a combination of pruning and fine-tuning, and show that it successfully weakens or even eliminates the backdoors, i.e., in some cases reducing the attack success rate to 0{\%} with only a {\$}{\$}0.4{\backslash}{\%}{\$}{\$}drop in accuracy for clean (non-triggering) inputs. Our work provides the first step toward defenses against backdoor attacks in deep neural networks.},
  isbn      = {978-3-030-00470-5}
}



@inproceedings{li-etal-2023-multi-target,
  title     = {Multi-target Backdoor Attacks for Code Pre-trained Models},
  author    = {Li, Yanzhou  and
               Liu, Shangqing  and
               Chen, Kangjie  and
               Xie, Xiaofei  and
               Zhang, Tianwei  and
               Liu, Yang},
  booktitle = {Proceedings of the 61st Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)},
  month     = jul,
  year      = {2023},
  address   = {Toronto, Canada},
  publisher = {Association for Computational Linguistics},
  url       = {https://aclanthology.org/2023.acl-long.399},
  doi       = {10.18653/v1/2023.acl-long.399},
  pages     = {7236--7254},
  abstract  = {Backdoor attacks for neural code models have gained considerable attention due to the advancement of code intelligence. However, most existing works insert triggers into task-specific data for code-related downstream tasks, thereby limiting the scope of attacks. Moreover, the majority of attacks for pre-trained models are designed for understanding tasks. In this paper, we propose task-agnostic backdoor attacks for code pre-trained models. Our backdoored model is pre-trained with two learning strategies (i.e., Poisoned Seq2Seq learning and token representation learning) to support the multi-target attack of downstream code understanding and generation tasks. During the deployment phase, the implanted backdoors in the victim models can be activated by the designed triggers to achieve the targeted attack. We evaluate our approach on two code understanding tasks and three code generation tasks over seven datasets. Extensive experimental results demonstrate that our approach effectively and stealthily attacks code-related downstream tasks.}
}

@misc{cotroneo2023vulnerabilities,
  title         = {Vulnerabilities in AI Code Generators: Exploring Targeted Data Poisoning Attacks},
  author        = {Domenico Cotroneo and Cristina Improta and Pietro Liguori and Roberto Natella},
  year          = {2023},
  eprint        = {2308.04451},
  archiveprefix = {arXiv},
  primaryclass  = {cs.CR}
}

@inproceedings{263874,
  author    = {Roei Schuster and Congzheng Song and Eran Tromer and Vitaly Shmatikov},
  title     = {You Autocomplete Me: Poisoning Vulnerabilities in Neural Code Completion},
  booktitle = {30th USENIX Security Symposium (USENIX Security 21)},
  year      = {2021},
  isbn      = {978-1-939133-24-3},
  pages     = {1559--1575},
  publisher = {USENIX Association},
  month     = aug
}

@misc{openai2023gpt4,
  title         = {GPT-4 Technical Report},
  author        = {OpenAI},
  year          = {2023},
  eprint        = {2303.08774},
  archiveprefix = {arXiv},
  primaryclass  = {cs.CL}
}

@inproceedings{mastropaolo2021studying,
  title        = {Studying the usage of text-to-text transfer transformer to support code-related tasks},
  author       = {Mastropaolo, Antonio and Scalabrino, Simone and Cooper, Nathan and Palacio, David Nader and Poshyvanyk, Denys and Oliveto, Rocco and Bavota, Gabriele},
  booktitle    = {2021 IEEE/ACM 43rd International Conference on Software Engineering (ICSE)},
  pages        = {336--347},
  year         = {2021},
  organization = {IEEE}
}

@article{radford2018improving,
  title     = {Improving language understanding by generative pre-training},
  author    = {Radford, Alec and Narasimhan, Karthik and Salimans, Tim and Sutskever, Ilya and others},
  year      = {2018},
  publisher = {OpenAI}
}

@inproceedings{gu2022assemble,
  title        = {Assemble foundation models for automatic code summarization},
  author       = {Gu, Jian and Salza, Pasquale and Gall, Harald C},
  booktitle    = {2022 IEEE International Conference on Software Analysis, Evolution and Reengineering (SANER)},
  pages        = {935--946},
  year         = {2022},
  organization = {IEEE}
}

@inproceedings{al2023extending,
  title        = {Extending Source Code Pre-Trained Language Models to Summarise Decompiled Binarie},
  author       = {Al-Kaswan, Ali and Ahmed, Toufique and Izadi, Maliheh and Sawant, Anand Ashok and Devanbu, Premkumar and van Deursen, Arie},
  booktitle    = {2023 IEEE International Conference on Software Analysis, Evolution and Reengineering (SANER)},
  pages        = {260--271},
  year         = {2023},
  organization = {IEEE}
}


@misc{CoTexT,
  title         = {CoTexT: Multi-task Learning with Code-Text Transformer},
  author        = {Long Phan and Hieu Tran and Daniel Le and Hieu Nguyen and James Anibal and Alec Peltekian and Yanfang Ye},
  year          = {2021},
  eprint        = {2105.08645},
  archiveprefix = {arXiv},
  primaryclass  = {cs.AI}
}

@inproceedings{ContraCode,
  title     = {Contrastive Code Representation Learning},
  author    = {Jain, Paras  and
               Jain, Ajay  and
               Zhang, Tianjun  and
               Abbeel, Pieter  and
               Gonzalez, Joseph  and
               Stoica, Ion},
  booktitle = {Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing},
  month     = nov,
  year      = {2021},
  address   = {Online and Punta Cana, Dominican Republic},
  publisher = {Association for Computational Linguistics},
  url       = {https://aclanthology.org/2021.emnlp-main.482},
  doi       = {10.18653/v1/2021.emnlp-main.482},
  pages     = {5954--5971},
  abstract  = {Recent work learns contextual representations of source code by reconstructing tokens from their context. For downstream semantic understanding tasks like code clone detection, these representations should ideally capture program functionality. However, we show that the popular reconstruction-based RoBERTa model is sensitive to source code edits, even when the edits preserve semantics. We propose ContraCode: a contrastive pre-training task that learns code functionality, not form. ContraCode pre-trains a neural network to identify functionally similar variants of a program among many non-equivalent distractors. We scalably generate these variants using an automated source-to-source compiler as a form of data augmentation. Contrastive pre-training outperforms RoBERTa on an adversarial code clone detection benchmark by 39{\%} AUROC. Surprisingly, improved adversarial robustness translates to better accuracy over natural code; ContraCode improves summarization and TypeScript type inference accuracy by 2 to 13 percentage points over competitive baselines. All source is available at \url{https://github.com/parasj/contracode}.}
}

@misc{springer2021strata,
  title         = {STRATA: Simple, Gradient-Free Attacks for Models of Code},
  author        = {Jacob M. Springer and Bryn Marie Reinstadler and Una-May O'Reilly},
  year          = {2021},
  eprint        = {2009.13562},
  archiveprefix = {arXiv},
  primaryclass  = {cs.LG}
}

@misc{abuhamad2023shield,
  title         = {SHIELD: Thwarting Code Authorship Attribution},
  author        = {Mohammed Abuhamad and Changhun Jung and David Mohaisen and DaeHun Nyang},
  year          = {2023},
  eprint        = {2304.13255},
  archiveprefix = {arXiv},
  primaryclass  = {cs.CR}
}

@inproceedings{RoPGen,
  author    = {Li, Zhen and Chen, Guenevere (Qian) and Chen, Chen and Zou, Yayi and Xu, Shouhuai},
  title     = {RoPGen: Towards Robust Code Authorship Attribution via Automatic Coding Style Transformation},
  year      = {2022},
  isbn      = {9781450392211},
  publisher = {Association for Computing Machinery},
  address   = {New York, NY, USA},
  url       = {https://doi.org/10.1145/3510003.3510181},
  doi       = {10.1145/3510003.3510181},
  abstract  = {Source code authorship attribution is an important problem often encountered in applications such as software forensics, bug fixing, and software quality analysis. Recent studies show that current source code authorship attribution methods can be compromised by attackers exploiting adversarial examples and coding style manipulation. This calls for robust solutions to the problem of code authorship attribution. In this paper, we initiate the study on making Deep Learning (DL)-based code authorship attribution robust. We propose an innovative framework called Robust coding style Patterns Generation (RoPGen), which essentially learns authors' unique coding style patterns that are hard for attackers to manipulate or imitate. The key idea is to combine data augmentation and gradient augmentation at the adversarial training phase. This effectively increases the diversity of training examples, generates meaningful perturbations to gradients of deep neural networks, and learns diversified representations of coding styles. We evaluate the effectiveness of RoPGen using four datasets of programs written in C, C++, and Java. Experimental results show that RoPGen can significantly improve the robustness of DL-based code authorship attribution, by respectively reducing 22.8\% and 41.0\% of the success rate of targeted and untargeted attacks on average.},
  booktitle = {Proceedings of the 44th International Conference on Software Engineering},
  pages     = {1906–1918},
  numpages  = {13},
  keywords  = {deep learning, authorship attribution, robustness, coding style, source code},
  location  = {Pittsburgh, Pennsylvania},
  series    = {ICSE '22}
}


@misc{codetrans,
  title         = {CodeTrans: Towards Cracking the Language of Silicon's Code Through Self-Supervised Deep Learning and High Performance Computing},
  author        = {Ahmed Elnaggar and Wei Ding and Llion Jones and Tom Gibbs and Tamas Feher and Christoph Angerer and Silvia Severini and Florian Matthes and Burkhard Rost},
  year          = {2021},
  eprint        = {2104.02443},
  archiveprefix = {arXiv},
  primaryclass  = {cs.SE}
}

@inproceedings{wang2021codet5,
  title     = {CodeT5: Identifier-aware Unified Pre-trained Encoder-Decoder Models for Code Understanding and Generation},
  author    = {Yue Wang and Weishi Wang and Shafiq Joty and Steven C.H. Hoi},
  booktitle = {Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing, EMNLP 2021},
  year      = {2021}
}

@misc{github2022codeql,
  author = {GitHub Inc.},
  title  = {GitHub CodeQL},
  year   = {2023},
  url    = {https://codeql.github.com/},
  note   = {Accessed: October, 2023}
}


@article{10.1145/3617367,
  author    = {Prather, James and Reeves, Brent N. and Denny, Paul and Becker, Brett A. and Leinonen, Juho and Luxton-Reilly, Andrew and Powell, Garrett and Finnie-Ansley, James and Santos, Eddie Antonio},
  title     = {“It's Weird That It Knows What I Want”: Usability and Interactions with Copilot for Novice Programmers},
  year      = {2023},
  publisher = {Association for Computing Machinery},
  address   = {New York, NY, USA},
  issn      = {1073-0516},
  url       = {https://doi.org/10.1145/3617367},
  doi       = {10.1145/3617367},
  note      = {Just Accepted},
  journal   = {ACM Trans. Comput.-Hum. Interact.},
  month     = {aug},
  keywords  = {Artificial Intelligence, GitHub, Novice Programming, Copilot, Large Language Models, OpenAI, Automatic Code Generation, CS1, LLM, Codex, HCI, Introductory Programming, AI, GPT-3}
}


@inproceedings{pmlr-v97-cohen19a,
  title     = {Empirical Analysis of Beam Search Performance Degradation in Neural Sequence Models},
  author    = {Cohen, Eldan and Beck, Christopher},
  booktitle = {Proceedings of the 36th International Conference on Machine Learning},
  pages     = {1290--1299},
  year      = {2019},
  editor    = {Chaudhuri, Kamalika and Salakhutdinov, Ruslan},
  volume    = {97},
  series    = {Proceedings of Machine Learning Research},
  month     = {09--15 Jun},
  publisher = {PMLR},
  pdf       = {http://proceedings.mlr.press/v97/cohen19a/cohen19a.pdf},
  url       = {https://proceedings.mlr.press/v97/cohen19a.html},
  abstract  = {Beam search is the most popular inference algorithm for decoding neural sequence models. Unlike greedy search, beam search allows for non-greedy local decisions that can potentially lead to a sequence with a higher overall probability. However, work on a number of applications has found that the quality of the highest probability hypothesis found by beam search degrades with large beam widths. We perform an empirical study of the behavior of beam search across three sequence synthesis tasks. We find that increasing the beam width leads to sequences that are disproportionately based on early, very low probability tokens that are followed by a sequence of tokens with higher (conditional) probability. We show that, empirically, such sequences are more likely to have a lower evaluation score than lower probability sequences without this pattern. Using the notion of search discrepancies from heuristic search, we hypothesize that large discrepancies are the cause of the performance degradation. We show that this hypothesis generalizes the previous ones in machine translation and image captioning. To validate our hypothesis, we show that constraining beam search to avoid large discrepancies eliminates the performance degradation.}
}




@inproceedings{liang2023usability,
  author    = {J. T. Liang and C. Yang and B. A. Myers},
  booktitle = {2024 IEEE/ACM 46th International Conference on Software Engineering (ICSE)},
  title     = {A Large-Scale Survey on the Usability of AI Programming Assistants: Successes and Challenges},
  year      = {2024},
  volume    = {},
  issn      = {1558-1225},
  pages     = {605-617},
  url       = {https://doi.ieeecomputersociety.org/},
  publisher = {IEEE Computer Society},
  address   = {Los Alamitos, CA, USA},
  month     = {apr}
}


@inproceedings{10.1145/3313831.3376442,
  author    = {Drosos, Ian and Barik, Titus and Guo, Philip J. and DeLine, Robert and Gulwani, Sumit},
  title     = {Wrex: A Unified Programming-by-Example Interaction for Synthesizing Readable Code for Data Scientists},
  year      = {2020},
  isbn      = {9781450367080},
  publisher = {Association for Computing Machinery},
  address   = {New York, NY, USA},
  url       = {https://doi-org.libproxy.smu.edu.sg/10.1145/3313831.3376442},
  doi       = {10.1145/3313831.3376442},
  abstract  = {Data wrangling is a difficult and time-consuming activity in computational notebooks, and existing wrangling tools do not fit the exploratory workflow for data scientists in these environments. We propose a unified interaction model based on programming-by-example that generates readable code for a variety of useful data transformations, implemented as a Jupyter notebook extension called Wrex. User study results demonstrate that data scientists are significantly more effective and efficient at data wrangling with Wrex over manual programming. Qualitative participant feedback indicates that Wrex was useful and reduced barriers in having to recall or look up the usage of various data transform functions. The synthesized code allowed data scientists to verify the intended data transformation, increased their trust and confidence in Wrex, and fit seamlessly within their cell-based notebook workflows. This work suggests that presenting readable code to professional data scientists is an indispensable component of offering data wrangling tools in notebooks.},
  booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
  pages     = {1–12},
  numpages  = {12},
  keywords  = {computational notebooks, data science, program synthesis},
  location  = {Honolulu, HI, USA},
  series    = {CHI '20}
}

@misc{alkaswan2023traces,
      title={Traces of Memorisation in Large Language Models for Code}, 
      author={Ali Al-Kaswan and Maliheh Izadi and Arie van Deursen},
      year={2023},
      eprint={2312.11658},
      archivePrefix={arXiv},
      primaryClass={cs.CR}
}

@article{10.1145/3591136,
  author     = {Bansal, Aakash and Sharif, Bonita and McMillan, Collin},
  title      = {Towards Modeling Human Attention from Eye Movements for Neural Source Code Summarization},
  year       = {2023},
  issue_date = {May 2023},
  publisher  = {Association for Computing Machinery},
  address    = {New York, NY, USA},
  volume     = {7},
  number     = {ETRA},
  url        = {https://doi-org.libproxy.smu.edu.sg/10.1145/3591136},
  doi        = {10.1145/3591136},
  abstract   = {Neural source code summarization is the task of generating natural language descriptions of source code behavior using neural networks. A fundamental component of most neural models is an attention mechanism. The attention mechanism learns to connect features in source code to specific words to use when generating natural language descriptions. Humans also pay attention to some features in code more than others. This human attention reflects experience and high-level cognition well beyond the capability of any current neural model. In this paper, we use data from published eye-tracking experiments to create a model of this human attention. The model predicts which words in source code are the most important for code summarization. Next, we augment a baseline neural code summarization approach using our model of human attention. We observe an improvement in prediction performance of the augmented approach in line with other bio-inspired neural models.},
  journal    = {Proc. ACM Hum.-Comput. Interact.},
  month      = {may},
  articleno  = {167},
  numpages   = {19},
  keywords   = {eye tracking, automatic documentation generation, bio-inspired models, source code summarization}
}

@misc{peng2023impact,
  title         = {The Impact of AI on Developer Productivity: Evidence from GitHub Copilot},
  author        = {Sida Peng and Eirini Kalliamvakou and Peter Cihon and Mert Demirer},
  year          = {2023},
  eprint        = {2302.06590},
  archiveprefix = {arXiv},
  primaryclass  = {cs.SE}
}

@inproceedings{10.1145/3544548.3580919,
  author    = {Kazemitabaar, Majeed and Chow, Justin and Ma, Carl Ka To and Ericson, Barbara J. and Weintrop, David and Grossman, Tovi},
  title     = {Studying the Effect of AI Code Generators on Supporting Novice Learners in Introductory Programming},
  year      = {2023},
  isbn      = {9781450394215},
  publisher = {Association for Computing Machinery},
  address   = {New York, NY, USA},
  url       = {https://doi.org/10.1145/3544548.3580919},
  doi       = {10.1145/3544548.3580919},
  abstract  = {AI code generators like OpenAI Codex have the potential to assist novice programmers by generating code from natural language descriptions, however, over-reliance might negatively impact learning and retention. To explore the implications that AI code generators have on introductory programming, we conducted a controlled experiment with 69 novices (ages 10-17). Learners worked on 45 Python code-authoring tasks, for which half of the learners had access to Codex, each followed by a code-modification task. Our results show that using Codex significantly increased code-authoring performance (1.15x increased completion rate and 1.8x higher scores) while not decreasing performance on manual code-modification tasks. Additionally, learners with access to Codex during the training phase performed slightly better on the evaluation post-tests conducted one week later, although this difference did not reach statistical significance. Of interest, learners with higher Scratch pre-test scores performed significantly better on retention post-tests, if they had prior access to Codex.},
  booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
  articleno = {455},
  numpages  = {23},
  keywords  = {Introductory Programming, GPT-3, Copilot, Large Language Models, AI-Assisted Pair-Programming, OpenAI Codex, K-12 Computer Science Education, ChatGPT, AI Coding Assistants},
  location  = {Hamburg, Germany},
  series    = {CHI '23}
}

@misc{mozannar2023reading,
  title         = {Reading Between the Lines: Modeling User Behavior and Costs in AI-Assisted Programming},
  author        = {Hussein Mozannar and Gagan Bansal and Adam Fourney and Eric Horvitz},
  year          = {2023},
  eprint        = {2210.14306},
  archiveprefix = {arXiv},
  primaryclass  = {cs.SE}
}

@article{Adam,
  title   = {Adam: A method for stochastic optimization},
  author  = {Kingma, Diederik P and Ba, Jimmy},
  journal = {arXiv preprint arXiv:1412.6980},
  year    = {2014}
}

@inproceedings{leblond-etal-2021-machine,
  title     = {Machine Translation Decoding beyond Beam Search},
  author    = {Leblond, R{\'e}mi  and
               Alayrac, Jean-Baptiste  and
               Sifre, Laurent  and
               Pislar, Miruna  and
               Jean-Baptiste, Lespiau  and
               Antonoglou, Ioannis  and
               Simonyan, Karen  and
               Vinyals, Oriol},
  booktitle = {Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing},
  month     = nov,
  year      = {2021},
  address   = {Online and Punta Cana, Dominican Republic},
  publisher = {Association for Computational Linguistics},
  url       = {https://aclanthology.org/2021.emnlp-main.662},
  doi       = {10.18653/v1/2021.emnlp-main.662},
  pages     = {8410--8434},
  abstract  = {Beam search is the go-to method for decoding auto-regressive machine translation models. While it yields consistent improvements in terms of BLEU, it is only concerned with finding outputs with high model likelihood, and is thus agnostic to whatever end metric or score practitioners care about. Our aim is to establish whether beam search can be replaced by a more powerful metric-driven search technique. To this end, we explore numerous decoding algorithms, including some which rely on a value function parameterised by a neural network, and report results on a variety of metrics. Notably, we introduce a Monte-Carlo Tree Search (MCTS) based method and showcase its competitiveness. We provide a blueprint for how to use MCTS fruitfully in language applications, which opens promising future directions. We find that which algorithm is best heavily depends on the characteristics of the goal metric; we believe that our extensive experiments and analysis will inform further research in this area.}
}

@inproceedings{lu-etal-2022-fantastically,
  title     = {Fantastically Ordered Prompts and Where to Find Them: Overcoming Few-Shot Prompt Order Sensitivity},
  author    = {Lu, Yao  and
               Bartolo, Max  and
               Moore, Alastair  and
               Riedel, Sebastian  and
               Stenetorp, Pontus},
  booktitle = {Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)},
  month     = may,
  year      = {2022},
  address   = {Dublin, Ireland},
  publisher = {Association for Computational Linguistics},
  url       = {https://aclanthology.org/2022.acl-long.556},
  doi       = {10.18653/v1/2022.acl-long.556},
  pages     = {8086--8098},
  abstract  = {When primed with only a handful of training samples, very large, pretrained language models such as GPT-3 have shown competitive results when compared to fully-supervised, fine-tuned, large, pretrained language models. We demonstrate that the order in which the samples are provided can make the difference between near state-of-the-art and random guess performance: essentially some permutations are {``}fantastic{''} and some not. We analyse this phenomenon in detail, establishing that: it is present across model sizes (even for the largest current models), it is not related to a specific subset of samples, and that a given good permutation for one model is not transferable to another. While one could use a development set to determine which permutations are performant, this would deviate from the true few-shot setting as it requires additional annotated data. Instead, we use the generative nature of language models to construct an artificial development set and based on entropy statistics of the candidate permutations on this set, we identify performant prompts. Our method yields a 13{\%} relative improvement for GPT-family models across eleven different established text classification tasks.}
}

@inproceedings{DeepDebug,
  author    = {Drain, Dawn and Wu, Chen and Svyatkovskiy, Alexey and Sundaresan, Neel},
  title     = {Generating Bug-Fixes Using Pretrained Transformers},
  year      = {2021},
  isbn      = {9781450384674},
  publisher = {Association for Computing Machinery},
  address   = {New York, NY, USA},
  url       = {https://doi.org/10.1145/3460945.3464951},
  doi       = {10.1145/3460945.3464951},
  booktitle = {Proceedings of the 5th ACM SIGPLAN International Symposium on Machine Programming},
  pages     = {1–8},
  numpages  = {8},
  keywords  = {program repair, bugpatching, bug-fixing, transformers},
  location  = {Virtual, Canada},
  series    = {MAPS 2021}
}

@inproceedings{bart,
  title     = {{BART}: Denoising Sequence-to-Sequence Pre-training for Natural Language Generation, Translation, and Comprehension},
  author    = {Lewis, Mike  and
               Liu, Yinhan  and
               Goyal, Naman  and
               Ghazvininejad, Marjan  and
               Mohamed, Abdelrahman  and
               Levy, Omer  and
               Stoyanov, Veselin  and
               Zettlemoyer, Luke},
  booktitle = {Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics},
  month     = jul,
  year      = {2020},
  address   = {Online},
  publisher = {Association for Computational Linguistics},
  url       = {https://aclanthology.org/2020.acl-main.703},
  doi       = {10.18653/v1/2020.acl-main.703},
  pages     = {7871--7880},
  abstract  = {We present BART, a denoising autoencoder for pretraining sequence-to-sequence models. BART is trained by (1) corrupting text with an arbitrary noising function, and (2) learning a model to reconstruct the original text. It uses a standard Tranformer-based neural machine translation architecture which, despite its simplicity, can be seen as generalizing BERT (due to the bidirectional encoder), GPT (with the left-to-right decoder), and other recent pretraining schemes. We evaluate a number of noising approaches, finding the best performance by both randomly shuffling the order of sentences and using a novel in-filling scheme, where spans of text are replaced with a single mask token. BART is particularly effective when fine tuned for text generation but also works well for comprehension tasks. It matches the performance of RoBERTa on GLUE and SQuAD, and achieves new state-of-the-art results on a range of abstractive dialogue, question answering, and summarization tasks, with gains of up to 3.5 ROUGE. BART also provides a 1.1 BLEU increase over a back-translation system for machine translation, with only target language pretraining. We also replicate other pretraining schemes within the BART framework, to understand their effect on end-task performance.}
}

@misc{palm,
  title         = {PaLM: Scaling Language Modeling with Pathways},
  author        = {Aakanksha Chowdhery and Sharan Narang and Jacob Devlin and Maarten Bosma and Gaurav Mishra and Adam Roberts and Paul Barham and Hyung Won Chung and Charles Sutton and Sebastian Gehrmann and Parker Schuh and Kensen Shi and Sasha Tsvyashchenko and Joshua Maynez and Abhishek Rao and Parker Barnes and Yi Tay and Noam Shazeer and Vinodkumar Prabhakaran and Emily Reif and Nan Du and Ben Hutchinson and Reiner Pope and James Bradbury and Jacob Austin and Michael Isard and Guy Gur-Ari and Pengcheng Yin and Toju Duke and Anselm Levskaya and Sanjay Ghemawat and Sunipa Dev and Henryk Michalewski and Xavier Garcia and Vedant Misra and Kevin Robinson and Liam Fedus and Denny Zhou and Daphne Ippolito and David Luan and Hyeontaek Lim and Barret Zoph and Alexander Spiridonov and Ryan Sepassi and David Dohan and Shivani Agrawal and Mark Omernick and Andrew M. Dai and Thanumalayan Sankaranarayana Pillai and Marie Pellat and Aitor Lewkowycz and Erica Moreira and Rewon Child and Oleksandr Polozov and Katherine Lee and Zongwei Zhou and Xuezhi Wang and Brennan Saeta and Mark Diaz and Orhan Firat and Michele Catasta and Jason Wei and Kathy Meier-Hellstern and Douglas Eck and Jeff Dean and Slav Petrov and Noah Fiedel},
  year          = {2022},
  eprint        = {2204.02311},
  archiveprefix = {arXiv},
  primaryclass  = {cs.CL}
}

@inproceedings{plbart,
  title     = {Unified Pre-training for Program Understanding and Generation},
  author    = {Ahmad, Wasi  and
               Chakraborty, Saikat  and
               Ray, Baishakhi  and
               Chang, Kai-Wei},
  booktitle = {Proceedings of the 2021 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies},
  month     = jun,
  year      = {2021},
  address   = {Online},
  publisher = {Association for Computational Linguistics},
  pages     = {2655--2668}
}

@article{pile,
  title   = {The {P}ile: An 800GB Dataset of Diverse Text for Language Modeling},
  author  = {Gao, Leo and Biderman, Stella and Black, Sid and Golding, Laurence and Hoppe, Travis and Foster, Charles and Phang, Jason and He, Horace and Thite, Anish and Nabeshima, Noa and Presser, Shawn and Leahy, Connor},
  journal = {arXiv preprint arXiv:2101.00027},
  year    = {2020}
}

@inproceedings{santacoder,
  title         = {SantaCoder: don't reach for the stars!},
  author        = {Loubna Ben Allal and Raymond Li and Denis Kocetkov et al.},
  year          = {2023},
  eprint        = {2301.03988},
  archiveprefix = {arXiv},
  primaryclass  = {cs.SE}
}

@article{arakelyan2023exploring,
  title   = {Exploring Distributional Shifts in Large Language Models for Code Analysis},
  author  = {Arakelyan, Shushan and Das, Rocktim Jyoti and Mao, Yi and Ren, Xiang},
  journal = {arXiv preprint arXiv:2303.09128},
  year    = {2023}
}

@article{mukherjee2023stack,
  title   = {Stack Over-Flowing with Results: The Case for Domain-Specific Pre-Training Over One-Size-Fits-All Models},
  author  = {Mukherjee, Manisha and Hellendoorn, Vincent J},
  journal = {arXiv preprint arXiv:2306.03268},
  year    = {2023}
}

@article{li2023codeie,
  title   = {CodeIE: Large Code Generation Models are Better Few-Shot Information Extractors},
  author  = {Li, Peng and Sun, Tianxiang and Tang, Qiong and Yan, Hang and Wu, Yuanbin and Huang, Xuanjing and Qiu, Xipeng},
  journal = {arXiv preprint arXiv:2305.05711},
  year    = {2023}
}

@inproceedings{9825884,
  author    = {C. Yang and B. Xu and J. Khan and G. Uddin and D. Han and Z. Yang and D. Lo},
  booktitle = {2022 IEEE International Conference on Software Analysis, Evolution and Reengineering (SANER)},
  title     = {Aspect-Based API Review Classification: How Far Can Pre-Trained Transformer Model Go?},
  year      = {2022},
  volume    = {},
  issn      = {1534-5351},
  pages     = {385-395},
  abstract  = {APIs (Application Programming Interfaces) are reusable software libraries and are building blocks for modern rapid software development. Previous research shows that programmers frequently share and search for reviews of APIs on the mainstream software question and answer (Q&amp;#x0026;A) platforms like Stack Overflow, which motivates researchers to design tasks and approaches related to process API reviews automatically. Among these tasks, classifying API reviews into different aspects (e.g., performance or security), which is called the aspect-based API review classification, is of great importance. The current state-of-the-art (SOTA) solution to this task is based on the traditional machine learning algorithm. Inspired by the great success achieved by pre-trained models on many software engineering tasks, this study fine-tunes six pre-trained models for the aspect-based API review classification task and compares them with the current SOTA solution on an API review benchmark collected by Uddin et al. The investigated models include four models (BERT, RoBERTa, ALBERT and XLNet) that are pre-trained on natural languages, BERTOverflow that is pre-trained on text corpus extracted from posts on Stack Overflow, and CosSensBERT that is designed for handling imbalanced data. The results show that all the six fine-tuned models outperform the traditional machine learning-based tool. More specifically, the improvement on the F1-score ranges from 21.0&amp;#x0025; to 30.2&amp;#x0025;. We also find that BERTOverflow, a model pre-trained on the corpus from Stack Overflow, does not show better performance than BERT. The result also suggests that CosSensBERT also does not exhibit better performance than BERT in terms of F1, but it is still worthy of being considered as it achieves better performance on MCC and AUC.},
  keywords  = {software libraries;machine learning algorithms;bit error rate;natural languages;transformers;software;data models},
  doi       = {10.1109/SANER53432.2022.00054},
  url       = {https://doi.ieeecomputersociety.org/10.1109/SANER53432.2022.00054},
  publisher = {IEEE Computer Society},
  address   = {Los Alamitos, CA, USA},
  month     = {mar}
}

@book{transformerbook,
  title     = {Natural language processing with transformers},
  author    = {Tunstall, Lewis and Von Werra, Leandro and Wolf, Thomas},
  year      = {2022},
  publisher = {" O'Reilly Media, Inc."}
}

@article{hinton2006fast,
  title     = {A fast learning algorithm for deep belief nets},
  author    = {Hinton, Geoffrey E and Osindero, Simon and Teh, Yee-Whye},
  journal   = {Neural computation},
  volume    = {18},
  number    = {7},
  pages     = {1527--1554},
  year      = {2006},
  publisher = {MIT Press One Rogers Street, Cambridge, MA 02142-1209, USA journals-info~…}
}

@misc{codeparrot,
  title        = {codeparrot (CodeParrot)},
  url          = {https://huggingface.co/codeparrot},
  urldate      = {2023-05-05},
  organization = {huggingface.co}
}

@article{murali2023codecompose,
  title   = {CodeCompose: A Large-Scale Industrial Deployment of AI-assisted Code Authoring},
  author  = {Murali, Vijayaraghavan and Maddila, Chandra and Ahmad, Imad and Bolin, Michael and Cheng, Daniel and Ghorbani, Negar and Fernandez, Renuka and Nagappan, Nachiappan},
  journal = {arXiv preprint arXiv:2305.12050},
  year    = {2023}
}

@misc{codeparrotrepo,
  title        = {Code for Transformer},
  url          = {https://github.com/huggingface/blog/blob/main/codeparrot.md},
  urldate      = {2023-05-05},
  organization = {huggingface.co}
}

@misc{ptmtorrent,
  title         = {PTMTorrent: A Dataset for Mining Open-source Pre-trained Model Packages},
  author        = {Wenxin Jiang and Nicholas Synovic and Purvish Jajal and Taylor R. Schorlemmer and Arav Tewari and Bhavesh Pareek and George K. Thiruvathukal and James C. Davis},
  year          = {2023},
  eprint        = {2303.08934},
  archiveprefix = {arXiv},
  primaryclass  = {cs.SE}
}

@misc{jiang2023empirical,
  title         = {An Empirical Study of Pre-Trained Model Reuse in the Hugging Face Deep Learning Model Registry},
  author        = {Wenxin Jiang and Nicholas Synovic and Matt Hyatt and Taylor R. Schorlemmer and Rohan Sethi and Yung-Hsiang Lu and George K. Thiruvathukal and James C. Davis},
  year          = {2023},
  eprint        = {2303.02552},
  archiveprefix = {arXiv},
  primaryclass  = {cs.SE}
}

@misc{carlini2023poisoning,
  title         = {Poisoning Web-Scale Training Datasets is Practical},
  author        = {Nicholas Carlini and Matthew Jagielski and Christopher A. Choquette-Choo and Daniel Paleka and Will Pearce and Hyrum Anderson and Andreas Terzis and Kurt Thomas and Florian Tramèr},
  year          = {2023},
  eprint        = {2302.10149},
  archiveprefix = {arXiv},
  primaryclass  = {cs.CR}
}

@inproceedings{jiang2022empirical,
  title     = {An Empirical Study of Artifacts and Security Risks in the Pre-trained Model Supply Chain},
  author    = {Jiang, Wenxin and Synovic, Nicholas and Sethi, Rohan and Indarapu, Aryan and Hyatt, Matt and Schorlemmer, Taylor R and Thiruvathukal, George K and Davis, James C},
  booktitle = {Proceedings of the 2022 ACM Workshop on Software Supply Chain Offensive Research and Ecosystem Defenses},
  pages     = {105--114},
  year      = {2022}
}



@inproceedings{davis2023empirical,
  title     = {Reusing Deep Learning Models: Challenges and
               Directions in Software Engineering},
  author    = {Davis, James C. and Jajal, Purvish and Jiang, Wenxin and Schorlemmer, Taylor R. and Synovic, Nicholas and Thiruvathukal, George K.},
  booktitle = {Proceedings of the IEEE John Vincent Atanasoff Symposium on Modern Computing (JVA'23) },
  year      = {2023}
}

@misc{he2023representation,
  title         = {Representation Learning for Stack Overflow Posts: How Far are We?},
  author        = {Junda He and Zhou Xin and Bowen Xu and Ting Zhang and Kisub Kim and Zhou Yang and Ferdian Thung and Ivana Irsan and David Lo},
  year          = {2023},
  eprint        = {2303.06853},
  archiveprefix = {arXiv},
  primaryclass  = {cs.SE}
}

@misc{the-stack,
  title         = {The Stack: 3 TB of permissively licensed source code},
  author        = {Denis Kocetkov and Raymond Li and Loubna Ben Allal and Jia Li and Chenghao Mou and Carlos Muñoz Ferrandis and Yacine Jernite and Margaret Mitchell and Sean Hughes and Thomas Wolf and Dzmitry Bahdanau and Leandro von Werra and Harm de Vries},
  year          = {2022},
  eprint        = {2211.15533},
  archiveprefix = {arXiv},
  primaryclass  = {cs.CL}
}

@inbook{TechSumBot,
  author    = {Yang, Chengran and Xu, Bowen and Thung, Ferdian and Shi, Yucen and Zhang, Ting and Yang, Zhou and Zhou, Xin and Shi, Jieke and He, Junda and Han, Donggyun and Lo, David},
  title     = {Answer Summarization for Technical Queries: Benchmark and New Approach},
  year      = {2023},
  isbn      = {9781450394758},
  publisher = {Association for Computing Machinery},
  address   = {New York, NY, USA},
  url       = {https://doi.org/10.1145/3551349.3560421},
  abstract  = {Prior studies have demonstrated that approaches to generate an answer summary for a given technical query in Software Question and Answer (SQA) sites are desired. We find that existing approaches are assessed solely through user studies. Hence, a new user study needs to be performed every time a new approach is introduced; this is time-consuming, slows down the development of the new approach, and results from different user studies may not be comparable to each other. There is a need for a benchmark with ground truth summaries as a complement assessment through user studies. Unfortunately, such a benchmark is non-existent for answer summarization for technical queries from SQA sites. To fill the gap, we manually construct a high-quality benchmark to enable automatic evaluation of answer summarization for the technical queries for SQA sites. It contains 111 query-summary pairs extracted from 382 Stack Overflow answers with 2,014 sentence candidates. Using the benchmark, we comprehensively evaluate the performance of existing approaches and find that there is still a big room for improvements.Motivated by the results, we propose a new approach TechSumBot with three key modules:1) Usefulness Ranking module; 2) Centrality Estimation module; and 3) Redundancy Removal module. We evaluate TechSumBot in both automatic (i.e., using our benchmark) and manual (i.e., via a user study) manners. The results from both evaluations consistently demonstrate that TechSumBot outperforms the best performing baseline approaches from both SE and NLP domains by a large margin, i.e., 10.83%–14.90%, 32.75%–36.59%, and 12.61%–17.54%, in terms of ROUGE-1, ROUGE-2, and ROUGE-L on automatic evaluation, and 5.79%–9.23% and 17.03%–17.68%, in terms of average usefulness and diversity score on human evaluation. This highlights that automatic evaluation on our benchmark can uncover findings similar to the ones found through user studies. More importantly, the automatic evaluation has a much lower cost, especially when it is used to assess a new approach. Additionally, we also conducted an ablation study, which demonstrates that each module in TechSumBot contributes to boosting the overall performance of TechSumBot. We release the benchmark as well as the replication package of our experiment at https://github.com/TechSumBot/TechSumBot.},
  booktitle = {Proceedings of the 37th IEEE/ACM International Conference on Automated Software Engineering},
  articleno = {8},
  numpages  = {13}
}


@inproceedings{zhou2023ccbert,
  author    = {X. Zhou and B. Xu and D. Han and Z. Yang and J. He and D. Lo},
  booktitle = {2023 IEEE International Conference on Software Maintenance and Evolution (ICSME)},
  title     = {CCBERT: Self-Supervised Code Change Representation Learning},
  year      = {2023},
  volume    = {},
  issn      = {},
  pages     = {182-193},
  abstract  = {Numerous code changes are made by developers in their daily work, and a superior representation of code changes is desired for effective code change analysis. Recently, Hoang et al. proposed CC2Vec, a neural network-based approach that learns a distributed representation of code changes to capture the semantic intent of the changes. Despite demonstrated effectiveness in multiple tasks, CC2Vec has several limitations: 1) it considers only coarse-grained information about code changes, and 2) it relies on log messages rather than the self-contained content of the code changes. In this work, we propose CCBERT (Code Change BERT), a new Transformer-based pre-trained model that learns a generic representation of code changes based on a large-scale dataset containing massive unlabeled code changes. CCBERT is pre-trained on four proposed self-supervised objectives that are specialized for learning code change representations based on the contents of code changes. CCBERT perceives fine-grained code changes at the token level by learning from the old and new versions of the content, along with the edit actions. Our experiments demonstrate that CCBERT significantly outperforms CC2Vec or the state-of-the-art approaches of the downstream tasks by 7.7%–14.0% in terms of different metrics and tasks. CCBERT consistently outperforms large pre-trained code models, such as CodeBERT, while requiring 6–10× less training time, 5–30× less inference time, and 7.9× less GPU memory.},
  keywords  = {training;measurement;representation learning;software maintenance;codes;memory management;semantics},
  doi       = {10.1109/ICSME58846.2023.00028},
  url       = {https://doi.ieeecomputersociety.org/10.1109/ICSME58846.2023.00028},
  publisher = {IEEE Computer Society},
  address   = {Los Alamitos, CA, USA},
  month     = {oct}
}


@inproceedings{PTM4TAG,
  author    = {He, Junda and Xu, Bowen and Yang, Zhou and Han, DongGyun and Yang, Chengran and Lo, David},
  title     = {PTM4Tag: Sharpening Tag Recommendation of Stack Overflow Posts with Pre-Trained Models},
  year      = {2022},
  isbn      = {9781450392983},
  publisher = {Association for Computing Machinery},
  address   = {New York, NY, USA},
  url       = {https://doi.org/10.1145/3524610.3527897},
  doi       = {10.1145/3524610.3527897},
  pages     = {1–11},
  numpages  = {11},
  keywords  = {transformer, tag recommendation, pre-trained models},
  location  = {Virtual Event},
  series    = {ICPC '22}
}

@article{pudari2023copilot,
  title   = {From Copilot to Pilot: Towards AI Supported Software Development},
  author  = {Pudari, Rohith and Ernst, Neil A},
  journal = {arXiv preprint arXiv:2303.04142},
  year    = {2023}
}

@inproceedings{li2022coderetriever,
  title     = {CodeRetriever: A Large Scale Contrastive Pre-Training Method for Code Search},
  author    = {Li, Xiaonan and Gong, Yeyun and Shen, Yelong and Qiu, Xipeng and Zhang, Hang and Yao, Bolun and Qi, Weizhen and Jiang, Daxin and Chen, Weizhu and Duan, Nan},
  booktitle = {Proceedings of the 2022 Conference on Empirical Methods in Natural Language Processing},
  pages     = {2898--2910},
  year      = {2022}
}

@inproceedings{sghaier2023multi,
  title        = {A Multi-Step Learning Approach to Assist Code Review},
  author       = {Sghaier, Oussama Ben and Sahraoui, Houari},
  booktitle    = {2023 IEEE International Conference on Software Analysis, Evolution and Reengineering (SANER)},
  pages        = {450--460},
  year         = {2023},
  organization = {IEEE}
}


@inproceedings{bertoverflow,
  title     = {Code and Named Entity Recognition in {S}tack{O}verflow},
  author    = {Tabassum, Jeniya  and
               Maddela, Mounica  and
               Xu, Wei  and
               Ritter, Alan},
  booktitle = {Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics},
  month     = jul,
  year      = {2020},
  address   = {Online},
  publisher = {Association for Computational Linguistics},
  url       = {https://aclanthology.org/2020.acl-main.443},
  doi       = {10.18653/v1/2020.acl-main.443},
  pages     = {4913--4926},
  abstract  = {There is an increasing interest in studying natural language and computer code together, as large corpora of programming texts become readily available on the Internet. For example, StackOverflow currently has over 15 million programming related questions written by 8.5 million users. Meanwhile, there is still a lack of fundamental NLP techniques for identifying code tokens or software-related named entities that appear within natural language sentences. In this paper, we introduce a new named entity recognition (NER) corpus for the computer programming domain, consisting of 15,372 sentences annotated with 20 fine-grained entity types. We trained in-domain BERT representations (BERTOverflow) on 152 million sentences from StackOverflow, which lead to an absolute increase of +10 F1 score over off-the-shelf BERT. We also present the SoftNER model which achieves an overall 79.10 F-1 score for code and named entity recognition on StackOverflow data. Our SoftNER model incorporates a context-independent code token classifier with corpus-level features to improve the BERT-based tagging model. Our code and data are available at: https://github.com/jeniyat/StackOverflowNER/}
}

@misc{vasconcelos2023generation,
  title         = {Generation Probabilities Are Not Enough: Exploring the Effectiveness of Uncertainty Highlighting in AI-Powered Code Completions},
  author        = {Helena Vasconcelos and Gagan Bansal and Adam Fourney and Q. Vera Liao and Jennifer Wortman Vaughan},
  year          = {2023},
  eprint        = {2302.07248},
  archiveprefix = {arXiv},
  primaryclass  = {cs.HC}
}

@misc{tian2023chatgpt,
  title         = {Is ChatGPT the Ultimate Programming Assistant -- How far is it?},
  author        = {Haoye Tian and Weiqi Lu and Tsz On Li and Xunzhu Tang and Shing-Chi Cheung and Jacques Klein and Tegawendé F. Bissyandé},
  year          = {2023},
  eprint        = {2304.11938},
  archiveprefix = {arXiv},
  primaryclass  = {cs.SE}
}

@inproceedings{10.1145/3510454.3522684,
  author    = {Imai, Saki},
  title     = {Is GitHub Copilot a Substitute for Human Pair-Programming? An Empirical Study},
  year      = {2022},
  isbn      = {9781450392235},
  publisher = {Association for Computing Machinery},
  address   = {New York, NY, USA},
  url       = {https://doi.org/10.1145/3510454.3522684},
  doi       = {10.1145/3510454.3522684},
  abstract  = {This empirical study investigates the effectiveness of pair programming with GitHub Copilot in comparison to human pair-programming. Through an experiment with 21 participants we focus on code productivity and code quality. For experimental design, a participant was given a project to code, under three conditions presented in a randomized order. The conditions are pair-programming with Copilot, human pair-programming as a driver, and as a navigator. The codes generated from the three trials were analyzed to determine how many lines of code on average were added in each condition and how many lines of code on average were removed in the subsequent stage. The former measures the productivity of each condition while the latter measures the quality of the produced code. The results suggest that although Copilot increases productivity as measured by lines of code added, the quality of code produced is inferior by having more lines of code deleted in the subsequent trial.},
  booktitle = {Proceedings of the ACM/IEEE 44th International Conference on Software Engineering: Companion Proceedings},
  pages     = {319–321},
  numpages  = {3},
  keywords  = {copilot, GitHub, AI, software development},
  location  = {Pittsburgh, Pennsylvania},
  series    = {ICSE '22}
}

@misc{github2021copilot,
  title        = {Github copilot},
  author       = {GitHub},
  howpublished = {\url{ https://copilot.github.com}},
  year         = {2023}
}


@inproceedings{10.1145/3520312.3534864,
  author    = {Ziegler, Albert and Kalliamvakou, Eirini and Li, X. Alice and Rice, Andrew and Rifkin, Devon and Simister, Shawn and Sittampalam, Ganesh and Aftandilian, Edward},
  title     = {Productivity Assessment of Neural Code Completion},
  year      = {2022},
  isbn      = {9781450392730},
  publisher = {Association for Computing Machinery},
  address   = {New York, NY, USA},
  url       = {https://doi.org/10.1145/3520312.3534864},
  doi       = {10.1145/3520312.3534864},
  abstract  = {Neural code synthesis has reached a point where snippet generation is accurate enough to be considered for integration into human software development workflows. Commercial products aim to increase programmers’ productivity, without being able to measure it directly. In this case study, we asked users of GitHub Copilot about its impact on their productivity, and sought to find a reflection of their perception in directly measurable user data. We find that the rate with which shown suggestions are accepted, rather than more specific metrics regarding the persistence of completions in the code over time, drives developers’ perception of productivity.},
  booktitle = {Proceedings of the 6th ACM SIGPLAN International Symposium on Machine Programming},
  pages     = {21–29},
  numpages  = {9},
  keywords  = {productivity, code completion, neural networks, code synthesis},
  location  = {San Diego, CA, USA},
  series    = {MAPS 2022}
}

@inproceedings{Zhang_2023,
  doi       = {10.18293/seke2023-077},
  url       = {https://doi.org/10.18293%2Fseke2023-077},
  year      = 2023,
  month     = {jul},
  publisher = {{KSI} Research Inc.},
  author    = {Beiqi Zhang and Peng Liang and Xiyu Zhou and Aakash Ahmad and Muhammad Waseem},
  title     = {Practices and Challenges of Using {GitHub} Copilot: An Empirical Study},
  booktitle = {International Conferences on Software Engineering and Knowledge Engineering}
}

@inproceedings{li-liang-2021-prefix,
  title     = {Prefix-Tuning: Optimizing Continuous Prompts for Generation},
  author    = {Li, Xiang Lisa  and
               Liang, Percy},
  editor    = {Zong, Chengqing  and
               Xia, Fei  and
               Li, Wenjie  and
               Navigli, Roberto},
  booktitle = {Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing (Volume 1: Long Papers)},
  month     = aug,
  year      = {2021},
  address   = {Online},
  publisher = {Association for Computational Linguistics},
  url       = {https://aclanthology.org/2021.acl-long.353},
  doi       = {10.18653/v1/2021.acl-long.353},
  pages     = {4582--4597},
  abstract  = {Fine-tuning is the de facto way of leveraging large pretrained language models for downstream tasks. However, fine-tuning modifies all the language model parameters and therefore necessitates storing a full copy for each task. In this paper, we propose prefix-tuning, a lightweight alternative to fine-tuning for natural language generation tasks, which keeps language model parameters frozen and instead optimizes a sequence of continuous task-specific vectors, which we call the prefix. Prefix-tuning draws inspiration from prompting for language models, allowing subsequent tokens to attend to this prefix as if it were {``}virtual tokens{''}. We apply prefix-tuning to GPT-2 for table-to-text generation and to BART for summarization. We show that by learning only 0.1{\%} of the parameters, prefix-tuning obtains comparable performance in the full data setting, outperforms fine-tuning in low-data settings, and extrapolates better to examples with topics that are unseen during training.}
}

@inproceedings{10.1145/3526113.3545659,
  author    = {Jayagopal, Dhanya and Lubin, Justin and Chasins, Sarah E.},
  title     = {Exploring the Learnability of Program Synthesizers by Novice Programmers},
  year      = {2022},
  isbn      = {9781450393201},
  publisher = {Association for Computing Machinery},
  address   = {New York, NY, USA},
  url       = {https://doi.org/10.1145/3526113.3545659},
  doi       = {10.1145/3526113.3545659},
  abstract  = {Modern program synthesizers are increasingly delivering on their promise of lightening the burden of programming by automatically generating code, but little research has addressed how we can make such systems learnable to all. In this work, we ask: What aspects of program synthesizers contribute to and detract from their learnability by novice programmers? We conducted a thematic analysis of 22 observations of novice programmers, during which novices worked with existing program synthesizers, then participated in semi-structured interviews. Our findings shed light on how their specific points in the synthesizer design space affect these tools’ learnability by novice programmers, including the type of specification the synthesizer requires, the method of invoking synthesis and receiving feedback, and the size of the specification. We also describe common misconceptions about what constitutes meaningful progress and useful specifications for the synthesizers, as well as participants’ common behaviors and strategies for using these tools. From this analysis, we offer a set of design opportunities to inform the design of future program synthesizers that strive to be learnable by novice programmers. This work serves as a first step toward understanding how we can make program synthesizers more learnable by novices, which opens up the possibility of using program synthesizers in educational settings as well as developer tooling oriented toward novice programmers.},
  booktitle = {Proceedings of the 35th Annual ACM Symposium on User Interface Software and Technology},
  articleno = {64},
  numpages  = {15},
  keywords  = {qualitative, program synthesis, thematic analysis, learnability, novice programmers},
  location  = {Bend, OR, USA},
  series    = {UIST '22}
}

@inproceedings{10.1145/3491101.3519665,
  author    = {Vaithilingam, Priyan and Zhang, Tianyi and Glassman, Elena L.},
  title     = {Expectation vs. Experience: Evaluating the Usability of Code Generation Tools Powered by Large Language Models},
  year      = {2022},
  isbn      = {9781450391566},
  publisher = {Association for Computing Machinery},
  address   = {New York, NY, USA},
  url       = {https://doi.org/10.1145/3491101.3519665},
  doi       = {10.1145/3491101.3519665},
  abstract  = {Recent advances in Large Language Models (LLM) have made automatic code generation possible for real-world programming tasks in general-purpose programming languages such as Python. However, there are few human studies on the usability of these tools and how they fit the programming workflow. In this work, we conducted a within-subjects user study with 24 participants to understand how programmers use and perceive Copilot, a LLM-based code generation tool. We found that, while Copilot did not necessarily improve the task completion time or success rate, most participants preferred to use Copilot in daily programming tasks, since Copilot often provided a useful starting point and saved the effort of searching online. However, participants did face difficulties in understanding, editing, and debugging code snippets generated by Copilot, which significantly hindered their task-solving effectiveness. Finally, we highlighted several promising directions for improving the design of Copilot based on our observations and participants’ feedback.},
  booktitle = {Extended Abstracts of the 2022 CHI Conference on Human Factors in Computing Systems},
  articleno = {332},
  numpages  = {7},
  keywords  = {large language model, github copilot},
  location  = {New Orleans, LA, USA},
  series    = {CHI EA '22}
}

@inproceedings{quantifying,
  title     = {Quantifying Privacy Risks of Masked Language Models Using Membership Inference Attacks},
  author    = {Mireshghallah, Fatemehsadat  and
               Goyal, Kartik  and
               Uniyal, Archit  and
               Berg-Kirkpatrick, Taylor  and
               Shokri, Reza},
  booktitle = {Proceedings of the 2022 Conference on Empirical Methods in Natural Language Processing},
  month     = dec,
  year      = {2022},
  address   = {Abu Dhabi, United Arab Emirates},
  publisher = {Association for Computational Linguistics},
  url       = {https://aclanthology.org/2022.emnlp-main.570},
  pages     = {8332--8347},
  abstract  = {The wide adoption and application of Masked language models (MLMs) on sensitive data (from legal to medical) necessitates a thorough quantitative investigation into their privacy vulnerabilities. Prior attempts at measuring leakage of MLMs via membership inference attacks have been inconclusive, implying potential robustness of MLMs to privacy attacks.In this work, we posit that prior attempts were inconclusive because they based their attack solely on the MLM{'}s model score. We devise a stronger membership inference attack based on likelihood ratio hypothesis testing that involves an additional reference MLM to more accurately quantify the privacy risks of memorization in MLMs. We show that masked language models are indeed susceptible to likelihood ratio membership inference attacks: Our empirical results, on models trained on medical notes, show that our attack improves the AUC of prior membership inference attacks from 0.66 to an alarmingly high 0.90 level.}
}

@article{10.1007/s10664-021-10057-7,
  author     = {Gold, Nicolas E. and Krinke, Jens},
  title      = {Ethics in the Mining of Software Repositories},
  year       = {2022},
  issue_date = {Jan 2022},
  publisher  = {Kluwer Academic Publishers},
  address    = {USA},
  volume     = {27},
  number     = {1},
  issn       = {1382-3256},
  url        = {https://doi.org/10.1007/s10664-021-10057-7},
  doi        = {10.1007/s10664-021-10057-7},
  abstract   = {Research in Mining Software Repositories (MSR) is research involving human subjects, as the repositories usually contain data about developers’ and users’ interactions with the repositories and with each other. The ethics issues raised by such research therefore need to be considered before beginning. This paper presents a discussion of ethics issues that can arise in MSR research, using the mining challenges from the years 2006 to 2021 as a case study to identify the kinds of data used. On the basis of contemporary research ethics frameworks we discuss ethics challenges that may be encountered in creating and using repositories and associated datasets. We also report some results from a small community survey of approaches to ethics in MSR research. In addition, we present four case studies illustrating typical ethics issues one encounters in projects and how ethics considerations can shape projects before they commence. Based on our experience, we present some guidelines and practices that can help in considering potential ethics issues and reducing risks.},
  journal    = {Empirical Softw. Engg.},
  month      = {jan},
  numpages   = {49},
  keywords   = {Mining software repositories, Research ethics}
}

@inproceedings{10.1145/3379597.3387462,
  author    = {Gold, Nicolas E. and Krinke, Jens},
  title     = {Ethical Mining: A Case Study on MSR Mining Challenges},
  year      = {2020},
  isbn      = {9781450375177},
  publisher = {Association for Computing Machinery},
  address   = {New York, NY, USA},
  url       = {https://doi.org/10.1145/3379597.3387462},
  doi       = {10.1145/3379597.3387462},
  abstract  = {Research in Mining Software Repositories (MSR) is research involving human subjects, as the repositories usually contain data about developers' interactions with the repositories. Therefore, any research in the area needs to consider the ethics implications of the intended activity before starting. This paper presents a discussion of the ethics implications of MSR research, using the mining challenges from the years 2010 to 2019 as a case study to identify the kinds of data used. It highlights problems that one may encounter in creating such datasets, and discusses ethics challenges that may be encountered when using existing datasets, based on a contemporary research ethics framework. We suggest that the MSR community should increase awareness of ethics issues by openly discussing ethics considerations in published articles.},
  booktitle = {Proceedings of the 17th International Conference on Mining Software Repositories},
  pages     = {265–276},
  numpages  = {12},
  keywords  = {mining software repositories, research ethics},
  location  = {Seoul, Republic of Korea},
  series    = {MSR '20}
}

@misc{yang2023memorzation,
  title         = {What Do Code Models Memorize? An Empirical Study on Large Language Models of Code},
  author        = {Zhou Yang and Zhipeng Zhao and Chenyu Wang and Jieke Shi and Dongsun Kim and DongGyun Han and David Lo},
  year          = {2023},
  eprint        = {2308.09932},
  archiveprefix = {arXiv},
  primaryclass  = {cs.SE}
}

@inproceedings{acsac2022gong,
  author    = {Gong, Chen and Yang, Zhou and Bai, Yunpeng and Shi, Jieke and Sinha, Arunesh and Xu, Bowen and Lo, David and Hou, Xinwen and Fan, Guoliang},
  title     = {Curiosity-Driven and Victim-Aware Adversarial Policies},
  year      = {2022},
  isbn      = {9781450397599},
  publisher = {Association for Computing Machinery},
  address   = {New York, NY, USA},
  url       = {https://doi.org/10.1145/3564625.3564636},
  doi       = {10.1145/3564625.3564636},
  abstract  = {Recent years have witnessed great potential in applying Deep Reinforcement Learning (DRL) in various challenging applications, such as autonomous driving, nuclear fusion control, complex game playing, etc. However, recently researchers have revealed that deep reinforcement learning models are vulnerable to adversarial attacks: malicious attackers can train adversarial policies to tamper with the observations of a well-trained victim agent, the latter of which fails dramatically when faced with such an attack. Understanding and improving the adversarial robustness of deep reinforcement learning is of great importance in enhancing the quality and reliability of a wide range of DRL-enabled systems. In this paper, we develop curiosity-driven and victim-aware adversarial policy training, a novel method that can more effectively exploit the defects of victim agents. To be victim-aware, we build a surrogate network that can approximate the state-value function of a black-box victim to collect the victim’s information. Then we propose a curiosity-driven approach, which encourages an adversarial policy to utilize the information from the hidden layer of the surrogate network to exploit the vulnerability of victims efficiently. Extensive experiments demonstrate that our proposed method outperforms or achieves a similar level of performance as the current state-of-the-art across multiple environments. We perform an ablation study to emphasize the benefits of utilizing the approximated victim information. Further analysis suggests that our method is harder to defend against a commonly used defensive strategy, which calls attention to more effective protection on the systems using DRL.},
  booktitle = {Proceedings of the 38th Annual Computer Security Applications Conference},
  pages     = {186–200},
  numpages  = {15},
  keywords  = {Adversarial Attack, Reinforcement Learning, Curiosity Mechanism},
  location  = {Austin, TX, USA},
  series    = {ACSAC '22}
}

@inproceedings{gu-2022-accelerating,
  title     = {Accelerating Code Search with Deep Hashing and Code Classification},
  author    = {Gu, Wenchao  and
               Wang, Yanlin  and
               Du, Lun  and
               Zhang, Hongyu  and
               Han, Shi  and
               Zhang, Dongmei  and
               Lyu, Michael},
  booktitle = {Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)},
  month     = may,
  year      = {2022},
  address   = {Dublin, Ireland},
  publisher = {Association for Computational Linguistics},
  url       = {https://aclanthology.org/2022.acl-long.181},
  doi       = {10.18653/v1/2022.acl-long.181},
  pages     = {2534--2544},
  abstract  = {Code search is to search reusable code snippets from source code corpus based on natural languages queries. Deep learning-based methods on code search have shown promising results. However, previous methods focus on retrieval accuracy, but lacked attention to the efficiency of the retrieval process. We propose a novel method CoSHC to accelerate code search with deep hashing and code classification, aiming to perform efficient code search without sacrificing too much accuracy. To evaluate the effectiveness of CoSHC, we apply our methodon five code search models. Extensive experimental results indicate that compared with previous code search baselines, CoSHC can save more than 90{\%} of retrieval time meanwhile preserving at least 99{\%} of retrieval accuracy.}
}

@inproceedings{CodeBERT,
  title     = {{C}ode{BERT}: A Pre-Trained Model for Programming and Natural Languages},
  author    = {Feng, Zhangyin  and
               Guo, Daya  and
               Tang, Duyu  and
               Duan, Nan  and
               Feng, Xiaocheng  and
               Gong, Ming  and
               Shou, Linjun  and
               Qin, Bing  and
               Liu, Ting  and
               Jiang, Daxin  and
               Zhou, Ming},
  booktitle = {Findings of the Association for Computational Linguistics: EMNLP 2020},
  month     = nov,
  year      = {2020},
  publisher = {Association for Computational Linguistics},
  pages     = {1536--1547},
  abstract  = {We present CodeBERT, a bimodal pre-trained model for programming language (PL) and natural language (NL). CodeBERT learns general-purpose representations that support downstream NL-PL applications such as natural language code search, code documentation generation, etc. We develop CodeBERT with Transformer-based neural architecture, and train it with a hybrid objective function that incorporates the pre-training task of replaced token detection, which is to detect plausible alternatives sampled from generators. This enables us to utilize both {``}bimodal{''} data of NL-PL pairs and {``}unimodal data, where the former provides input tokens for model training while the latter helps to learn better generators. We evaluate CodeBERT on two NL-PL applications by fine-tuning model parameters. Results show that CodeBERT achieves state-of-the-art performance on both natural language code search and code documentation generation. Furthermore, to investigate what type of knowledge is learned in CodeBERT, we construct a dataset for NL-PL probing, and evaluate in a zero-shot setting where parameters of pre-trained models are fixed. Results show that CodeBERT performs better than previous pre-trained models on NLPL probing.}
}

@inproceedings{GraphCodeBERT,
  author    = {Daya Guo and
               Shuo Ren and
               Shuai Lu and
               Zhangyin Feng and
               Duyu Tang and
               Shujie Liu and
               Long Zhou and
               Nan Duan and
               Alexey Svyatkovskiy and
               Shengyu Fu andz
               Michele Tufano and
               Shao Kun Deng and
               Colin B. Clement and
               Dawn Drain and
               Neel Sundaresan and
               Jian Yin and
               Daxin Jiang and
               Ming Zhou},
  title     = {GraphCodeBERT: Pre-training Code Representations with Data Flow},
  booktitle = {9th International Conference on Learning Representations, {ICLR} 2021,
               Virtual Event, Austria, May 3-7, 2021},
  year      = {2021}
}

@inproceedings{VulDeePecker,
  author    = {Zhen Li and
               Deqing Zou and
               Shouhuai Xu and
               Xinyu Ou and
               Hai Jin and
               Sujuan Wang and
               Zhijun Deng and
               Yuyi Zhong},
  title     = {VulDeePecker: {A} Deep Learning-Based System for Vulnerability Detection},
  booktitle = {25th Annual Network and Distributed System Security Symposium, {NDSS}
               2018, San Diego, California, USA, February 18-21, 2018},
  publisher = {The Internet Society},
  year      = {2018},
  url       = {https://www.ndss-symposium.org/wp-content/uploads/2018/02/ndss2018\_03A-2\_Li\_paper.pdf},
  timestamp = {Thu, 15 Jun 2023 16:53:20 +0200},
  biburl    = {https://dblp.org/rec/conf/ndss/LiZXO0WDZ18.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@article{ReVeal,
  author    = {S. Chakraborty and R. Krishna and Y. Ding and B. Ray},
  journal   = {IEEE Transactions on Software Engineering},
  title     = {Deep Learning Based Vulnerability Detection: Are We There Yet?},
  year      = {2022},
  volume    = {48},
  number    = {09},
  issn      = {1939-3520},
  pages     = {3280-3296},
  abstract  = {Automated detection of software vulnerabilities is a fundamental problem in software security. Existing program analysis techniques either suffer from high false positives or false negatives. Recent progress in Deep Learning (DL) has resulted in a surge of interest in applying DL for automated vulnerability detection. Several recent studies have demonstrated promising results achieving an accuracy of up to 95 percent at detecting vulnerabilities. In this paper, we ask, “how well do the state-of-the-art DL-based techniques perform in a real-world vulnerability prediction scenario?” To our surprise, we find that their performance drops by more than 50 percent. A systematic investigation of what causes such precipitous performance drop reveals that existing DL-based vulnerability prediction approaches suffer from challenges with the training data (e.g., data duplication, unrealistic distribution of vulnerable classes, etc.) and with the model choices (e.g., simple token-based models). As a result, these approaches often do not learn features related to the actual cause of the vulnerabilities. Instead, they learn unrelated artifacts from the dataset (e.g., specific variable/function names, etc.). Leveraging these empirical findings, we demonstrate how a more principled approach to data collection and model design, based on realistic settings of vulnerability prediction, can lead to better solutions. The resulting tools perform significantly better than the studied baseline—up to 33.57 percent boost in precision and 128.38 percent boost in recall compared to the best performing model in the literature. Overall, this paper elucidates existing DL-based vulnerability prediction systems’ potential issues and draws a roadmap for future DL-based vulnerability prediction research.},
  keywords  = {predictive models;neural networks;testing;data models;security;training;training data},
  doi       = {10.1109/TSE.2021.3087402},
  publisher = {IEEE Computer Society},
  address   = {Los Alamitos, CA, USA},
  month     = {sep}
}

@inproceedings{10.1007/978-3-030-41579-2_13,
  author    = {Lin, Guanjun
               and Xiao, Wei
               and Zhang, Jun
               and Xiang, Yang},
  editor    = {Zhou, Jianying
               and Luo, Xiapu
               and Shen, Qingni
               and Xu, Zhen},
  title     = {Deep Learning-Based Vulnerable Function Detection: A Benchmark},
  booktitle = {Information and Communications Security},
  year      = {2020},
  publisher = {Springer International Publishing},
  address   = {Cham},
  pages     = {219--232},
  abstract  = {The application of Deep Learning (DL) technique for code analysis enables the rich and latent patterns within software code to be revealed, facilitating various downstream tasks such as the software defect and vulnerability detection. Many DL architectures have been applied for identifying vulnerable code segments in recent literature. However, the proposed studies were evaluated on self-constructed/-collected datasets. There is a lack of unified performance criteria, acting as a baseline for measuring the effectiveness of the proposed DL-based approaches. This paper proposes a benchmarking framework for building and testing DL-based vulnerability detectors, providing six built-in mainstream neural network models with three embedding solutions available for selection. The framework also offers easy-to-use APIs for integration of new network models and embedding methods. In addition, we constructed a real-world vulnerability ground truth dataset containing manually labelled 1,471 vulnerable functions and 1,320 vulnerable files from nine open-source software projects. With the proposed framework and the ground truth dataset, researchers can conveniently establish a vulnerability detection baseline system for comparison and evaluation. This paper also includes usage examples of the proposed framework, aiming to investigate the performance behaviours of mainstream neural network models and providing a reference for DL-based vulnerability detection at function-level.},
  isbn      = {978-3-030-41579-2}
}



@inbook{Devign,
  author    = {Zhou, Yaqin and Liu, Shangqing and Siow, Jingkai and Du, Xiaoning and Liu, Yang},
  title     = {Devign: Effective Vulnerability Identification by Learning Comprehensive Program Semantics via Graph Neural Networks},
  year      = {2019},
  publisher = {Curran Associates Inc.},
  address   = {Red Hook, NY, USA},
  abstract  = {Vulnerability identification is crucial to protect the software systems from attacks for cyber security. It is especially important to localize the vulnerable functions among the source code to facilitate the fix. However, it is a challenging and tedious process, and also requires specialized security expertise. Inspired by the work on manually-defined patterns of vulnerabilities from various code representation graphs and the recent advance on graph neural networks, we propose Devign, a general graph neural network based model for graph-level classification through learning on a rich set of code semantic representations. It includes a novel Conv module to efficiently extract useful features in the learned rich node representations for graph-level classification. The model is trained over manually labeled datasets built on 4 diversified large-scale open-source C projects that incorporate high complexity and variety of real source code instead of synthesis code used in previous works. The results of the extensive evaluation on the datasets demonstrate that Devign outperforms the state of the arts significantly with an average of 10.51\% higher accuracy and 8.68\% F1 score, increases averagely 4.66\% accuracy and 6.37\% F1 by the Conv module.},
  booktitle = {Proceedings of the 33rd International Conference on Neural Information Processing Systems},
  articleno = {915},
  numpages  = {11}
}

@misc{li2023multitarget,
  title         = {Multi-target Backdoor Attacks for Code Pre-trained Models},
  author        = {Yanzhou Li and Shangqing Liu and Kangjie Chen and Xiaofei Xie and Tianwei Zhang and Yang Liu},
  year          = {2023},
  eprint        = {2306.08350},
  archiveprefix = {arXiv},
  primaryclass  = {cs.CR}
}


@inproceedings{spectral,
  author    = {Tran, Brandon and Li, Jerry and Madry, Aleksander},
  booktitle = {Advances in Neural Information Processing Systems},
  editor    = {S. Bengio and H. Wallach and H. Larochelle and K. Grauman and N. Cesa-Bianchi and R. Garnett},
  pages     = {},
  publisher = {Curran Associates, Inc.},
  title     = {Spectral Signatures in Backdoor Attacks},
  volume    = {31},
  year      = {2018}
}

@inproceedings{codebackdoor,
  author    = {G. Ramakrishnan and A. Albarghouthi},
  booktitle = {2022 26th International Conference on Pattern Recognition (ICPR)},
  title     = {Backdoors in Neural Models of Source Code},
  year      = {2022},
  volume    = {},
  issn      = {},
  pages     = {2892-2899},
  abstract  = {Deep neural networks are vulnerable to a range of adversaries. A particularly pernicious class of vulnerabilities are backdoors, where model predictions diverge in the presence of subtle triggers in inputs. An attacker can implant a backdoor by poisoning the training data to yield a desired target prediction on triggered inputs. We study backdoors in the context of deep-learning for source code. (1) We define a range of backdoor classes for source-code tasks and install backdoors using dataset poisoning. (2) We adapt and improve recent algorithms from robust statistics for our setting, showing that backdoors leave a spectral signature in the learned representation of source code, thus enabling detection of poisoned data. (3) We conduct a thorough evaluation on different architectures and languages, showing the ease of injecting backdoors and our ability to eliminate them.},
  keywords  = {deep learning;codes;source coding;neural networks;training data;implants;predictive models},
  doi       = {10.1109/ICPR56361.2022.9956690},
  url       = {https://doi.ieeecomputersociety.org/10.1109/ICPR56361.2022.9956690},
  publisher = {IEEE Computer Society},
  address   = {Los Alamitos, CA, USA},
  month     = {aug}
}

@inproceedings{10.5555/3615924.3615927,
  author    = {Nathalia, Nascimento and Paulo, Alencar and Donald, Cowan},
  title     = {Artificial Intelligence vs. Software Engineers: An Empirical Study on Performance and Efficiency Using ChatGPT},
  year      = {2023},
  publisher = {IBM Corp.},
  address   = {USA},
  abstract  = {In the realm of Software Engineering (SE), automation has become a tangible reality. Artificial Intelligence (AI) has suc-cessfully addressed challenges in project management, mod-eling, testing, and development. Among the latest innova-tions is ChatGPT, an ML-infused chatbot capable of gen-erating programming codes and software testing strategies. Although there is speculation that AI-based computation can boost productivity and even substitute software engineers in software development, empirical evidence supporting such claims is lacking. Moreover, questions remain about their po-tential to address overlooked evaluation metrics like energy efficiency, vulnerability, fairness (i.e., human bias), and safety. This paper probes into these issues with an empirical study, comparing ChatGPT with both novice and expert program-mers using LeetCode contest problems. The investigation focuses on performance and memory-efficiency, while also acknowledging the need for a broader assessment of non-functional requirements. The results suggest that ChatGPT is better than beginners at solving easy and medium prob-lems, but it is not yet proven to beat expert programmers. This paper posits that a comprehensive comparison of soft-ware engineers and AI-based solutions, considering various evaluation criteria, is pivotal in fostering human-machine collaboration, enhancing the reliability of AI-based meth-ods, and understanding task suitability for humans or AI. Furthermore, it facilitates the effective implementation of co-operative work structures and human-in-the-loop processes.},
  booktitle = {Proceedings of the 33rd Annual International Conference on Computer Science and Software Engineering},
  pages     = {24–33},
  numpages  = {10},
  keywords  = {AI-based solutions, Software Engineering, ChatGPT, Machine Learning, Performance Evaluation},
  location  = {Las Vegas, NV, USA},
  series    = {CASCON '23}
}

@misc{druga2023ai,
  title         = {AI Friends: A Design Framework for AI-Powered Creative Programming for Youth},
  author        = {Stefania Druga and Amy J. Ko},
  year          = {2023},
  eprint        = {2305.10412},
  archiveprefix = {arXiv},
  primaryclass  = {cs.HC}
}

@misc{druga2023scratch,
  title         = {Scratch Copilot Evaluation: Assessing AI-Assisted Creative Coding for Families},
  author        = {Stefania Druga and Nancy Otero},
  year          = {2023},
  eprint        = {2305.10417},
  archiveprefix = {arXiv},
  primaryclass  = {cs.HC}
}

@article{LI2023165,
  title    = {A comparative study of adversarial training methods for neural models of source code},
  journal  = {Future Generation Computer Systems},
  volume   = {142},
  pages    = {165-181},
  year     = {2023},
  issn     = {0167-739X},
  doi      = {https://doi.org/10.1016/j.future.2022.12.030},
  url      = {https://www.sciencedirect.com/science/article/pii/S0167739X22004332},
  author   = {Zhen Li and Xiang Huang and Yangrui Li and Guenevere Chen},
  keywords = {Adversarial training, Robustness, Source code, Comparative study},
  abstract = {Adversarial training has been employed by researchers to protect AI models of source code. However, it is still unknown how adversarial training methods in this field compare to each other in effectiveness and robustness. This study surveys and investigates existing adversarial training methods, and conducts experiments to evaluate these neural models’ performance in the domain of source code. First, we examine the process of adversarial training to identify four dimensions that could be used to classify different adversarial training methods into five categories, which are Mixing Directly, Composite Loss, Adversarial Fine-tuning, Min–max + Composite Loss, and Min–max. Second, we conduct empirical evaluations of these classified adversarial training methods under two tasks (i.e., code summarization and code authorship attribution) to determine their performance of effectiveness and robustness. Experimental results indicate that the performance of certain combinations of adversarial training techniques (i.e., min–max with composite loss, or directly-sample with ordinary loss) would be much better than other combinations or other techniques used alone. Our experiments also reveal that the model’s robustness of defensive methods can be enhanced by using diverse input data for adversarial training, and that the number of fine-tuning epochs has little or no impact on model’s performance.}
}

@article{frank2000text,
  title     = {Text categorization using compression models},
  author    = {Frank, Eibe and Chui, Chang and Witten, Ian H},
  year      = {2000},
  publisher = {University of Waikato, Department of Computer Science}
}

@inproceedings{kasturi2022text,
  title        = {Text Ranking and Classification using Data Compression},
  author       = {Kasturi, Nitya and Markov, Igor L},
  booktitle    = {I (Still) Can't Believe It's Not Better! Workshop at NeurIPS 2021},
  pages        = {48--53},
  year         = {2022},
  organization = {PMLR}
}

@inproceedings{marton2005compression,
  title        = {On compression-based text classification},
  author       = {Marton, Yuval and Wu, Ning and Hellerstein, Lisa},
  booktitle    = {Advances in Information Retrieval: 27th European Conference on IR Research, ECIR 2005, Santiago de Compostela, Spain, March 21-23, 2005. Proceedings 27},
  pages        = {300--314},
  year         = {2005},
  organization = {Springer}
}

@article{coutinho2015text,
  title     = {Text classification using compression-based dissimilarity measures},
  author    = {Coutinho, David Pereira and Figueiredo, Mario AT},
  journal   = {International Journal of Pattern Recognition and Artificial Intelligence},
  volume    = {29},
  number    = {05},
  pages     = {1553004},
  year      = {2015},
  publisher = {World Scientific}
}

@misc{nguyen2023adversarial,
  title         = {Adversarial Attacks on Code Models with Discriminative Graph Patterns},
  author        = {Thanh-Dat Nguyen and Zhou Yang and Xuan Bach D. Le and Patanamon and Thongtanunam and David Lo},
  year          = {2023},
  eprint        = {2308.11161},
  archiveprefix = {arXiv},
  primaryclass  = {cs.SE}
}

@inproceedings{ahmad-etal-2020-transformer,
  title     = {A Transformer-based Approach for Source Code Summarization},
  author    = {Ahmad, Wasi  and
               Chakraborty, Saikat  and
               Ray, Baishakhi  and
               Chang, Kai-Wei},
  editor    = {Jurafsky, Dan  and
               Chai, Joyce  and
               Schluter, Natalie  and
               Tetreault, Joel},
  booktitle = {Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics},
  month     = jul,
  year      = {2020},
  address   = {Online},
  publisher = {Association for Computational Linguistics},
  url       = {https://aclanthology.org/2020.acl-main.449},
  doi       = {10.18653/v1/2020.acl-main.449},
  pages     = {4998--5007},
  abstract  = {Generating a readable summary that describes the functionality of a program is known as source code summarization. In this task, learning code representation by modeling the pairwise relationship between code tokens to capture their long-range dependencies is crucial. To learn code representation for summarization, we explore the Transformer model that uses a self-attention mechanism and has shown to be effective in capturing long-range dependencies. In this work, we show that despite the approach is simple, it outperforms the state-of-the-art techniques by a significant margin. We perform extensive analysis and ablation studies that reveal several important findings, e.g., the absolute encoding of source code tokens{'} position hinders, while relative encoding significantly improves the summarization performance. We have made our code publicly available to facilitate future research.}
}

@article{9916170,
  author  = {Wei, Moshi and Huang, Yuchao and Yang, Jinqiu and Wang, Junjie and Wang, Song},
  journal = {IEEE Transactions on Reliability},
  title   = {CoCoFuzzing: Testing Neural Code Models With Coverage-Guided Fuzzing},
  year    = {2022},
  volume  = {},
  number  = {},
  pages   = {1-14},
  doi     = {10.1109/TR.2022.3208239}
}

@article{Yefet2020,
  arxivid  = {1910.07517},
  author   = {Yefet, Noam and Alon, Uri and Yahav, Eran},
  issn     = {24751421},
  journal  = {Proceedings of the ACM on Programming Languages},
  keywords = {Adversarial Attacks,Neural Models of Code,Targeted Attacks},
  number   = {OOPSLA},
  title    = {{Adversarial examples for models of code}},
  volume   = {4},
  year     = {2020}
}

@misc{goodname,
  doi       = {10.48550/ARXIV.2211.15844},
  url       = {https://arxiv.org/abs/2211.15844},
  author    = {Yang, Guang and Zhou, Yu and Yang, Wenhua and Yue, Tao and Chen, Xiang and Chen, Taolue},
  keywords  = {Software Engineering (cs.SE), FOS: Computer and information sciences, FOS: Computer and information sciences},
  title     = {How Important are Good Method Names in Neural Code Generation? A Model Robustness Perspective},
  publisher = {arXiv},
  year      = {2022},
  copyright = {Creative Commons Attribution Non Commercial No Derivatives 4.0 International}
}

@inproceedings{BigCloneBench,
  author    = {Svajlenko, Jeffrey and Islam, Judith F. and Keivanloo, Iman and Roy, Chanchal K. and Mia, Mohammad Mamun},
  booktitle = {2014 IEEE International Conference on Software Maintenance and Evolution},
  title     = {Towards a Big Data Curated Benchmark of Inter-project Code Clones},
  year      = {2014},
  volume    = {},
  number    = {},
  pages     = {476-480},
  doi       = {10.1109/ICSME.2014.77}
}


@inproceedings{word2vec,
  author    = {Tom{\'{a}}s Mikolov and
               Kai Chen and
               Greg Corrado and
               Jeffrey Dean},
  editor    = {Yoshua Bengio and
               Yann LeCun},
  title     = {Efficient Estimation of Word Representations in Vector Space},
  booktitle = {1st International Conference on Learning Representations, {ICLR} 2013,
               Scottsdale, Arizona, USA, May 2-4, 2013, Workshop Track Proceedings},
  year      = {2013},
  url       = {http://arxiv.org/abs/1301.3781},
  timestamp = {Mon, 28 Dec 2020 11:31:01 +0100},
  biburl    = {https://dblp.org/rec/journals/corr/abs-1301-3781.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@inproceedings{CuBERT,
  title        = {Learning and evaluating contextual embedding of source code},
  author       = {Kanade, Aditya and Maniatis, Petros and Balakrishnan, Gogul and Shi, Kensen},
  booktitle    = {International Conference on Machine Learning},
  pages        = {5110--5121},
  year         = {2020},
  organization = {PMLR}
}


@article{CBERT,
  author        = {Luca Buratti and
                   Saurabh Pujar and
                   Mihaela A. Bornea and
                   J. Scott McCarley and
                   Yunhui Zheng and
                   Gaetano Rossiello and
                   Alessandro Morari and
                   Jim Laredo and
                   Veronika Thost and
                   Yufan Zhuang and
                   Giacomo Domeniconi},
  title         = {Exploring Software Naturalness through Neural Language Models},
  journal       = {CoRR},
  volume        = {abs/2006.12641},
  year          = {2020},
  url           = {https://arxiv.org/abs/2006.12641},
  archiveprefix = {arXiv},
  eprint        = {2006.12641},
  timestamp     = {Fri, 11 Dec 2020 17:26:59 +0100},
  biburl        = {https://dblp.org/rec/journals/corr/abs-2006-12641.bib},
  bibsource     = {dblp computer science bibliography, https://dblp.org}
}

@inproceedings{henderson2018ethical,
  title        = {Ethical Challenges in Data-Driven Dialogue Systems},
  author       = {Henderson, Peter and Sinha, Koustuv and Angelard-Gontier, Nicolas and Ke, Nan Rosemary and Fried, Genevieve and Lowe, Ryan and Pineau, Joelle},
  booktitle    = {Proceedings of the 2018 AAAI/ACM Conference on AI, Ethics, and Society},
  series       = {AIES '18},
  pages        = {123--129},
  numpages     = {7},
  year         = {2018},
  organization = {Association for Computing Machinery},
  publisher    = {Association for Computing Machinery},
  address      = {New York, NY, USA},
  location     = {New Orleans, LA, USA},
  keywords     = {ethics and safety, dialogue systems, adversarial examples, security, privacy, reproducibility, computers and society, reinforcement learning, bias, natural language processing, machine learning},
  isbn         = {9781450360128},
  doi          = {10.1145/3278721.3278777},
  url          = {https://doi.org/10.1145/3278721.3278777},
  abstract     = {The use of dialogue systems as a medium for human-machine interaction is an increasingly prevalent paradigm. A growing number of dialogue systems use conversation strategies that are learned from large datasets. There are well documented instances where interactions with these system have resulted in biased or even offensive conversations due to the data-driven training process. Here, we highlight potential ethical issues that arise in dialogue systems research, including: implicit biases in data-driven systems, the rise of adversarial examples, potential sources of privacy violations, safety concerns, special considerations for reinforcement learning systems, and reproducibility concerns. We also suggest areas stemming from these issues that deserve further investigation. Through this initial survey, we hope to spur research leading to robust, safe, and ethically sound dialogue systems.}
}

@inproceedings{10174120,
  author    = {Jungwirth, Gerhard and Saha, Aakanksha and Schröder, Michael and Fiebig, Tobias and Lindorfer, Martina and Cito, Jürgen},
  booktitle = {2023 IEEE/ACM 20th International Conference on Mining Software Repositories (MSR)},
  title     = {Connecting the .dotfiles: Checked-In Secret Exposure with Extra (Lateral Movement) Steps},
  year      = {2023},
  volume    = {},
  number    = {},
  pages     = {322-333},
  doi       = {10.1109/MSR59073.2023.00051}
}


@inproceedings{carlini2019secretsharer,
  title        = {The Secret Sharer: Evaluating and Testing Unintended Memorization in Neural Networks},
  author       = {Carlini, Nicholas and Liu, Chang and Erlingsson, {'U}lfar and Kos, Jernej and Song, Dawn},
  booktitle    = {Proceedings of the 28th USENIX Conference on Security Symposium},
  series       = {SEC'19},
  pages        = {267--284},
  year         = {2019},
  organization = {USENIX Association},
  address      = {Santa Clara, CA, USA},
  publisher    = {USENIX Association},
  isbn         = {978-1-939133-06-9},
  numpages     = {18}
}

@inproceedings{GGNN,
  author    = {Patrick Fernandes and
               Miltiadis Allamanis and
               Marc Brockschmidt},
  title     = {Structured Neural Summarization},
  booktitle = {7th International Conference on Learning Representations, {ICLR} 2019,
               New Orleans, LA, USA, May 6-9, 2019},
  publisher = {OpenReview.net},
  year      = {2019},
  url       = {https://openreview.net/forum?id=H1ersoRqtm},
  timestamp = {Thu, 25 Jul 2019 14:25:49 +0200},
  biburl    = {https://dblp.org/rec/conf/iclr/FernandesAB19.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@misc{rabin2021evaluation,
  title         = {Evaluation of Generalizability of Neural Program Analyzers under Semantic-Preserving Transformations},
  author        = {Md Rafiqul Islam Rabin and Mohammad Amin Alipour},
  year          = {2021},
  eprint        = {2004.07313},
  archiveprefix = {arXiv},
  primaryclass  = {cs.SE}
}

@article{rabin2021generalizability,
  title     = {On the generalizability of Neural Program Models with respect to semantic-preserving program transformations},
  author    = {Rabin, Md Rafiqul Islam and Bui, Nghi DQ and Wang, Ke and Yu, Yijun and Jiang, Lingxiao and Alipour, Mohammad Amin},
  journal   = {Information and Software Technology},
  volume    = {135},
  pages     = {106552},
  year      = {2021},
  publisher = {Elsevier}
}


@inproceedings{pmlr-v48-allamanis16,
  title     = {A Convolutional Attention Network for Extreme Summarization of Source Code},
  author    = {Allamanis, Miltiadis and Peng, Hao and Sutton, Charles},
  booktitle = {Proceedings of The 33rd International Conference on Machine Learning},
  pages     = {2091--2100},
  year      = {2016},
  editor    = {Balcan, Maria Florina and Weinberger, Kilian Q.},
  volume    = {48},
  series    = {Proceedings of Machine Learning Research},
  address   = {New York, New York, USA},
  month     = {20--22 Jun},
  publisher = {PMLR},
  pdf       = {http://proceedings.mlr.press/v48/allamanis16.pdf},
  url       = {https://proceedings.mlr.press/v48/allamanis16.html},
  abstract  = {Attention mechanisms in neural networks have proved useful for problems in which the input and output do not have fixed dimension. Often there exist features that are locally translation invariant and would be valuable for directing the model’s attention, but previous attentional architectures are not constructed to learn such features specifically. We introduce an attentional neural network that employs convolution on the input tokens to detect local time-invariant and long-range topical attention features in a context-dependent way. We apply this architecture to the problem of extreme summarization of source code snippets into short, descriptive function name-like summaries. Using those features, the model sequentially generates a summary by marginalizing over two attention mechanisms: one that predicts the next summary token based on the attention weights of the input tokens and another that is able to copy a code token as-is directly into the summary. We demonstrate our convolutional attention neural network’s performance on 10 popular Java projects showing that it achieves better performance compared to previous attentional mechanisms.}
}


@inproceedings{code2seq,
  title     = {code2seq: Generating Sequences from Structured Representations of Code},
  author    = {Uri Alon and Omer Levy and Eran Yahav},
  booktitle = {International Conference on Learning Representations},
  year      = {2019},
  url       = {https://openreview.net/forum?id=H1gKYo09tX}
}

@article{10.1145/3340544,
  author     = {Tufano, Michele and Watson, Cody and Bavota, Gabriele and Penta, Massimiliano Di and White, Martin and Poshyvanyk, Denys},
  title      = {An Empirical Study on Learning Bug-Fixing Patches in the Wild via Neural Machine Translation},
  year       = {2019},
  issue_date = {October 2019},
  publisher  = {Association for Computing Machinery},
  address    = {New York, NY, USA},
  volume     = {28},
  number     = {4},
  issn       = {1049-331X},
  url        = {https://doi.org/10.1145/3340544},
  doi        = {10.1145/3340544},
  abstract   = {Millions of open source projects with numerous bug fixes are available in code repositories. This proliferation of software development histories can be leveraged to learn how to fix common programming bugs. To explore such a potential, we perform an empirical study to assess the feasibility of using Neural Machine Translation techniques for learning bug-fixing patches for real defects. First, we mine millions of bug-fixes from the change histories of projects hosted on GitHub in order to extract meaningful examples of such bug-fixes. Next, we abstract the buggy and corresponding fixed code, and use them to train an Encoder-Decoder model able to translate buggy code into its fixed version. In our empirical investigation, we found that such a model is able to fix thousands of unique buggy methods in the wild. Overall, this model is capable of predicting fixed patches generated by developers in 9--50\% of the cases, depending on the number of candidate patches we allow it to generate. Also, the model is able to emulate a variety of different Abstract Syntax Tree operations and generate candidate patches in a split second.},
  journal    = {ACM Trans. Softw. Eng. Methodol.},
  month      = {sep},
  articleno  = {19},
  numpages   = {29},
  keywords   = {bug-fixes, Neural machine translation}
}

@misc{codeattack,
  author    = {Jha, Akshita and Reddy, Chandan K.},
  keywords  = {Computation and Language (cs.CL), Cryptography and Security (cs.CR), FOS: Computer and information sciences, FOS: Computer and information sciences},
  title     = {CodeAttack: Code-based Adversarial Attacks for Pre-Trained Programming Language Models},
  publisher = {arXiv},
  year      = {2022},
  copyright = {Creative Commons Attribution 4.0 International}
}


@article{10.1016/j.future.2022.12.030,
  author     = {Li, Zhen and Huang, Xiang and Li, Yangrui and Chen, Guenevere},
  title      = {A Comparative Study of Adversarial Training Methods for Neural Models of Source Code},
  year       = {2023},
  issue_date = {May 2023},
  publisher  = {Elsevier Science Publishers B. V.},
  address    = {NLD},
  volume     = {142},
  number     = {C},
  issn       = {0167-739X},
  url        = {https://doi.org/10.1016/j.future.2022.12.030},
  doi        = {10.1016/j.future.2022.12.030},
  journal    = {Future Gener. Comput. Syst.},
  month      = {may},
  pages      = {165–181},
  numpages   = {17},
  keywords   = {Comparative study, Robustness, Source code, Adversarial training}
}

@inproceedings{10.5555/3304889.3304975,
  author    = {Hu, Xing and Li, Ge and Xia, Xin and Lo, David and Lu, Shuai and Jin, Zhi},
  title     = {Summarizing Source Code with Transferred API Knowledge},
  year      = {2018},
  isbn      = {9780999241127},
  publisher = {AAAI Press},
  abstract  = {Code summarization, aiming to generate succinct natural language description of source code, is extremely useful for code search and code comprehension. It has played an important role in software maintenance and evolution. Previous approaches generate summaries by retrieving summaries from similar code snippets. However, these approaches heavily rely on whether similar code snippets can be retrieved, how similar the snippets are, and fail to capture the API knowledge in the source code, which carries vital information about the functionality of the source code. In this paper, we propose a novel approach, named TL-CodeSum, which successfully uses API knowledge learned in a different but related task to code summarization. Experiments on large-scale real-world industry Java projects indicate that our approach is effective and outperforms the state-of-the-art in code summarization.},
  booktitle = {Proceedings of the 27th International Joint Conference on Artificial Intelligence},
  pages     = {2269–2275},
  numpages  = {7},
  location  = {Stockholm, Sweden},
  series    = {IJCAI'18}
}

@inproceedings{9438605,
  author    = {Maryam Vahdat Pour and
               Zhuo Li and
               Lei Ma and
               Hadi Hemmati},
  title     = {A Search-Based Testing Framework for Deep Neural Networks of Source
               Code Embedding},
  booktitle = {14th {IEEE} Conference on Software Testing, Verification and Validation,
               {ICST} 2021, Porto de Galinhas, Brazil, April 12-16, 2021},
  pages     = {36--46},
  publisher = {{IEEE}},
  year      = {2021}
}

@misc{simian,
  author       = {Simon Harris},
  title        = {Simian},
  howpublished = {\url{https://www.harukizaemon.com/simian}},
  year         = {n.d.}
}


@inproceedings{code-model-clone-msr22,
  author    = {Ciniselli, Matteo and Pascarella, Luca and Bavota, Gabriele},
  title     = {To What Extent Do Deep Learning-Based Code Recommenders Generate Predictions by Cloning Code from the Training Set?},
  year      = {2022},
  isbn      = {9781450393034},
  publisher = {Association for Computing Machinery},
  address   = {New York, NY, USA},
  url       = {https://doi.org/10.1145/3524842.3528440},
  doi       = {10.1145/3524842.3528440},
  abstract  = {Deep Learning (DL) models have been widely used to support code completion. These models, once properly trained, can take as input an incomplete code component (e.g., an incomplete function) and predict the missing tokens to finalize it. GitHub Copilot is an example of code recommender built by training a DL model on millions of open source repositories: The source code of these repositories acts as training data, allowing the model to learn "how to program". The usage of such a code is usually regulated by Free and Open Source Software (FOSS) licenses, that establish under which conditions the licensed code can be redistributed or modified. As of Today, it is unclear whether the code generated by DL models trained on open source code should be considered as "new" or as "derivative" work, with possible implications on license infringements. In this work, we run a large-scale study investigating the extent to which DL models tend to clone code from their training set when recommending code completions. Such an exploratory study can help in assessing the magnitude of the potential licensing issues mentioned before: If these models tend to generate new code that is unseen in the training set, then licensing issues are unlikely to occur. Otherwise, a revision of these licenses urges to regulate how the code generated by these models should be treated when used, for example, in a commercial setting. Highlights from our results show that ~10% to ~0.1% of the predictions generated by a state-of-the-art DL-based code completion tool are Type-1 clones of instances in the training set, depending on the size of the predicted code. Long predictions are unlikely to be cloned.},
  booktitle = {Proceedings of the 19th International Conference on Mining Software Repositories},
  pages     = {167–178},
  numpages  = {12},
  keywords  = {code completion, code clones, deep learning},
  location  = {Pittsburgh, Pennsylvania},
  series    = {MSR '22}
}

@misc{ledel2022studying,
  title         = {Studying the explanations for the automated prediction of bug and non-bug issues using LIME and SHAP},
  author        = {Benjamin Ledel and Steffen Herbold},
  year          = {2022},
  eprint        = {2209.07623},
  archiveprefix = {arXiv},
  primaryclass  = {cs.SE}
}

@misc{zhang2022does,
  title         = {What does Transformer learn about source code?},
  author        = {Kechi Zhang and Ge Li and Zhi Jin},
  year          = {2022},
  eprint        = {2207.08466},
  archiveprefix = {arXiv},
  primaryclass  = {cs.SE}
}

@misc{huber2023look,
  title         = {Where to Look When Repairing Code? Comparing the Attention of Neural Models and Developers},
  author        = {Dominik Huber and Matteo Paltenghi and Michael Pradel},
  year          = {2023},
  eprint        = {2305.07287},
  archiveprefix = {arXiv},
  primaryclass  = {cs.SE}
}

@inproceedings{10.1145/3490099.3511119,
  author    = {Sun, Jiao and Liao, Q. Vera and Muller, Michael and Agarwal, Mayank and Houde, Stephanie and Talamadupula, Kartik and Weisz, Justin D.},
  title     = {Investigating Explainability of Generative AI for Code through Scenario-Based Design},
  year      = {2022},
  isbn      = {9781450391443},
  publisher = {Association for Computing Machinery},
  address   = {New York, NY, USA},
  url       = {https://doi.org/10.1145/3490099.3511119},
  doi       = {10.1145/3490099.3511119},
  abstract  = {What does it mean for a generative AI model to be explainable? The emergent discipline of explainable AI (XAI) has made great strides in helping people understand discriminative models. Less attention has been paid to generative models that produce artifacts, rather than decisions, as output. Meanwhile, generative AI (GenAI) technologies are maturing and being applied to application domains such as software engineering. Using scenario-based design and question-driven XAI design approaches, we explore users’ explainability needs for GenAI in three software engineering use cases: natural language to code, code translation, and code auto-completion. We conducted 9 workshops with 43 software engineers in which real examples from state-of-the-art generative AI models were used to elicit users’ explainability needs. Drawing from prior work, we also propose 4 types of XAI features for GenAI for code and gathered additional design ideas from participants. Our work explores explainability needs for GenAI for code and demonstrates how human-centered approaches can drive the technical development of XAI in novel domains.},
  booktitle = {27th International Conference on Intelligent User Interfaces},
  pages     = {212–228},
  numpages  = {17},
  keywords  = {generative AI, software engineering tooling, human-centered AI, scenario based design, explainable AI},
  location  = {Helsinki, Finland},
  series    = {IUI '22}
}

@article{WheaCha,
  author     = {Wang, Yu and Wang, Ke and Wang, Linzhang},
  title      = {An Explanation Method for Models of Code},
  year       = {2023},
  issue_date = {October 2023},
  publisher  = {Association for Computing Machinery},
  address    = {New York, NY, USA},
  volume     = {7},
  number     = {OOPSLA2},
  url        = {https://doi.org/10.1145/3622826},
  doi        = {10.1145/3622826},
  abstract   = {This paper introduces a novel method, called WheaCha, for explaining the predictions of code models. Similar to attribution methods, WheaCha seeks to identify input features that are responsible for a particular prediction that models make. On the other hand, it differs from attribution methods in crucial ways. Specifically, WheaCha separates an input program into "wheat" (i.e., defining features that are the reason for which models predict the label that they predict) and the rest "chaff" for any given prediction. We realize WheaCha in a tool, HuoYan, and use it to explain four prominent code models: code2vec, seq-GNN, GGNN, and CodeBERT. Results show that (1) HuoYan is efficient — taking on average under twenty seconds to compute wheat for an input program in an end-to-end fashion (i.e., including model prediction time); (2) the wheat that all models use to make predictions is predominantly comprised of simple syntactic or even lexical properties (i.e., identifier names); (3) neither the latest explainability methods for code models (i.e., SIVAND and CounterFactual Explanations) nor the most noteworthy attribution methods (i.e., Integrated Gradients and SHAP) can precisely capture wheat. Finally, we set out to demonstrate the usefulness of WheaCha, in particular, we assess if WheaCha’s explanations can help end users to identify defective code models (e.g., trained on mislabeled data or learned spurious correlations from biased data). We find that, with WheaCha, users achieve far higher accuracy in identifying faulty models than SIVAND, CounterFactual Explanations, Integrated Gradients and SHAP.},
  journal    = {Proc. ACM Program. Lang.},
  month      = {oct},
  articleno  = {250},
  numpages   = {27},
  keywords   = {Models of Code, Explainability Method, Defining Features}
}

@misc{huang2024bias,
      title={Bias Testing and Mitigation in LLM-based Code Generation}, 
      author={Dong Huang and Qingwen Bu and Jie Zhang and Xiaofei Xie and Junjie Chen and Heming Cui},
      year={2024},
      eprint={2309.14345},
      archivePrefix={arXiv},
      primaryClass={cs.SE}
}

@inproceedings{10.1109/ASE51524.2021.9678927,
  author    = {Karmakar, Anjan and Robbes, Romain},
  title     = {What Do Pre-Trained Code Models Know about Code?},
  year      = {2022},
  isbn      = {9781665403375},
  publisher = {IEEE Press},
  url       = {https://doi.org/10.1109/ASE51524.2021.9678927},
  doi       = {10.1109/ASE51524.2021.9678927},
  abstract  = {Pre-trained models of code built on the transformer architecture have performed well on software engineering (SE) tasks such as predictive code generation, code summarization, among others. However, whether the vector representations from these pre-trained models comprehensively encode characteristics of source code well enough to be applicable to a broad spectrum of downstream tasks remains an open question.One way to investigate this is with diagnostic tasks called probes. In this paper, we construct four probing tasks (probing for surface-level, syntactic, structural, and semantic information) for pre-trained code models. We show how probes can be used to identify whether models are deficient in (understanding) certain code properties, characterize different model layers, and get insight into the model sample-efficiency.We probe four models that vary in their expected knowledge of code properties: BERT (pre-trained on English), CodeBERT and CodeBERTa (pre-trained on source code, and natural language documentation), and GraphCodeBERT (pre-trained on source code with dataflow). While GraphCodeBERT performs more consistently overall, we find that BERT performs surprisingly well on some code tasks, which calls for further investigation.},
  booktitle = {Proceedings of the 36th IEEE/ACM International Conference on Automated Software Engineering},
  pages     = {1332–1336},
  numpages  = {5},
  keywords  = {software engineering tasks, transformers, probing, source code models},
  location  = {Melbourne, Australia},
  series    = {ASE '21}
}

@inproceedings{10.1145/3510003.3510050,
  author    = {Wan, Yao and Zhao, Wei and Zhang, Hongyu and Sui, Yulei and Xu, Guandong and Jin, Hai},
  title     = {What Do They Capture? A Structural Analysis of Pre-Trained Language Models for Source Code},
  year      = {2022},
  isbn      = {9781450392211},
  publisher = {Association for Computing Machinery},
  address   = {New York, NY, USA},
  url       = {https://doi.org/10.1145/3510003.3510050},
  doi       = {10.1145/3510003.3510050},
  abstract  = {Recently, many pre-trained language models for source code have been proposed to model the context of code and serve as a basis for downstream code intelligence tasks such as code completion, code search, and code summarization. These models leverage masked pre-training and Transformer and have achieved promising results. However, currently there is still little progress regarding interpretability of existing pre-trained code models. It is not clear why these models work and what feature correlations they can capture. In this paper, we conduct a thorough structural analysis aiming to provide an interpretation of pre-trained language models for source code (e.g., CodeBERT, and GraphCodeBERT) from three distinctive perspectives: (1) attention analysis, (2) probing on the word embedding, and (3) syntax tree induction. Through comprehensive analysis, this paper reveals several insightful findings that may inspire future studies: (1) Attention aligns strongly with the syntax structure of code. (2) Pre-training language models of code can preserve the syntax structure of code in the intermediate representations of each Transformer layer. (3) The pre-trained models of code have the ability of inducing syntax trees of code. Theses findings suggest that it may be helpful to incorporate the syntax structure of code into the process of pre-training for better code representations.},
  booktitle = {Proceedings of the 44th International Conference on Software Engineering},
  pages     = {2377–2388},
  numpages  = {12},
  keywords  = {code representation, deep learning, attention analysis, syntax tree induction, probing, pre-trained language model},
  location  = {Pittsburgh, Pennsylvania},
  series    = {ICSE '22}
}

@inproceedings{9678712,
  author    = {Paltenghi, Matteo and Pradel, Michael},
  booktitle = {2021 36th IEEE/ACM International Conference on Automated Software Engineering (ASE)},
  title     = {Thinking Like a Developer? Comparing the Attention of Humans with Neural Models of Code},
  year      = {2021},
  volume    = {},
  number    = {},
  pages     = {867-879},
  doi       = {10.1109/ASE51524.2021.9678712}
}

@misc{palacio2023theory,
  title         = {Toward a Theory of Causation for Interpreting Neural Code Models},
  author        = {David N. Palacio and Nathan Cooper and Alvaro Rodriguez and Kevin Moran and Denys Poshyvanyk},
  year          = {2023},
  eprint        = {2302.03788},
  archiveprefix = {arXiv},
  primaryclass  = {cs.SE}
}


@inproceedings{10.1109/ASE51524.2021.9678763,
  author    = {Pornprasit, Chanathip and Tantithamthavorn, Chakkrit and Jiarpakdee, Jirayus and Fu, Michael and Thongtanunam, Patanamon},
  title     = {PyExplainer: Explaining the Predictions of Just-in-Time Defect Models},
  year      = {2022},
  isbn      = {9781665403375},
  publisher = {IEEE Press},
  url       = {https://doi.org/10.1109/ASE51524.2021.9678763},
  doi       = {10.1109/ASE51524.2021.9678763},
  abstract  = {Just-In-Time (JIT) defect prediction (i.e., an AI/ML model to predict defect-introducing commits) is proposed to help developers prioritize their limited Software Quality Assurance (SQA) resources on the most risky commits. However, the explainability of JIT defect models remains largely unexplored (i.e., practitioners still do not know why a commit is predicted as defect-introducing). Recently, LIME has been used to generate explanations for any AI/ML models. However, the random perturbation approach used by LIME to generate synthetic neighbors is still suboptimal, i.e., generating synthetic neighbors that may not be similar to an instance to be explained, producing low accuracy of the local models, leading to inaccurate explanations for just-in-time defect models. In this paper, we propose PyExplainer---i.e., a local rule-based model-agnostic technique for generating explanations (i.e., why a commit is predicted as defective) of JIT defect models. Through a case study of two open-source software projects, we find that our PyExplainer produces (1) synthetic neighbors that are 41%-45% more similar to an instance to be explained; (2) 18%-38% more accurate local models; and (3) explanations that are 69%-98% more unique and 17%-54% more consistent with the actual characteristics of defect-introducing commits in the future than LIME (a state-of-the-art model-agnostic technique). This could help practitioners focus on the most important aspects of the commits to mitigate the risk of being defect-introducing. Thus, the contributions of this paper build an important step towards Explainable AI for Software Engineering, making software analytics more explainable and actionable. Finally, we publish our PyExplainer as a Python package to support practitioners and researchers (https://github.com/awsm-research/PyExplainer).},
  booktitle = {Proceedings of the 36th IEEE/ACM International Conference on Automated Software Engineering},
  pages     = {407–418},
  numpages  = {12},
  keywords  = {explainable AI, explainable software analytics, just-in-time defect prediction},
  location  = {Melbourne, Australia},
  series    = {ASE '21}
}


@inproceedings{troshin-chirkova-2022-probing,
  title     = {Probing Pretrained Models of Source Codes},
  author    = {Troshin, Sergey  and
               Chirkova, Nadezhda},
  editor    = {Bastings, Jasmijn  and
               Belinkov, Yonatan  and
               Elazar, Yanai  and
               Hupkes, Dieuwke  and
               Saphra, Naomi  and
               Wiegreffe, Sarah},
  booktitle = {Proceedings of the Fifth BlackboxNLP Workshop on Analyzing and Interpreting Neural Networks for NLP},
  month     = dec,
  year      = {2022},
  address   = {Abu Dhabi, United Arab Emirates (Hybrid)},
  publisher = {Association for Computational Linguistics},
  url       = {https://aclanthology.org/2022.blackboxnlp-1.31},
  doi       = {10.18653/v1/2022.blackboxnlp-1.31},
  pages     = {371--383},
  abstract  = {Deep learning models are widely used for solving challenging code processing tasks, such as code generation or code summarization. Traditionally, a specific model architecture was carefully built to solve a particular code processing task. However, recently general pretrained models such as CodeBERT or CodeT5 have been shown to outperform task-specific models in many applications. While pretrained models are known to learn complex patterns from data, they may fail to understand some properties of source code. To test diverse aspects of code understanding, we introduce a set of diagnostic probing tasks. We show that pretrained models of code indeed contain information about code syntactic structure, the notions of identifiers, and namespaces, but they may fail to recognize more complex code properties such as semantic equivalence. We also investigate how probing results are affected by using code-specific pretraining objectives, varying the model size, or finetuning.}
}

@article{Liuyue2023,
  abstract      = {Automatic code generation, the task of generating new code snippets from existing code or comments, has long been of interest. Numerous code generation models have been proposed and proven on different benchmark datasets. However, little is known about whether this objective has been achieved and why code generation models effectively transform code sequences automatically. In other words, can we totally trust these automated code generation models? Consequently, there is a pressing need to understand the inner logic of code generation models and to investigate their replicability, reliability, and explainability. To bridge these research gaps, we conduct a thorough empirical study of five code generation models on four representative code generation datasets to assess the limits and capabilities of automatic code generation approaches. We further employ advanced explainable AI approaches to highlight the tokens that significantly contribute to the code generation. Experiments demonstrate that we successfully replicate state-of-the-art code generation approaches. We discover that state-of-the-art approaches suffer from severe data duplication and input insensitivity, which are subtle issues with significant implications. Our explainability analysis reveals that, in various experimental scenarios, code generation models can recognize code grammar and structural information, but can not capture key tokens that need to be updated. Our results draw several lessons and guidelines for future work in this area.},
  archiveprefix = {arXiv},
  arxivid       = {2302.09587},
  author        = {Liu, Yue and Tantithamthavorn, Chakkrit and Liu, Yonghui and Li, Li},
  eprint        = {2302.09587},
  number        = {1},
  pages         = {1--20},
  title         = {{On the Reliability and Explainability of Automated Code Generation Approaches}},
  url           = {http://arxiv.org/abs/2302.09587},
  volume        = {1},
  year          = {2023}
}


@article{10.1145/3324916,
  author     = {Ren, Xiaoxue and Xing, Zhenchang and Xia, Xin and Lo, David and Wang, Xinyu and Grundy, John},
  title      = {Neural Network-Based Detection of Self-Admitted Technical Debt: From Performance to Explainability},
  year       = {2019},
  issue_date = {July 2019},
  publisher  = {Association for Computing Machinery},
  address    = {New York, NY, USA},
  volume     = {28},
  number     = {3},
  issn       = {1049-331X},
  url        = {https://doi.org/10.1145/3324916},
  doi        = {10.1145/3324916},
  abstract   = {Technical debt is a metaphor to reflect the tradeoff software engineers make between short-term benefits and long-term stability. Self-admitted technical debt (SATD), a variant of technical debt, has been proposed to identify debt that is intentionally introduced during software development, e.g., temporary fixes and workarounds. Previous studies have leveraged human-summarized patterns (which represent n-gram phrases that can be used to identify SATD) or text-mining techniques to detect SATD in source code comments. However, several characteristics of SATD features in code comments, such as vocabulary diversity, project uniqueness, length, and semantic variations, pose a big challenge to the accuracy of pattern or traditional text-mining-based SATD detection, especially for cross-project deployment. Furthermore, although traditional text-mining-based method outperforms pattern-based method in prediction accuracy, the text features it uses are less intuitive than human-summarized patterns, which makes the prediction results hard to explain. To improve the accuracy of SATD prediction, especially for cross-project prediction, we propose a Convolutional Neural Network-- (CNN) based approach for classifying code comments as SATD or non-SATD. To improve the explainability of our model’s prediction results, we exploit the computational structure of CNNs to identify key phrases and patterns in code comments that are most relevant to SATD. We have conducted an extensive set of experiments with 62,566 code comments from 10 open-source projects and a user study with 150 comments of another three projects. Our evaluation confirms the effectiveness of different aspects of our approach and its superior performance, generalizability, adaptability, and explainability over current state-of-the-art traditional text-mining-based methods for SATD classification.},
  journal    = {ACM Trans. Softw. Eng. Methodol.},
  month      = {jul},
  articleno  = {15},
  numpages   = {45},
  keywords   = {convolutional neural network, Self-admitted technical debt, model explainability, model generalizability, model adaptability, cross project prediction}
}

@inproceedings{10.5555/2818754.2818851,
  author    = {Peters, Fayola and Menzies, Tim and Layman, Lucas},
  title     = {LACE2: Better Privacy-Preserving Data Sharing for Cross Project Defect Prediction},
  year      = {2015},
  isbn      = {9781479919345},
  publisher = {IEEE Press},
  abstract  = {Before a community can learn general principles, it must share individual experiences. Data sharing is the fundamental step of cross project defect prediction, i.e. the process of using data from one project to predict for defects in another. Prior work on secure data sharing allowed data owners to share their data on a single-party basis for defect prediction via data minimization and obfuscation. However the studied method did not consider that bigger data required the data owner to share more of their data.In this paper, we extend previous work with LACE2 which reduces the amount of data shared by using multi-party data sharing. Here data owners incrementally add data to a cache passed among them and contribute "interesting" data that are not similar to the current content of the cache. Also, before data owner i passes the cache to data owner j, privacy is preserved by applying obfuscation algorithms to hide project details. The experiments of this paper show that (a) LACE2 is comparatively less expensive than the single-party approach and (b) the multi-party approach of LACE2 yields higher privacy than the prior approach without damaging predictive efficacy (indeed, in some cases, LACE2 leads to better defect predictors).},
  booktitle = {Proceedings of the 37th International Conference on Software Engineering - Volume 1},
  pages     = {801–811},
  numpages  = {11},
  location  = {Florence, Italy},
  series    = {ICSE '15}
}

@article{10.1145/3429444,
  author     = {Zou, Deqing and Zhu, Yawei and Xu, Shouhuai and Li, Zhen and Jin, Hai and Ye, Hengkai},
  title      = {Interpreting Deep Learning-Based Vulnerability Detector Predictions Based on Heuristic Searching},
  year       = {2021},
  issue_date = {April 2021},
  publisher  = {Association for Computing Machinery},
  address    = {New York, NY, USA},
  volume     = {30},
  number     = {2},
  issn       = {1049-331X},
  url        = {https://doi.org/10.1145/3429444},
  doi        = {10.1145/3429444},
  abstract   = {Detecting software vulnerabilities is an important problem and a recent development in tackling the problem is the use of deep learning models to detect software vulnerabilities. While effective, it is hard to explain why a deep learning model predicts a piece of code as vulnerable or not because of the black-box nature of deep learning models. Indeed, the interpretability of deep learning models is a daunting open problem. In this article, we make a significant step toward tackling the interpretability of deep learning model in vulnerability detection. Specifically, we introduce a high-fidelity explanation framework, which aims to identify a small number of tokens that make significant contributions to a detector’s prediction with respect to an example. Systematic experiments show that the framework indeed has a higher fidelity than existing methods, especially when features are not independent of each other (which often occurs in the real world). In particular, the framework can produce some vulnerability rules that can be understood by domain experts for accepting a detector’s outputs (i.e., true positives) or rejecting a detector’s outputs (i.e., false-positives and false-negatives). We also discuss limitations of the present study, which indicate interesting open problems for future research.},
  journal    = {ACM Trans. Softw. Eng. Methodol.},
  month      = {mar},
  articleno  = {23},
  numpages   = {31},
  keywords   = {sensitivity analysis, vulnerability detection, Explainable AI, deep learning}
}

@inproceedings{10.1007/978-3-030-60029-7-32,
  author    = {Zhu, Mingdong and Wang, Xianfang and Zhang, Yang},
  title     = {Interpretable Text-to-SQL Generation with Joint Optimization},
  year      = {2020},
  isbn      = {978-3-030-60028-0},
  publisher = {Springer-Verlag},
  address   = {Berlin, Heidelberg},
  url       = {https://doi.org/10.1007/978-3-030-60029-7_32},
  doi       = {10.1007/978-3-030-60029-7_32},
  abstract  = {The purpose of Text-to-SQL is to obtain the correct answer for a textual question from the database, which can take advantage of advanced database system to provide reliable and efficient response. Existing Text-to-SQL methods generally focus on accuracy by designing complex deep neural network models, and hardly consider interpretability, which is very important for serious applications. To address this, in this paper we propose a novel framework for Interpretable Text-to-SQL Generation (ITSG) with joint optimization, which achieves state-of-the-art accuracy and possesses two-level interpretability at the same time. The framework mainly consists of three layers: a sequence encoder which encodes questions, table headers and significant table contents, an attention-based LSTM layer which generates SQL queries and a reinforcement learning layer which boosts the execution accuracy. Comparing with state-of-the-art methods on benchmark datasets, the experimental results show the effectiveness and interpretability of our ITSG framework.},
  booktitle = {Web Information Systems and Applications: 17th International Conference, WISA 2020, Guangzhou, China, September 23–25, 2020, Proceedings},
  pages     = {341–351},
  numpages  = {11},
  keywords  = {Reinforcement learning, Attention-based LSTM, Interpretability, Text-to-SQL},
  location  = {Guangzhou, China}
}

@inproceedings{10.1145/3411764.3445646,
  author    = {Zhang, Tianyi and Chen, Zhiyang and Zhu, Yuanli and Vaithilingam, Priyan and Wang, Xinyu and Glassman, Elena L.},
  title     = {Interpretable Program Synthesis},
  year      = {2021},
  isbn      = {9781450380966},
  publisher = {Association for Computing Machinery},
  address   = {New York, NY, USA},
  url       = {https://doi.org/10.1145/3411764.3445646},
  doi       = {10.1145/3411764.3445646},
  abstract  = {Program synthesis, which generates programs based on user-provided specifications, can be obscure and brittle: users have few ways to understand and recover from synthesis failures. We propose interpretable program synthesis, a novel approach that unveils the synthesis process and enables users to monitor and guide a synthesizer. We designed three representations that explain the underlying synthesis process with different levels of fidelity. We implemented an interpretable synthesizer for regular expressions and conducted a within-subjects study with eighteen participants on three challenging regex tasks. With interpretable synthesis, participants were able to reason about synthesis failures and provide strategic feedback, achieving a significantly higher success rate compared with a state-of-the-art synthesizer. In particular, participants with a high engagement tendency (as measured by NCS-6) preferred a deductive representation that shows the synthesis process in a search tree, while participants with a relatively low engagement tendency preferred an inductive representation that renders representative samples of programs enumerated during synthesis.},
  booktitle = {Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems},
  articleno = {105},
  numpages  = {16},
  keywords  = {Interpretability, Program synthesis, Programming by example},
  location  = {Yokohama, Japan},
  series    = {CHI '21}
}

@article{li2022competition,
  title     = {Competition-level code generation with alphacode},
  author    = {Li, Yujia and Choi, David and Chung, Junyoung and Kushman, Nate and Schrittwieser, Julian and Leblond, R{\'e}mi and Eccles, Tom and Keeling, James and Gimeno, Felix and Dal Lago, Agustin and others},
  journal   = {Science},
  volume    = {378},
  number    = {6624},
  pages     = {1092--1097},
  year      = {2022},
  publisher = {American Association for the Advancement of Science}
}

@book{tunstall2022natural,
  title     = {Natural language processing with transformers},
  author    = {Tunstall, Lewis and Von Werra, Leandro and Wolf, Thomas},
  year      = {2022},
  publisher = {" O'Reilly Media, Inc."}
}

@misc{codet5p,
  title         = {CodeT5+: Open Code Large Language Models for Code Understanding and Generation},
  author        = {Yue Wang and Hung Le and Akhilesh Deepak Gotmare and Nghi D. Q. Bui and Junnan Li and Steven C. H. Hoi},
  year          = {2023},
  eprint        = {2305.07922},
  archiveprefix = {arXiv},
  primaryclass  = {cs.CL}
}

@inproceedings{yang2023users,
  title     = {What Do Users Ask in Open-Source AI Repositories? An Empirical Study of GitHub Issues},
  author    = {Zhou Yang and Chenyu Wang and Jieke Shi and Thong Hoang and Pavneet Kochhar and Qinghua Lu and Zhenchang Xing and David Lo},
  year      = {2023},
  booktitle = {Proceedings of the 20th International Conference on Mining Software Repositories},
  numpages  = {12},
  series    = {MSR '23}
}

@inproceedings{NICHE,
  author    = {Widyasari, Ratnadira and Yang, Zhou and Thung, Ferdian and Sim, Sheng Qin and Wee, Fiona and Lok, Camellia and Phan, Jack and Qi, Haodi and Tan, Constance and Tay, Qijin and Lo, David},
  keywords  = {Software Engineering (cs.SE), FOS: Computer and information sciences, FOS: Computer and information sciences},
  title     = {NICHE: A Curated Dataset of Engineered Machine Learning Projects in Python},
  booktitle = {Proceedings of the 20th International Conference on Mining Software Repositories},
  numpages  = {5},
  series    = {MSR '23}
}


@inproceedings{9678706,
  author    = {Applis, Leonhard and Panichella, Annibale and van Deursen, Arie},
  booktitle = {2021 36th IEEE/ACM International Conference on Automated Software Engineering (ASE)},
  title     = {Assessing Robustness of ML-Based Program Analysis Tools using Metamorphic Program Transformations},
  year      = {2021},
  volume    = {},
  number    = {},
  pages     = {1377-1381},
  doi       = {10.1109/ASE51524.2021.9678706}
}

@article{MHM,
  title   = {Generating Adversarial Examples for Holding Robustness of Source Code Processing Models},
  volume  = {34},
  number  = {01},
  journal = {Proceedings of the AAAI Conference on Artificial Intelligence},
  author  = {Zhang, Huangzhao and Li, Zhuo and Li, Ge and Ma, Lei and Liu, Yang and Jin, Zhi},
  year    = {2020},
  month   = {Apr.},
  pages   = {1169-1176}
}

@article{Epresentation2021,
  author   = {Shashank Srikant and
              Sijia Liu and
              Tamara Mitrovska and
              Shiyu Chang and
              Quanfu Fan and
              Gaoyuan Zhang and
              Una{-}May O'Reilly},
  journal  = {ICLR},
  keywords = {minecraft. programming input,programming-learning},
  pages    = {209--226},
  title    = {{Generating Adversarial Computer Programs using Optimized Obfuscations}},
  volume   = {16},
  year     = {2021}
}

@article{metropolis1953equation,
  title     = {Equation of state calculations by fast computing machines},
  author    = {Metropolis, Nicholas and Rosenbluth, Arianna W and Rosenbluth, Marshall N and Teller, Augusta H and Teller, Edward},
  journal   = {The journal of chemical physics},
  volume    = {21},
  number    = {6},
  pages     = {1087--1092},
  year      = {1953},
  publisher = {American Institute of Physics}
}



@inproceedings{10123641,
  author    = {d’Aragona, Dario Amoroso and Pecorelli, Fabiano and Baldassarre, Maria Teresa and Taibi, Davide and Lenarduzzi, Valentina},
  booktitle = {2023 IEEE International Conference on Software Analysis, Evolution and Reengineering (SANER)},
  title     = {Technical Debt Diffuseness in the Apache Ecosystem: A Differentiated Replication},
  year      = {2023},
  volume    = {},
  number    = {},
  pages     = {825-833},
  doi       = {10.1109/SANER56733.2023.00095}
}

@article{fundation-models,
  title   = {On the opportunities and risks of foundation models},
  author  = {Bommasani, Rishi and Hudson, Drew A and Adeli, Ehsan and Altman, Russ and Arora, Simran and von Arx, Sydney and Bernstein, Michael S and Bohg, Jeannette and Bosselut, Antoine and Brunskill, Emma and others},
  journal = {arXiv preprint arXiv:2108.07258},
  year    = {2021}
}

@misc{ecosystem-graph,
  title         = {Ecosystem Graphs: The Social Footprint of Foundation Models},
  author        = {Rishi Bommasani and Dilara Soylu and Thomas I. Liao and Kathleen A. Creel and Percy Liang},
  year          = {2023},
  eprint        = {2303.15772},
  archiveprefix = {arXiv},
  primaryclass  = {cs.LG}
}

@inproceedings{massacci2021technical,
  title        = {Technical leverage in a software ecosystem: Development opportunities and security risks},
  author       = {Massacci, Fabio and Pashchenko, Ivan},
  booktitle    = {2021 IEEE/ACM 43rd International Conference on Software Engineering (ICSE)},
  pages        = {1386--1397},
  year         = {2021},
  organization = {IEEE}
}

@inproceedings{7962382,
  author    = {Cito, Jürgen and Schermann, Gerald and Wittern, John Erik and Leitner, Philipp and Zumberi, Sali and Gall, Harald C.},
  booktitle = {2017 IEEE/ACM 14th International Conference on Mining Software Repositories (MSR)},
  title     = {An Empirical Analysis of the Docker Container Ecosystem on GitHub},
  year      = {2017},
  volume    = {},
  number    = {},
  pages     = {323-333},
  doi       = {10.1109/MSR.2017.67}
}


@article{10109341,
  author    = {C. Tantithamthavorn and J. Cito and H. Hemmati and S. Chandra},
  journal   = {IEEE Software},
  title     = {Explainable AI for SE: Challenges and Future Directions},
  year      = {2023},
  volume    = {40},
  number    = {03},
  issn      = {1937-4194},
  pages     = {29-33},
  abstract  = {In recent years, artificial intelligence/machine learning (AI/ML) have been widely used in software engineering (SE) to improve developer productivity, software quality, and decision making. This includes well-known tools for code completion (for example, GitHub’s Copilot) but also code search; automated task recommendation; automated developer recommendation; automated defect/vulnerability/malware prediction, detection, localization, and repair; and many other purposes.},
  keywords  = {},
  doi       = {10.1109/MS.2023.3246686},
  publisher = {IEEE Computer Society},
  address   = {Los Alamitos, CA, USA},
  month     = {may}
}

@article{10.1145/3630010,
  author    = {Yang, Guang and Zhou, Yu and Yang, Wenhua and Yue, Tao and Chen, Xiang and Chen, Taolue},
  title     = {How Important Are Good Method Names in Neural Code Generation? A Model Robustness Perspective},
  year      = {2023},
  publisher = {Association for Computing Machinery},
  address   = {New York, NY, USA},
  issn      = {1049-331X},
  url       = {https://doi.org/10.1145/3630010},
  doi       = {10.1145/3630010},
  abstract  = {Pre-trained code generation models (PCGMs) have been widely applied in neural code generation which can generate executable code from functional descriptions in natural languages, possibly together with signatures. Despite substantial performance improvement of PCGMs, the role of method names in neural code generation has not been thoroughly investigated. In this paper, we study and demonstrate the potential of benefiting from method names to enhance the performance of PCGMs, from a model robustness perspective. Specifically, we propose a novel approach, named RADAR (neuRAl coDe generAtor Robustifier). RADAR consists of two components: RADAR-Attack and RADAR-Defense. The former attacks a PCGM by generating adversarial method names as part of the input, which are semantic and visual similar to the original input, but may trick the PCGM to generate completely unrelated code snippets. As a countermeasure to such attacks, RADAR-Defense synthesizes a new method name from the functional description and supplies it to the PCGM. Evaluation results show that RADAR-Attack can reduce the CodeBLEU of generated code by 19.72\% to 38.74\% in three state-of-the-art PCGMs (i.e., CodeGPT, PLBART, and CodeT5) in the fine-tuning code generation task, and reduce the Pass@1 of generated code by 32.28\% to 44.42\% in three state-of-the-art PCGMs (i.e., Replit, CodeGen, and CodeT5+) in the zero-shot code generation task. Moreover, RADAR-Defense is able to reinstate the performance of PCGMs with synthesized method names. These results highlight the importance of good method names in neural code generation and implicate the benefits of studying model robustness in software engineering.},
  note      = {Just Accepted},
  journal   = {ACM Trans. Softw. Eng. Methodol.},
  month     = {oct},
  keywords  = {Code generation, Robustness, Pre-trained model, Adversarial examples, Passive defense}
}

@article{RABIN2022100432,
  title    = {FeatureExtractor: A tool for extracting key input features of code intelligence models},
  journal  = {Software Impacts},
  volume   = {14},
  pages    = {100432},
  year     = {2022},
  issn     = {2665-9638},
  doi      = {https://doi.org/10.1016/j.simpa.2022.100432},
  url      = {https://www.sciencedirect.com/science/article/pii/S2665963822001166},
  author   = {Md Rafiqul Islam Rabin and Mohammad Amin Alipour},
  keywords = {Program reduction, Feature engineering, Transparency, Interpretability, Explainability, Models of code},
  abstract = {Although becoming successful in modeling source code, deep neural models are challenging to interpret. This opacity may lead to distrust in their prediction and hamper their wider adoption in safety–critical applications. Therefore, we propose a tool, referred to as FeatureExtractor, that aims at improving the transparency and explainability of opaque models. Given an input program and a code intelligence model, the tool applies a program reduction technique to reduce the size of the input program while preserving the prediction of the model. The goal is to identify key input features from reduced programs for explaining the model’s prediction.}
}

@misc{paltenghi2022extracting,
  title         = {Extracting Meaningful Attention on Source Code: An Empirical Study of Developer and Neural Model Code Exploration},
  author        = {Matteo Paltenghi and Rahul Pandita and Austin Z. Henley and Albert Ziegler},
  year          = {2022},
  eprint        = {2210.05506},
  archiveprefix = {arXiv},
  primaryclass  = {cs.SE}
}

@article{9044387,
  author  = {Jiarpakdee, Jirayus and Tantithamthavorn, Chakkrit Kla and Dam, Hoa Khanh and Grundy, John},
  journal = {IEEE Transactions on Software Engineering},
  title   = {An Empirical Study of Model-Agnostic Techniques for Defect Prediction Models},
  year    = {2022},
  volume  = {48},
  number  = {1},
  pages   = {166-185},
  doi     = {10.1109/TSE.2020.2982385}
}



@misc{shin2021explainable,
  title         = {Explainable Software Defect Prediction: Are We There Yet?},
  author        = {Jiho Shin and Reem Aleithan and Jaechang Nam and Junjie Wang and Song Wang},
  year          = {2021},
  eprint        = {2111.10901},
  archiveprefix = {arXiv},
  primaryclass  = {cs.SE}
}

@inproceedings{Reemicse21,
  author    = {Aleithan, Reem},
  title     = {Explainable Just-in-Time Bug Prediction: Are We There Yet?},
  year      = {2021},
  publisher = {IEEE Press},
  url       = {https://doi.org/10.1109/ICSE-Companion52605.2021.00056},
  doi       = {10.1109/ICSE-Companion52605.2021.00056},
  abstract  = {Explaining the prediction results of software bug prediction models is a challenging task, which can provide useful information for developers to understand and fix the predicted bugs. Recently, Jirayus et al. [4] proposed to use two model-agnostic techniques (i.e., LIME and iBreakDown) to explain the prediction results of bug prediction models. Although their experiments on file-level bug prediction show promising results, the performance of these techniques on explaining the results of just-in-time (i.e., change-level) bug prediction is unknown. This paper conducts the first empirical study to explore the explainability of these model-agnostic techniques on just-in-time bug prediction models. Specifically, this study takes a three-step approach, 1) replicating previously widely used just-in-time bug prediction models, 2) applying Local Interpretability Model-agnostic Explanation Technique (LIME) and iBreakDown on the prediction results, and 3) manually evaluating the explanations for buggy instances (i.e. positive predictions) against the root cause of the bugs. The results of our experiment show that LIME and iBreakDown fail to explain defect prediction explanations for just-in-time bug prediction models, unlike file-level [4]. This paper urges for new approaches for explaining the results of just-in-time bug prediction models.},
  booktitle = {Proceedings of the 43rd International Conference on Software Engineering: Companion Proceedings},
  pages     = {129–131},
  numpages  = {3},
  keywords  = {bug prediction, prediction explanation},
  location  = {Virtual Event, Spain},
  series    = {ICSE '21}
}


@article{Mohammadkhani2022,
  abstract      = {In recent years, there has been a wide interest in designing deep neural network-based models that automate downstream software engineering tasks, such as program document generation, code search, and program repair. Although the main objective of these studies is to improve the effectiveness of the downstream task, many studies only attempt to employ the next best neural network model, without a proper in-depth analysis of why a particular solution works or does not, on particular tasks or scenarios. In this paper, using an eXplainable AI (XAI) method (attention mechanism), we study state-of-the-art Transformer-based models (CodeBERT and GraphCodeBERT) on a set of software engineering downstream tasks: code document generation (CDG), code refinement (CR), and code translation (CT). We first evaluate the validity of the attention mechanism on each particular task. Then, through quantitative and qualitative studies, we identify what CodeBERT and GraphCodeBERT learn (put the highest attention on, in terms of source code token types), on these tasks. Finally, we show some of the common patterns when the model does not work as expected (perform poorly while the problem in hand is easy) and suggest recommendations that may alleviate the observed challenges.},
  archiveprefix = {arXiv},
  arxivid       = {2211.12821},
  author        = {Mohammadkhani, Ahmad Haji and Tantithamthavorn, Chakkrit and Hemmati, Hadi},
  eprint        = {2211.12821},
  file          = {:Users/zhouyang/SynologyDrive/Mendeley/Explainable AI for Pre-Trained Code Models What Do They Learn When They Do Not Work - Mohammadkhani, Tantithamthavorn, Hemmati - Unknown.pdf:pdf},
  keywords      = {a,attention,codebert,explainable ai,graphcodebert,haji mohammadkhani,interpretable machine learning,transformer,university of calgary,xai},
  title         = {{Explainable AI for Pre-Trained Code Models: What Do They Learn? When They Do Not Work?}},
  url           = {http://arxiv.org/abs/2211.12821},
  year          = {2022}
}

@article{10232920,
  author    = {Y. Li and T. Zhang and X. Luo and H. Cai and S. Fang and D. Yuan},
  journal   = {IEEE Transactions on Software Engineering},
  title     = {Do Pretrained Language Models Indeed Understand Software Engineering Tasks?},
  year      = {2023},
  volume    = {49},
  number    = {10},
  issn      = {1939-3520},
  pages     = {4639-4655},
  abstract  = {Artificial intelligence (AI) for software engineering (SE) tasks has recently achieved promising performance. In this article, we investigate to what extent the pre-trained language model truly understands those SE tasks such as code search, code summarization, etc. We conduct a comprehensive empirical study on a board set of AI for SE (AI4SE) tasks by feeding them with variant inputs: 1) with various masking rates and 2) with sufficient input subset method. Then, the trained models are evaluated on different SE tasks, including code search, code summarization, and duplicate bug report detection. Our experimental results show that pre-trained language models are insensitive to the given input, thus they achieve similar performance in these three SE tasks. We refer to this phenomenon as overinterpretation, where a model confidently makes a decision without salient features, or where a model finds some irrelevant relationships between the final decision and the dataset. Our study investigates two approaches to mitigate the overinterpretation phenomenon: whole word mask strategy and ensembling. To the best of our knowledge, we are the first to reveal this overinterpretation phenomenon to the AI4SE community, which is an important reminder for researchers to design the input for the models and calls for necessary future work in understanding and implementing AI4SE tasks.},
  keywords  = {task analysis;codes;computer bugs;software engineering;artificial intelligence;deep learning;computational modeling},
  doi       = {10.1109/TSE.2023.3308952},
  publisher = {IEEE Computer Society},
  address   = {Los Alamitos, CA, USA},
  month     = {oct}
}


@inproceedings{10.1145/3324884.3416583,
  author    = {Wang, Xin and Liu, Jin and Li, Li and Chen, Xiao and Liu, Xiao and Wu, Hao},
  title     = {Detecting and Explaining Self-Admitted Technical Debts with Attention-Based Neural Networks},
  year      = {2021},
  isbn      = {9781450367684},
  publisher = {Association for Computing Machinery},
  address   = {New York, NY, USA},
  url       = {https://doi.org/10.1145/3324884.3416583},
  doi       = {10.1145/3324884.3416583},
  abstract  = {Self-Admitted Technical Debt (SATD) is a sub-type of technical debt. It is introduced to represent such technical debts that are intentionally introduced by developers in the process of software development. While being able to gain short-term benefits, the introduction of SATDs often requires to be paid back later with a higher cost, e.g., introducing bugs to the software or increasing the complexity of the software.To cope with these issues, our community has proposed various machine learning-based approaches to detect SATDs. These approaches, however, are either not generic that usually require manual feature engineering efforts or do not provide promising means to explain the predicted outcomes. To that end, we propose to the community a novel approach, namely HATD (Hybrid Attention-based method for self-admitted Technical Debt detection), to detect and explain SATDs using attention-based neural networks. Through extensive experiments on 445,365 comments in 20 projects, we show that HATD is effective in detecting SATDs on both in-the-lab and in-the-wild datasets under both within-project and cross-project settings. HATD also outperforms the state-of-the-art approaches in detecting and explaining SATDs.},
  booktitle = {Proceedings of the 35th IEEE/ACM International Conference on Automated Software Engineering},
  pages     = {871–882},
  numpages  = {12},
  keywords  = {SATD, attention-based neural networks, self-admitted technical debt, word embedding},
  location  = {Virtual Event, Australia},
  series    = {ASE '20}
}

@misc{wang2023demystifying,
  title         = {Demystifying What Code Summarization Models Learned},
  author        = {Yu Wang and Ke Wang},
  year          = {2023},
  eprint        = {2303.02333},
  archiveprefix = {arXiv},
  primaryclass  = {cs.PL}
}

@inproceedings{10.1145/3510457.3513081,
  author    = {Cito, J\"{u}rgen and Dillig, Isil and Murali, Vijayaraghavan and Chandra, Satish},
  title     = {Counterfactual Explanations for Models of Code},
  year      = {2022},
  isbn      = {9781450392266},
  publisher = {Association for Computing Machinery},
  address   = {New York, NY, USA},
  url       = {https://doi.org/10.1145/3510457.3513081},
  doi       = {10.1145/3510457.3513081},
  abstract  = {Machine learning (ML) models play an increasingly prevalent role in many software engineering tasks. However, because most models are now powered by opaque deep neural networks, it can be difficult for developers to understand why the model came to a certain conclusion and how to act upon the model's prediction. Motivated by this problem, this paper explores counterfactual explanations for models of source code. Such counterfactual explanations constitute minimal changes to the source code under which the model "changes its mind". We integrate counterfactual explanation generation to models of source code in a real-world setting. We describe considerations that impact both the ability to find realistic and plausible counterfactual explanations, as well as the usefulness of such explanation to the developers that use the model. In a series of experiments we investigate the efficacy of our approach on three different models, each based on a BERT-like architecture operating over source code.},
  booktitle = {Proceedings of the 44th International Conference on Software Engineering: Software Engineering in Practice},
  pages     = {125–134},
  numpages  = {10},
  location  = {Pittsburgh, Pennsylvania},
  series    = {ICSE-SEIP '22}
}

@inproceedings{10123571,
  author    = {A. M. Mir and M. Keshani and S. Proksch},
  booktitle = {2023 IEEE International Conference on Software Analysis, Evolution and Reengineering (SANER)},
  title     = {On the Effect of Transitivity and Granularity on Vulnerability Propagation in the Maven Ecosystem},
  year      = {2023},
  volume    = {},
  issn      = {},
  pages     = {201-211},
  abstract  = {Reusing software libraries is a pillar of modern software engineering. In 2022, the average Java application depends on 40 third-party libraries. Relying on such libraries exposes a project to potential vulnerabilities and may put an application and its users at risk. Unfortunately, research on software ecosystems has shown that the number of projects that are affected by such vulnerabilities is rising. Previous investigations usually reason about dependencies on the dependency level, but we believe that this highly inflates the actual number of affected projects. In this work, we study the effect of transitivity and granularity on vulnerability propagation in the Maven ecosystem. In our research methodology, we gather a large dataset of 3M recent Maven packages. We obtain the full transitive set of dependencies for this dataset, construct whole-program call graphs, and perform reachability analysis. This approach allows us to identify Maven packages that are actually affected by using vulnerable dependencies. Our empirical results show that: (1) about 1/3 of packages in our dataset are identified as vulnerable if and only if all the transitive dependencies are considered. (2) less than 1% of packages have a reachable call path to vulnerable code in their dependencies, which is far lower than that of a naive dependency-based analysis. (3) limiting the depth of the resolved dependency tree might be a useful technique to reduce computation time for expensive fine-grained (vulnerability) analysis. We discuss the implications of our work and provide actionable insights for researchers and practitioners.},
  keywords  = {java;software libraries;limiting;codes;ecosystems;software;reachability analysis},
  doi       = {10.1109/SANER56733.2023.00028},
  url       = {https://doi.ieeecomputersociety.org/10.1109/SANER56733.2023.00028},
  publisher = {IEEE Computer Society},
  address   = {Los Alamitos, CA, USA},
  month     = {mar}
}


@inproceedings{9794026,
  author    = {Liu, Chengwei and Chen, Sen and Fan, Lingling and Chen, Bihuan and Liu, Yang and Peng, Xin},
  booktitle = {2022 IEEE/ACM 44th International Conference on Software Engineering (ICSE)},
  title     = {Demystifying the Vulnerability Propagation and Its Evolution via Dependency Trees in the NPM Ecosystem},
  year      = {2022},
  volume    = {},
  number    = {},
  pages     = {672-684},
  doi       = {10.1145/3510003.3510142}
}

@inproceedings{10.1007/978-3-031-08129-3_6,
  author    = {Makari, Ilyas Sa{\"i}d
               and Zerouali, Ahmed
               and De Roover, Coen},
  editor    = {Perrouin, Gilles
               and Moha, Naouel
               and Seriai, Abdelhak-Djamel},
  title     = {Prevalence and Evolution of License Violations in npm and RubyGems Dependency Networks},
  booktitle = {Reuse and Software Quality},
  year      = {2022},
  publisher = {Springer International Publishing},
  address   = {Cham},
  pages     = {85--100},
  abstract  = {It can be challenging to manage an open source package from a licensing perspective. License violations can be introduced by both direct and indirect package dependencies, which evolve independently. In this paper, we propose a license compatibility matrix as the foundation for a tool that can help maintainers assess the compliance of their package with the licenses of its dependencies. Using this tool, we empirically study the evolution, popularity, and compliance with dependency licenses in the npm and RubyGems software package ecosystems. The size of the corresponding dependency networks renders verifying license compliance for indirect dependencies computationally expensive. We found that 7.3{\%} of npm packages and 13.9{\%} of RubyGems have direct or indirect dependencies with incompatible licenses. We also found that GPL dependencies are the major cause for incompatibilities. Our results provide a good understanding of the state of license incompatibilities in software package ecosystems, and suggest that individual ecosystems can differ significantly in this regard.},
  isbn      = {978-3-031-08129-3}
}



@misc{CFSA,
  doi       = {10.48550/ARXIV.2302.08018},
  url       = {https://arxiv.org/abs/2302.08018},
  author    = {Wang, Zichong and Zhou, Yang and Qiu, Meikang and Haque, Israat and Brown, Laura and He, Yi and Wang, Jianwu and Lo, David and Zhang, Wenbin},
  keywords  = {Software Engineering (cs.SE), Artificial Intelligence (cs.AI), FOS: Computer and information sciences, FOS: Computer and information sciences},
  title     = {Towards Fair Machine Learning Software: Understanding and Addressing Model Bias Through Counterfactual Thinking},
  publisher = {arXiv},
  year      = {2023},
  copyright = {Creative Commons Zero v1.0 Universal}
}

@inproceedings{8453117,
  author    = {Trockman, Asher and Zhou, Shurui and Kästner, Christian and Vasilescu, Bogdan},
  booktitle = {2018 IEEE/ACM 40th International Conference on Software Engineering (ICSE)},
  title     = {Adding Sparkle to Social Coding: An Empirical Study of Repository Badges in the npm Ecosystem},
  year      = {2018},
  volume    = {},
  number    = {},
  pages     = {511-522},
  doi       = {10.1145/3180155.3180209}
}


@inproceedings{9284138,
  author    = {Wang, Ying and Wen, Ming and Liu, Yepang and Wang, Yibo and Li, Zhenming and Wang, Chao and Yu, Hai and Cheung, Shing-Chi and Xu, Chang and Zhu, Zhiliang},
  booktitle = {2020 IEEE/ACM 42nd International Conference on Software Engineering (ICSE)},
  title     = {Watchman: Monitoring Dependency Conflicts for Python Library Ecosystem},
  year      = {2020},
  volume    = {},
  number    = {},
  pages     = {125-135},
  doi       = {10.1145/3377811.3380426}
}

@inproceedings{li-etal-2022-semantic,
  title     = {Semantic-Preserving Adversarial Code Comprehension},
  author    = {Li, Yiyang  and
               Wu, Hongqiu  and
               Zhao, Hai},
  booktitle = {Proceedings of the 29th International Conference on Computational Linguistics},
  month     = oct,
  year      = {2022},
  address   = {Gyeongju, Republic of Korea},
  publisher = {International Committee on Computational Linguistics},
  url       = {https://aclanthology.org/2022.coling-1.267},
  pages     = {3017--3028},
  abstract  = {Based on the tremendous success of pre-trained language models (PrLMs) for source code comprehension tasks, current literature studies either ways to further improve the performance (generalization) of PrLMs, or their robustness against adversarial attacks. However, they have to compromise on the trade-off between the two aspects and none of them consider improving both sides in an effective and practical way. To fill this gap, we propose Semantic-Preserving Adversarial Code Embeddings (SPACE) to find the worst-case semantic-preserving attacks while forcing the model to predict the correct labels under these worst cases. Experiments and analysis demonstrate that SPACE can stay robust against state-of-the-art attacks while boosting the performance of PrLMs for code.}
}

@inproceedings{9425974,
  author    = {Alfadel, Mahmoud and Costa, Diego Elias and Shihab, Emad},
  booktitle = {2021 IEEE International Conference on Software Analysis, Evolution and Reengineering (SANER)},
  title     = {Empirical Analysis of Security Vulnerabilities in Python Packages},
  year      = {2021},
  volume    = {},
  number    = {},
  pages     = {446-457},
  doi       = {10.1109/SANER50967.2021.00048}
}


@inproceedings{9284011,
  author    = {Ma, Wanwangying and Chen, Lin and Zhang, Xiangyu and Feng, Yang and Xu, Zhaogui and Chen, Zhifei and Zhou, Yuming and Xu, Baowen},
  booktitle = {2020 IEEE/ACM 42nd International Conference on Software Engineering (ICSE)},
  title     = {Impact Analysis of Cross-Project Bugs on Software Ecosystems},
  year      = {2020},
  volume    = {},
  number    = {},
  pages     = {100-111},
  doi       = {}
}



@book{messerschmitt2003software,
  title     = {Software ecosystem: understanding an indispensable technology and industry},
  author    = {Messerschmitt, David G and Szyperski, Clemens and others},
  volume    = {1},
  year      = {2003},
  publisher = {MIT press Cambridge}
}

@inproceedings{mikolov2010recurrent,
  title        = {Recurrent neural network based language model.},
  author       = {Mikolov, Tomas and Karafi{\'a}t, Martin and Burget, Lukas and Cernock{\`y}, Jan and Khudanpur, Sanjeev},
  booktitle    = {Interspeech},
  volume       = {2},
  number       = {3},
  pages        = {1045--1048},
  year         = {2010},
  organization = {Makuhari}
}

@article{bengio2000neural,
  title   = {A neural probabilistic language model},
  author  = {Bengio, Yoshua and Ducharme, R{\'e}jean and Vincent, Pascal},
  journal = {Advances in neural information processing systems},
  volume  = {13},
  year    = {2000}
}

@book{jelinek1998statistical,
  title     = {Statistical methods for speech recognition},
  author    = {Jelinek, Frederick},
  year      = {1998},
  publisher = {MIT press}
}

@article{rosenfeld2000two,
  title     = {Two decades of statistical language modeling: Where do we go from here?},
  author    = {Rosenfeld, Ronald},
  journal   = {Proceedings of the IEEE},
  volume    = {88},
  number    = {8},
  pages     = {1270--1278},
  year      = {2000},
  publisher = {IEEE}
}

@inproceedings{stolcke2002srilm,
  title     = {SRILM-an extensible language modeling toolkit},
  author    = {Stolcke, Andreas},
  booktitle = {Seventh international conference on spoken language processing},
  year      = {2002}
}

@article{1165125,
  author  = {Katz, S.},
  journal = {IEEE Transactions on Acoustics, Speech, and Signal Processing},
  title   = {Estimation of probabilities from sparse data for the language model component of a speech recognizer},
  year    = {1987},
  volume  = {35},
  number  = {3},
  pages   = {400-401},
  doi     = {10.1109/TASSP.1987.1165125}
}

@article{gale1995good,
  title     = {Good-turing frequency estimation without tears},
  author    = {Gale, William A and Sampson, Geoffrey},
  journal   = {Journal of quantitative linguistics},
  volume    = {2},
  number    = {3},
  pages     = {217--237},
  year      = {1995},
  publisher = {Taylor \& Francis}
}

@inproceedings{gpt-3,
  author    = {Brown, Tom and Mann, Benjamin and Ryder, Nick et al.},
  booktitle = {Advances in Neural Information Processing Systems},
  editor    = {H. Larochelle and M. Ranzato and R. Hadsell and M.F. Balcan and H. Lin},
  pages     = {1877--1901},
  publisher = {Curran Associates, Inc.},
  title     = {Language Models are Few-Shot Learners},
  volume    = {33},
  year      = {2020}
}

@inproceedings{naturalness,
  author    = {Hindle, Abram and Barr, Earl T. and Su, Zhendong and Gabel, Mark and Devanbu, Premkumar},
  title     = {On the Naturalness of Software},
  year      = {2012},
  isbn      = {9781467310673},
  publisher = {IEEE Press},
  abstract  = {Natural languages like English are rich, complex, and powerful. The highly creative and graceful use of languages like English and Tamil, by masters like Shakespeare and Avvaiyar, can certainly delight and inspire. But in practice, given cognitive constraints and the exigencies of daily life, most human utterances are far simpler and much more repetitive and predictable. In fact, these utterances can be very usefully modeled using modern statistical methods. This fact has led to the phenomenal success of statistical approaches to speech recognition, natural language translation, question-answering, and text mining and comprehension. We begin with the conjecture that most software is also natural, in the sense that it is created by humans at work, with all the attendant constraints and limitations---and thus, like natural language, it is also likely to be repetitive and predictable. We then proceed to ask whether a) code can be usefully modeled by statistical language models and b) such models can be leveraged to support software engineers. Using the widely adopted n-gram model, we provide empirical evidence supportive of a positive answer to both these questions. We show that code is also very repetitive, and in fact even more so than natural languages. As an example use of the model, we have developed a simple code completion engine for Java that, despite its simplicity, already improves Eclipse's completion capability. We conclude the paper by laying out a vision for future research in this area.},
  booktitle = {Proceedings of the 34th International Conference on Software Engineering},
  pages     = {837–847},
  numpages  = {11},
  location  = {Zurich, Switzerland},
  series    = {ICSE '12}
}

@inproceedings{alert,
  author    = {Yang, Zhou and Shi, Jieke and He, Junda and Lo, David},
  title     = {Natural Attack for Pre-Trained Models of Code},
  year      = {2022},
  isbn      = {9781450392211},
  publisher = {Association for Computing Machinery},
  address   = {New York, NY, USA},
  url       = {https://doi.org/10.1145/3510003.3510146},
  doi       = {10.1145/3510003.3510146},
  booktitle = {Proceedings of the 44th International Conference on Software Engineering},
  pages     = {1482–1493},
  numpages  = {12},
  keywords  = {genetic algorithm, pre-trained models, adversarial attack},
  location  = {Pittsburgh, Pennsylvania},
  series    = {ICSE '22}
}

@misc{codecompose,
  title         = {CodeCompose: A Large-Scale Industrial Deployment of AI-assisted Code Authoring},
  author        = {Vijayaraghavan Murali and Chandra Maddila and Imad Ahmad and Michael Bolin and Daniel Cheng and Negar Ghorbani and Renuka Fernandez and Nachiappan Nagappan},
  year          = {2023},
  eprint        = {2305.12050},
  archiveprefix = {arXiv},
  primaryclass  = {cs.SE}
}

@inproceedings{291327,
  author    = {Liang Niu and Shujaat Mirza and Zayd Maradni and Christina P{\"o}pper},
  title     = {{CodexLeaks}: Privacy Leaks from Code Generation Language Models in {GitHub} Copilot},
  booktitle = {32nd USENIX Security Symposium (USENIX Security 23)},
  year      = {2023},
  isbn      = {978-1-939133-37-3},
  address   = {Anaheim, CA},
  pages     = {2133--2150},
  url       = {https://www.usenix.org/conference/usenixsecurity23/presentation/niu},
  publisher = {USENIX Association},
  month     = aug
}

@article{ouyang2022training,
  title   = {Training language models to follow instructions with human feedback},
  author  = {Ouyang, Long and Wu, Jeffrey and Jiang, Xu and Almeida, Diogo and Wainwright, Carroll and Mishkin, Pamela and Zhang, Chong and Agarwal, Sandhini and Slama, Katarina and Ray, Alex and others},
  journal = {Advances in Neural Information Processing Systems},
  volume  = {35},
  pages   = {27730--27744},
  year    = {2022}
}


@article{CodeXGLUE,
  author        = {Shuai Lu and
                   Daya Guo and
                   Shuo Ren and
                   Junjie Huang and
                   Alexey Svyatkovskiy and
                   Ambrosio Blanco and
                   Colin B. Clement and
                   Dawn Drain and
                   Daxin Jiang and
                   Duyu Tang and
                   Ge Li and
                   Lidong Zhou and
                   Linjun Shou and
                   Long Zhou and
                   Michele Tufano and
                   Ming Gong and
                   Ming Zhou and
                   Nan Duan and
                   Neel Sundaresan and
                   Shao Kun Deng and
                   Shengyu Fu and
                   Shujie Liu},
  title         = {CodeXGLUE: {A} Machine Learning Benchmark Dataset for Code Understanding
                   and Generation},
  journal       = {CoRR},
  volume        = {abs/2102.04664},
  year          = {2021},
  archiveprefix = {arXiv},
  eprint        = {2102.04664}
}

@inproceedings{finnie2022robots,
  title     = {The robots are coming: Exploring the implications of openai codex on introductory programming},
  author    = {Finnie-Ansley, James and Denny, Paul and Becker, Brett A and Luxton-Reilly, Andrew and Prather, James},
  booktitle = {Proceedings of the 24th Australasian Computing Education Conference},
  pages     = {10--19},
  year      = {2022}
}

@article{codex,
  author     = {Mark Chen and
                Jerry Tworek and
                Heewoo Jun et al.},
  title      = {Evaluating Large Language Models Trained on Code},
  journal    = {CoRR},
  volume     = {abs/2107.03374},
  year       = {2021},
  url        = {https://arxiv.org/abs/2107.03374},
  eprinttype = {arXiv},
  eprint     = {2107.03374},
  timestamp  = {Tue, 20 Jul 2021 15:08:33 +0200},
  biburl     = {https://dblp.org/rec/journals/corr/abs-2107-03374.bib},
  bibsource  = {dblp computer science bibliography, https://dblp.org}
}

@inproceedings{big_code,
  author    = {R. Karampatsis and H. Babii and R. Robbes and C. Sutton and A. Janes},
  booktitle = {2020 IEEE/ACM 42nd International Conference on Software Engineering (ICSE)},
  title     = {Big Code != Big Vocabulary: Open-Vocabulary Models for Source Code},
  year      = {2020},
  volume    = {},
  issn      = {},
  pages     = {1073-1085},
  abstract  = {Statistical language modeling techniques have successfully been applied to large source code corpora, yielding a variety of new software development tools, such as tools for code suggestion, improving readability, and API migration. A major issue with these techniques is that code introduces new vocabulary at a far higher rate than natural language, as new identifier names proliferate. Both large vocabularies and out-of-vocabulary issues severely affect Neural Language Models (NLMs) of source code, degrading their performance and rendering them unable to scale. In this paper, we address this issue by: 1) studying how various modelling choices impact the resulting vocabulary on a large-scale corpus of 13,362 projects; 2) presenting an open vocabulary source code NLM that can scale to such a corpus, 100 times larger than in previous work; and 3) showing that such models outperform the state of the art on three distinct code corpora (Java, C, Python). To our knowledge, these are the largest NLMs for code that have been reported. All datasets, code, and trained models used in this work are publicly available.},
  keywords  = {training;vocabulary;adaptation models;computer bugs;predictive models;tools;software engineering},
  doi       = {},
  url       = {https://doi.ieeecomputersociety.org/},
  publisher = {IEEE Computer Society},
  address   = {Los Alamitos, CA, USA},
  month     = {oct}
}


@inproceedings{10.1145/3106237.3106290,
  author    = {Hellendoorn, Vincent J. and Devanbu, Premkumar},
  title     = {Are Deep Neural Networks the Best Choice for Modeling Source Code?},
  year      = {2017},
  isbn      = {9781450351058},
  publisher = {Association for Computing Machinery},
  address   = {New York, NY, USA},
  url       = {https://doi.org/10.1145/3106237.3106290},
  doi       = {10.1145/3106237.3106290},
  abstract  = {Current statistical language modeling techniques, including deep-learning based models, have proven to be quite effective for source code. We argue here that the special properties of source code can be exploited for further improvements. In this work, we enhance established language modeling approaches to handle the special challenges of modeling source code, such as: frequent changes, larger, changing vocabularies, deeply nested scopes, etc. We present a fast, nested language modeling toolkit specifically designed for software, with the ability to add &amp; remove text, and mix &amp; swap out many models. Specifically, we improve upon prior cache-modeling work and present a model with a much more expansive, multi-level notion of locality that we show to be well-suited for modeling software. We present results on varying corpora in comparison with traditional N-gram, as well as RNN, and LSTM deep-learning language models, and release all our source code for public use. Our evaluations suggest that carefully adapting N-gram models for source code can yield performance that surpasses even RNN and LSTM based deep-learning models.},
  booktitle = {Proceedings of the 2017 11th Joint Meeting on Foundations of Software Engineering},
  pages     = {763–773},
  numpages  = {11},
  keywords  = {software tools, naturalness, language models},
  location  = {Paderborn, Germany},
  series    = {ESEC/FSE 2017}
}

@inproceedings{javacorpus,
  author    = {M. Allamanis and C. Sutton},
  booktitle = {2013 10th IEEE Working Conference on Mining Software Repositories (MSR 2013)},
  title     = {Mining source code repositories at massive scale using language modeling},
  year      = {2013},
  volume    = {},
  issn      = {2160-1852},
  pages     = {207-216},
  abstract  = {The tens of thousands of high-quality open source software projects on the Internet raise the exciting possibility of studying software development by finding patterns across truly large source code repositories. This could enable new tools for developing code, encouraging reuse, and navigating large projects. In this paper, we build the first giga-token probabilistic language model of source code, based on 352 million lines of Java. This is 100 times the scale of the pioneering work by Hindle et al. The giga-token model is significantly better at the code suggestion task than previous models. More broadly, our approach provides a new “lens” for analyzing software projects, enabling new complexity metrics based on statistical analysis of large corpora. We call these metrics data-driven complexity metrics. We propose new metrics that measure the complexity of a code module and the topical centrality of a module to a software project. In particular, it is possible to distinguish reusable utility classes from classes that are part of a program&#x27;s core logic based solely on general information theoretic criteria.},
  keywords  = {training;entropy;java;measurement;predictive models;complexity theory;software},
  doi       = {10.1109/MSR.2013.6624029},
  url       = {https://doi.ieeecomputersociety.org/10.1109/MSR.2013.6624029},
  publisher = {IEEE Computer Society},
  address   = {Los Alamitos, CA, USA},
  month     = {may}
}


@inproceedings{10.1145/3236024.3236053,
  author    = {Chen, Junjie and Lou, Yiling and Zhang, Lingming and Zhou, Jianyi and Wang, Xiaoleng and Hao, Dan and Zhang, Lu},
  title     = {Optimizing Test Prioritization via Test Distribution Analysis},
  year      = {2018},
  isbn      = {9781450355735},
  publisher = {Association for Computing Machinery},
  address   = {New York, NY, USA},
  url       = {https://doi.org/10.1145/3236024.3236053},
  doi       = {10.1145/3236024.3236053},
  abstract  = {Test prioritization aims to detect regression faults faster via reordering test executions, and a large number of test prioritization techniques have been proposed accordingly. However, test prioritization effectiveness is usually measured in terms of the average percentage of faults detected concerned with the number of test executions, rather than the actual regression testing time, making it unclear which technique is optimal in actual regression testing time. To answer this question, this paper first conducts an empirical study to investigate the actual regression testing time of various prioritization techniques. The results reveal a number of practical guidelines. In particular, no prioritization technique can always perform optimal in practice. To achieve the optimal prioritization effectiveness for any given project in practice, based on the findings of this study, we design learning-based Predictive Test Prioritization (PTP). PTP predicts the optimal prioritization technique for a given project based on the test distribution analysis (i.e., the distribution of test coverage, testing time, and coverage per unit time). The results show that PTP correctly predicts the optimal prioritization technique for 46 out of 50 open-source projects from GitHub, outperforming state-of-the-art techniques significantly in regression testing time, e.g., 43.16% to 94.92% improvement in detecting the first regression fault. Furthermore, PTP has been successfully integrated into the practical testing infrastructure of Baidu (a search service provider with over 600M monthly active users), and received positive feedbacks from the testing team of this company, e.g., saving beyond 2X testing costs with negligible overheads.},
  booktitle = {Proceedings of the 2018 26th ACM Joint Meeting on European Software Engineering Conference and Symposium on the Foundations of Software Engineering},
  pages     = {656–667},
  numpages  = {12},
  keywords  = {Machine Learning, Regression Testing, Test Prioritization},
  location  = {Lake Buena Vista, FL, USA},
  series    = {ESEC/FSE 2018}
}


@inproceedings{naik-etal-2018-stress,
  title     = {Stress Test Evaluation for Natural Language Inference},
  author    = {Naik, Aakanksha  and
               Ravichander, Abhilasha  and
               Sadeh, Norman  and
               Rose, Carolyn  and
               Neubig, Graham},
  booktitle = {Proceedings of the 27th International Conference on Computational Linguistics},
  month     = aug,
  year      = {2018},
  address   = {Santa Fe, New Mexico, USA},
  publisher = {Association for Computational Linguistics},
  url       = {https://aclanthology.org/C18-1198},
  pages     = {2340--2353},
  abstract  = {Natural language inference (NLI) is the task of determining if a natural language hypothesis can be inferred from a given premise in a justifiable manner. NLI was proposed as a benchmark task for natural language understanding. Existing models perform well at standard datasets for NLI, achieving impressive results across different genres of text. However, the extent to which these models understand the semantic content of sentences is unclear. In this work, we propose an evaluation methodology consisting of automatically constructed {``}stress tests{''} that allow us to examine whether systems have the ability to make real inferential decisions. Our evaluation of six sentence-encoder models on these stress tests reveals strengths and weaknesses of these models with respect to challenging linguistic phenomena, and suggests important directions for future work in this area.}
}

@inproceedings{liu-etal-2016-evaluate,
  title     = {How {NOT} To Evaluate Your Dialogue System: An Empirical Study of Unsupervised Evaluation Metrics for Dialogue Response Generation},
  author    = {Liu, Chia-Wei  and
               Lowe, Ryan  and
               Serban, Iulian  and
               Noseworthy, Mike  and
               Charlin, Laurent  and
               Pineau, Joelle},
  editor    = {Su, Jian  and
               Duh, Kevin  and
               Carreras, Xavier},
  booktitle = {Proceedings of the 2016 Conference on Empirical Methods in Natural Language Processing},
  month     = nov,
  year      = {2016},
  address   = {Austin, Texas},
  publisher = {Association for Computational Linguistics},
  url       = {https://aclanthology.org/D16-1230},
  doi       = {10.18653/v1/D16-1230},
  pages     = {2122--2132}
}

@inproceedings{10.1109/ICSE48619.2023.00181,
  author    = {Mastropaolo, Antonio and Pascarella, Luca and Guglielmi, Emanuela and Ciniselli, Matteo and Scalabrino, Simone and Oliveto, Rocco and Bavota, Gabriele},
  title     = {On the Robustness of Code Generation Techniques: An Empirical Study on GitHub Copilot},
  year      = {2023},
  isbn      = {9781665457019},
  publisher = {IEEE Press},
  url       = {https://doi.org/10.1109/ICSE48619.2023.00181},
  doi       = {10.1109/ICSE48619.2023.00181},
  abstract  = {Software engineering research has always being concerned with the improvement of code completion approaches, which suggest the next tokens a developer will likely type while coding. The release of GitHub Copilot constitutes a big step forward, also because of its unprecedented ability to automatically generate even entire functions from their natural language description. While the usefulness of Copilot is evident, it is still unclear to what extent it is robust. Specifically, we do not know the extent to which semantic-preserving changes in the natural language description provided to the model have an effect on the generated code function. In this paper we present an empirical study in which we aim at understanding whether different but semantically equivalent natural language descriptions result in the same recommended function. A negative answer would pose questions on the robustness of deep learning (DL)-based code generators since it would imply that developers using different wordings to describe the same code would obtain different recommendations. We asked Copilot to automatically generate 892 Java methods starting from their original Javadoc description. Then, we generated different semantically equivalent descriptions for each method both manually and automatically, and we analyzed the extent to which predictions generated by Copilot changed. Our results show that modifying the description results in different code recommendations in ~46\% of cases. Also, differences in the semantically equivalent descriptions might impact the correctness of the generated code (±28\%).},
  booktitle = {Proceedings of the 45th International Conference on Software Engineering},
  pages     = {2149–2160},
  numpages  = {12},
  keywords  = {empirical study, recommender systems},
  location  = {Melbourne, Victoria, Australia},
  series    = {ICSE '23}
}


@article{vaswani2017attention,
  title   = {Attention is all you need},
  author  = {Vaswani, Ashish and Shazeer, Noam and Parmar, Niki and Uszkoreit, Jakob and Jones, Llion and Gomez, Aidan N and Kaiser, {\L}ukasz and Polosukhin, Illia},
  journal = {Advances in neural information processing systems},
  volume  = {30},
  year    = {2017}
}

@article{fitria2021quillbot,
  title   = {QuillBot as an online tool: Students’ alternative in paraphrasing and rewriting of English writing},
  author  = {Fitria, Tira Nur},
  journal = {Englisia: Journal of Language, Education, and Humanities},
  volume  = {9},
  number  = {1},
  pages   = {183--196},
  year    = {2021}
}

@misc{zhuo2023source,
  title         = {Source Code Data Augmentation for Deep Learning: A Survey},
  author        = {Terry Yue Zhuo and Zhou Yang and Zhensu Sun and Yufei Wang and Li Li and Xiaoning Du and Zhenchang Xing and David Lo},
  year          = {2023},
  eprint        = {2305.19915},
  archiveprefix = {arXiv},
  primaryclass  = {cs.CL}
}

@misc{shiri2023paraphrasing,
  title         = {Paraphrasing Techniques for Maritime QA system},
  author        = {Fatemeh Shiri and Terry Yue Zhuo and Zhuang Li and Van Nguyen and Shirui Pan and Weiqing Wang and Reza Haffari and Yuan-Fang Li},
  year          = {2023},
  eprint        = {2203.10854},
  archiveprefix = {arXiv},
  primaryclass  = {cs.CL}
}

@inproceedings{Li_2019,
  doi       = {10.14722/ndss.2019.23138},
  url       = {https://doi.org/10.14722%2Fndss.2019.23138},
  year      = 2019,
  publisher = {Internet Society},
  author    = {Jinfeng Li and Shouling Ji and Tianyu Du and Bo Li and Ting Wang},
  title     = {{TextBugger}: Generating Adversarial Text Against Real-world Applications},
  booktitle = {Proceedings 2019 Network and Distributed System Security Symposium}
}

@inproceedings{wang2021adversarial,
  title     = {Adversarial {GLUE}: A Multi-Task Benchmark for Robustness Evaluation of Language Models},
  author    = {Boxin Wang and Chejian Xu and Shuohang Wang and Zhe Gan and Yu Cheng and Jianfeng Gao and Ahmed Hassan Awadallah and Bo Li},
  booktitle = {Thirty-fifth Conference on Neural Information Processing Systems Datasets and Benchmarks Track (Round 2)},
  year      = {2021},
  url       = {https://openreview.net/forum?id=GF9cSKI3A_q}
}

@inproceedings{finegan-dollak-etal-2018-improving,
  title     = {Improving Text-to-{SQL} Evaluation Methodology},
  author    = {Finegan-Dollak, Catherine  and
               Kummerfeld, Jonathan K.  and
               Zhang, Li  and
               Ramanathan, Karthik  and
               Sadasivam, Sesh  and
               Zhang, Rui  and
               Radev, Dragomir},
  editor    = {Gurevych, Iryna  and
               Miyao, Yusuke},
  booktitle = {Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)},
  month     = jul,
  year      = {2018},
  address   = {Melbourne, Australia},
  publisher = {Association for Computational Linguistics},
  url       = {https://aclanthology.org/P18-1033},
  doi       = {10.18653/v1/P18-1033},
  pages     = {351--360},
  abstract  = {To be informative, an evaluation must measure how well systems generalize to realistic unseen data. We identify limitations of and propose improvements to current evaluations of text-to-SQL systems. First, we compare human-generated and automatically generated questions, characterizing properties of queries necessary for real-world applications. To facilitate evaluation on multiple datasets, we release standardized and improved versions of seven existing datasets and one new text-to-SQL dataset. Second, we show that the current division of data into training and test sets measures robustness to variations in the way questions are asked, but only partially tests how well systems generalize to new queries; therefore, we propose a complementary dataset split for evaluation of future work. Finally, we demonstrate how the common practice of anonymizing variables during evaluation removes an important challenge of the task. Our observations highlight key difficulties, and our methodology enables effective measurement of future development.}
}

@inproceedings{zhuo2023-robustness,
  title     = {On Robustness of Prompt-based Semantic Parsing with Large Pre-trained Language Model: An Empirical Study on Codex},
  author    = {Zhuo, Terry Yue  and
               Li, Zhuang  and
               Huang, Yujin  and
               Shiri, Fatemeh  and
               Wang, Weiqing  and
               Haffari, Gholamreza  and
               Li, Yuan-Fang},
  booktitle = {Proceedings of the 17th Conference of the European Chapter of the Association for Computational Linguistics},
  month     = may,
  year      = {2023},
  address   = {Dubrovnik, Croatia},
  publisher = {Association for Computational Linguistics},
  url       = {https://aclanthology.org/2023.eacl-main.77},
  doi       = {10.18653/v1/2023.eacl-main.77},
  pages     = {1090--1102},
  abstract  = {Semantic parsing is a technique aimed at constructing a structured representation of the meaning of a natural-language question. Recent advances in language models trained on code have shown superior performance in generating these representations compared to language models trained solely on natural language text. The existing fine-tuned neural semantic parsers are vulnerable to adversarial attacks on natural-language inputs. While it has been established that the robustness of smaller semantic parsers can be enhanced through adversarial training, this approach is not feasible for large language models in real-world scenarios, as it requires both substantial computational resources and expensive human annotation on in-domain semantic parsing data. This paper presents the first empirical study on the adversarial robustness of a prompt-based semantic parser based on CODEX, a stateof-the-art (SOTA) language model trained on code. Our results demonstrate that the large language model of code is vulnerable to carefully crafted adversarial examples. To overcome this challenge, we propose methods for enhancing robustness without requiring substantial amounts of labelled data or intensive computational resources.}
}

@article{DBLP:journals/corr/abs-2203-09829,
  author     = {Abdul Hameed Azeemi and
                Ihsan Ayyub Qazi and
                Agha Ali Raza},
  title      = {Towards Representative Subset Selection for Self-Supervised Speech
                Recognition},
  journal    = {CoRR},
  volume     = {abs/2203.09829},
  year       = {2022},
  url        = {https://doi.org/10.48550/arXiv.2203.09829},
  doi        = {10.48550/arXiv.2203.09829},
  eprinttype = {arXiv},
  eprint     = {2203.09829},
  timestamp  = {Mon, 28 Mar 2022 17:09:43 +0200},
  biburl     = {https://dblp.org/rec/journals/corr/abs-2203-09829.bib},
  bibsource  = {dblp computer science bibliography, https://dblp.org}
}

@inproceedings{10.1145/3460319.3464810,
  author    = {Cheng, Runxiang and Zhang, Lingming and Marinov, Darko and Xu, Tianyin},
  title     = {Test-Case Prioritization for Configuration Testing},
  year      = {2021},
  isbn      = {9781450384599},
  publisher = {Association for Computing Machinery},
  address   = {New York, NY, USA},
  url       = {https://doi.org/10.1145/3460319.3464810},
  doi       = {10.1145/3460319.3464810},
  abstract  = {Configuration changes are among the dominant causes of failures of large-scale software system deployment. Given the velocity of configuration changes, typically at the scale of hundreds to thousands of times daily in modern cloud systems, checking these configuration changes is critical to prevent failures due to misconfigurations. Recent work has proposed configuration testing, Ctest, a technique that tests configuration changes together with the code that uses the changed configurations. Ctest can automatically generate a large number of ctests that can effectively detect misconfigurations, including those that are hard to detect by traditional techniques. However, running ctests can take a long time to detect misconfigurations. Inspired by traditional test-case prioritization (TCP) that aims to reorder test executions to speed up detection of regression code faults, we propose to apply TCP to reorder ctests to speed up detection of misconfigurations. We extensively evaluate a total of 84 traditional and novel ctest-specific TCP techniques. The experimental results on five widely used cloud projects demonstrate that TCP can substantially speed up misconfiguration detection. Our study provides guidelines for applying TCP to configuration testing in practice.},
  booktitle = {Proceedings of the 30th ACM SIGSOFT International Symposium on Software Testing and Analysis},
  pages     = {452–465},
  numpages  = {14},
  keywords  = {software testing, configuration, reliability, Test prioritization},
  location  = {Virtual, Denmark},
  series    = {ISSTA 2021}
}

@inproceedings{919106,
  author    = {Elbaum, S. and Malishevsky, A. and Rothermel, G.},
  booktitle = {Proceedings of the 23rd International Conference on Software Engineering. ICSE 2001},
  title     = {Incorporating varying test costs and fault severities into test case prioritization},
  year      = {2001},
  volume    = {},
  number    = {},
  pages     = {329-338},
  doi       = {10.1109/ICSE.2001.919106}
}

@article{guilford1950fundamental,
  title     = {Fundamental statistics in psychology and education},
  author    = {Guilford, Joy Paul},
  year      = {1950},
  publisher = {McGraw-Hill}
}

@article{testsurvey,
  author     = {Yoo, S. and Harman, M.},
  title      = {Regression Testing Minimization, Selection and Prioritization: A Survey},
  year       = {2012},
  issue_date = {March 2012},
  publisher  = {John Wiley and Sons Ltd.},
  address    = {GBR},
  volume     = {22},
  number     = {2},
  issn       = {0960-0833},
  url        = {https://doi.org/10.1002/stv.430},
  doi        = {10.1002/stv.430},
  abstract   = {Regression testing is a testing activity that is performed to provide confidence that changes do not harm the existing behaviour of the software. Test suites tend to grow in size as software evolves, often making it too costly to execute entire test suites. A number of different approaches have been studied to maximize the value of the accrued test suite: minimization, selection and prioritization. Test suite minimization seeks to eliminate redundant test cases in order to reduce the number of tests to run. Test case selection seeks to identify the test cases that are relevant to some set of recent changes. Test case prioritization seeks to order test cases in such a way that early fault detection is maximized. This paper surveys each area of minimization, selection and prioritization technique and discusses open problems and potential directions for future research. Copyright © 2010 John Wiley &amp; Sons, Ltd.},
  journal    = {Softw. Test. Verif. Reliab.},
  month      = {mar},
  pages      = {67–120},
  numpages   = {54},
  keywords   = {regression testing, regression test selection, test suite minimization, test case prioritization}
}

@misc{starcoder,
  title         = {StarCoder: may the source be with you!},
  author        = {Raymond Li and Loubna Ben Allal and Yangtian Zi et al.},
  year          = {2023},
  eprint        = {2305.06161},
  archiveprefix = {arXiv},
  primaryclass  = {cs.CL}
}

@article{Tran2017Online,
  author  = {Tran, Nhi N and Lee, Joohyun},
  title   = {Online Reviews as Health Data: Examining the Association Between Availability of Health Care Services and Patient Star Ratings Exemplified by the Yelp Academic Dataset},
  journal = {JMIR Public Health Surveill},
  volume  = {3},
  number  = {3},
  pages   = {e43},
  year    = {2017},
  doi     = {10.2196/publichealth.7001},
  pmid    = {28701293},
  pmcid   = {PMC5529738}
}

@misc{adult,
  author      = {Dua, Dheeru and Graff, Casey},
  year        = {2017},
  title       = {{UCI} Machine Learning Repository},
  url         = {http://archive.ics.uci.edu/ml},
  institution = {University of California, Irvine, School of Information and Computer Sciences}
}

@inproceedings{PGD,
  author    = {Aleksander Madry and
               Aleksandar Makelov and
               Ludwig Schmidt and
               Dimitris Tsipras and
               Adrian Vladu},
  title     = {Towards Deep Learning Models Resistant to Adversarial Attacks},
  booktitle = {6th International Conference on Learning Representations, {ICLR} 2018,
               Vancouver, BC, Canada, April 30 - May 3, 2018, Conference Track Proceedings},
  year      = {2018}
}


@inproceedings{DeepGini,
  author    = {Feng, Yang and Shi, Qingkai and Gao, Xinyu and Wan, Jun and Fang, Chunrong and Chen, Zhenyu},
  title     = {DeepGini: Prioritizing Massive Tests to Enhance the Robustness of Deep Neural Networks},
  year      = {2020},
  isbn      = {9781450380089},
  publisher = {Association for Computing Machinery},
  address   = {New York, NY, USA},
  url       = {https://doi.org/10.1145/3395363.3397357},
  doi       = {10.1145/3395363.3397357},
  abstract  = {Deep neural networks (DNN) have been deployed in many software systems to assist in various classification tasks. In company with the fantastic effectiveness in classification, DNNs could also exhibit incorrect behaviors and result in accidents and losses. Therefore, testing techniques that can detect incorrect DNN behaviors and improve DNN quality are extremely necessary and critical. However, the testing oracle, which defines the correct output for a given input, is often not available in the automated testing. To obtain the oracle information, the testing tasks of DNN-based systems usually require expensive human efforts to label the testing data, which significantly slows down the process of quality assurance. To mitigate this problem, we propose DeepGini, a test prioritization technique designed based on a statistical perspective of DNN. Such a statistical perspective allows us to reduce the problem of measuring misclassification probability to the problem of measuring set impurity, which allows us to quickly identify possibly-misclassified tests. To evaluate, we conduct an extensive empirical study on popular datasets and prevalent DNN models. The experimental results demonstrate that DeepGini outperforms existing coverage-based techniques in prioritizing tests regarding both effectiveness and efficiency. Meanwhile, we observe that the tests prioritized at the front by DeepGini are more effective in improving the DNN quality in comparison with the coverage-based techniques.},
  booktitle = {Proceedings of the 29th ACM SIGSOFT International Symposium on Software Testing and Analysis},
  pages     = {177–188},
  numpages  = {12},
  keywords  = {Test Case Prioritization, Deep Learning, Deep Learning Testing},
  location  = {Virtual Event, USA},
  series    = {ISSTA 2020}
}

@inproceedings{ASRTest,
  author    = {Ji, Pin and Feng, Yang and Liu, Jia and Zhao, Zhihong and Chen, Zhenyu},
  title     = {ASRTest: Automated Testing for Deep-Neural-Network-Driven Speech Recognition Systems},
  year      = {2022},
  isbn      = {9781450393799},
  publisher = {Association for Computing Machinery},
  address   = {New York, NY, USA},
  url       = {https://doi.org/10.1145/3533767.3534391},
  doi       = {10.1145/3533767.3534391},
  abstract  = {With the rapid development of deep neural networks and end-to-end learning techniques, automatic speech recognition (ASR) systems have been deployed into our daily and assist in various tasks. However, despite their tremendous progress, ASR systems could also suffer from software defects and exhibit incorrect behaviors. While the nature of DNN makes conventional software testing techniques inapplicable for ASR systems, lacking diverse tests and oracle information further hinders their testing. In this paper, we propose and implement a testing approach, namely ASR, specifically for the DNN-driven ASR systems. ASRTest is built upon the theory of metamorphic testing. We first design the metamorphic relation for ASR systems and then implement three families of transformation operators that can simulate practical application scenarios to generate speeches. Furthermore, we adopt Gini impurity to guide the generation process and improve the testing efficiency. To validate the effectiveness of ASRTest, we apply ASRTest to four ASR models with four widely-used datasets. The results show that ASRTest can detect erroneous behaviors under different realistic application conditions efficiently and improve 19.1% recognition performance on average via retraining with the generated data. Also, we conduct a case study on an industrial ASR system to investigate the performance of ASRTest under the real usage scenario. The study shows that ASRTest can detect errors and improve the performance of DNN-driven ASR systems effectively.},
  booktitle = {Proceedings of the 31st ACM SIGSOFT International Symposium on Software Testing and Analysis},
  pages     = {189–201},
  numpages  = {13},
  keywords  = {Metamorphic Testing, Automated Testing, Deep Neural Networks, Automatic Speech Recognition},
  location  = {Virtual, South Korea},
  series    = {ISSTA 2022}
}


@inproceedings{biasrv,
  author    = {Yang, Zhou and Asyrofi, Muhammad Hilmi and Lo, David},
  title     = {BiasRV: Uncovering Biased Sentiment Predictions at Runtime},
  year      = {2021},
  isbn      = {9781450385626},
  publisher = {Association for Computing Machinery},
  address   = {New York, NY, USA},
  url       = {https://doi.org/10.1145/3468264.3473117},
  doi       = {10.1145/3468264.3473117},
  abstract  = {Sentiment analysis (SA) systems, though widely applied in many domains, have been demonstrated to produce biased results. Some research works have been done in automatically generating test cases to reveal unfairness in SA systems, but the community still lacks tools that can monitor and uncover biased predictions at runtime. This paper fills this gap by proposing BiasRV, the first tool to raise an alarm when a deployed SA system makes a biased prediction on a given input text. To implement this feature, BiasRV dynamically extracts a template from an input text and generates gender-discriminatory mutants (semantically-equivalent texts that only differ in gender information) from the template. Based on popular metrics used to evaluate the overall fairness of an SA system, we define the distributional fairness property for an individual prediction of an SA system. This property specifies a requirement that for one piece of text, mutants from different gender classes should be treated similarly. Verifying the distributional fairness property causes much overhead to the running system. To run more efficiently, BiasRV adopts a two-step heuristic: (1) sampling several mutants from each gender and checking if the system predicts them as of the same sentiment, (2) checking distributional fairness only when sampled mutants have conflicting results. Experiments show that when compared to directly checking the distributional fairness property for each input text, our two-step heuristic can decrease the overhead used for analyzing mutants by 73.81% while only resulting in 6.7% of biased predictions being missed. Besides, BiasRV can be used conveniently without knowing the implementation of SA systems. Future researchers can easily extend BiasRV to detect more types of bias, e.g., race and occupation. The demo video for BiasRV can be viewed at https://youtu.be/WPe4Ml77d3U and the source code can be found at https://github.com/soarsmu/BiasRV.},
  booktitle = {Proceedings of the 29th ACM Joint Meeting on European Software Engineering Conference and Symposium on the Foundations of Software Engineering},
  pages     = {1540–1544},
  numpages  = {5},
  keywords  = {Runtime Verification, Sentiment Analysis, Ethical AI, Fairness},
  location  = {Athens, Greece},
  series    = {ESEC/FSE 2021}
}

@article{biasfinder,
  author  = {Asyrofi, Muhammad Hilmi and Yang, Zhou and Yusuf, Imam Nur Bani and Kang, Hong Jin and Thung, Ferdian and Lo, David},
  journal = {IEEE Transactions on Software Engineering},
  title   = {BiasFinder: Metamorphic Test Generation to Uncover Bias for Sentiment Analysis Systems},
  year    = {2022},
  volume  = {48},
  number  = {12},
  pages   = {5087-5101},
  doi     = {10.1109/TSE.2021.3136169}
}

@inproceedings{europarl,
  title     = {{E}uroparl: A Parallel Corpus for Statistical Machine Translation},
  author    = {Koehn, Philipp},
  booktitle = {Proceedings of Machine Translation Summit X: Papers},
  month     = sep # { 13-15},
  year      = {2005},
  address   = {Phuket, Thailand},
  url       = {https://aclanthology.org/2005.mtsummit-papers.11},
  pages     = {79--86},
  abstract  = {We collected a corpus of parallel text in 11 languages from the proceedings of the European Parliament, which are published on the web. This corpus has found widespread use in the NLP community. Here, we focus on its acquisition and its application as training data for statistical machine translation (SMT). We trained SMT systems for 110 language pairs, which reveal interesting clues into the challenges ahead.}
}

@inproceedings{Libri-Light,
  author    = {Kahn, J. and Rivière, M. and Zheng, W. and Kharitonov, E. and Xu, Q. and Mazaré, P.E. and Karadayi, J. and Liptchinsky, V. and Collobert, R. and Fuegen, C. and Likhomanenko, T. and Synnaeve, G. and Joulin, A. and Mohamed, A. and Dupoux, E.},
  booktitle = {ICASSP 2020 - 2020 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)},
  title     = {Libri-Light: A Benchmark for ASR with Limited or No Supervision},
  year      = {2020},
  volume    = {},
  number    = {},
  pages     = {7669-7673},
  doi       = {10.1109/ICASSP40776.2020.9052942}
}

@article{ml-testing-survey,
  author  = {Zhang, Jie M. and Harman, Mark and Ma, Lei and Liu, Yang},
  journal = {IEEE Transactions on Software Engineering},
  title   = {Machine Learning Testing: Survey, Landscapes and Horizons},
  year    = {2022},
  volume  = {48},
  number  = {1},
  pages   = {1-36},
  doi     = {10.1109/TSE.2019.2962027}
}

@article{selection_survey,
  author     = {Kazmi, Rafaqut and Jawawi, Dayang N. A. and Mohamad, Radziah and Ghani, Imran},
  title      = {Effective Regression Test Case Selection: A Systematic Literature Review},
  year       = {2017},
  issue_date = {March 2018},
  publisher  = {Association for Computing Machinery},
  address    = {New York, NY, USA},
  volume     = {50},
  number     = {2},
  issn       = {0360-0300},
  url        = {https://doi.org/10.1145/3057269},
  doi        = {10.1145/3057269},
  abstract   = {Regression test case selection techniques attempt to increase the testing effectiveness based on the measurement capabilities, such as cost, coverage, and fault detection. This systematic literature review presents state-of-the-art research in effective regression test case selection techniques. We examined 47 empirical studies published between 2007 and 2015. The selected studies are categorized according to the selection procedure, empirical study design, and adequacy criteria with respect to their effectiveness measurement capability and methods used to measure the validity of these results.The results showed that mining and learning-based regression test case selection was reported in 39% of the studies, unit level testing was reported in 18% of the studies, and object-oriented environment (Java) was used in 26% of the studies. Structural faults, the most common target, was used in 55% of the studies. Overall, only 39% of the studies conducted followed experimental guidelines and are reproducible.There are 7 different cost measures, 13 different coverage types, and 5 fault-detection metrics reported in these studies. It is also observed that 70% of the studies being analyzed used cost as the effectiveness measure compared to 31% that used fault-detection capability and 16% that used coverage.},
  journal    = {ACM Comput. Surv.},
  month      = {may},
  articleno  = {29},
  numpages   = {32},
  keywords   = {coverage, cost effectiveness, Software testing, fault detection ability, SLR}
}

@inproceedings{common-voice,
  title     = {Common Voice: A Massively-Multilingual Speech Corpus},
  author    = {Ardila, Rosana  and
               Branson, Megan  and
               Davis, Kelly  and
               Kohler, Michael  and
               Meyer, Josh  and
               Henretty, Michael  and
               Morais, Reuben  and
               Saunders, Lindsay  and
               Tyers, Francis  and
               Weber, Gregor},
  booktitle = {Proceedings of the 12th Language Resources and Evaluation Conference},
  month     = may,
  year      = {2020},
  address   = {Marseille, France},
  publisher = {European Language Resources Association},
  url       = {https://aclanthology.org/2020.lrec-1.520},
  pages     = {4218--4222},
  abstract  = {The Common Voice corpus is a massively-multilingual collection of transcribed speech intended for speech technology research and development. Common Voice is designed for Automatic Speech Recognition purposes but can be useful in other domains (e.g. language identification). To achieve scale and sustainability, the Common Voice project employs crowdsourcing for both data collection and data validation. The most recent release includes 29 languages, and as of November 2019 there are a total of 38 languages collecting data. Over 50,000 individuals have participated so far, resulting in 2,500 hours of collected audio. To our knowledge this is the largest audio corpus in the public domain for speech recognition, both in terms of number of hours and number of languages. As an example use case for Common Voice, we present speech recognition experiments using Mozilla{'}s DeepSpeech Speech-to-Text toolkit. By applying transfer learning from a source English model, we find an average Character Error Rate improvement of 5.99 {\mbox{$\pm$}} 5.48 for twelve target languages (German, French, Italian, Turkish, Catalan, Slovenian, Welsh, Irish, Breton, Tatar, Chuvash, and Kabyle). For most of these languages, these are the first ever published results on end-to-end Automatic Speech Recognition.},
  language  = {English},
  isbn      = {979-10-95546-34-4}
}

@inproceedings{biasheal,
  author    = {Yang, Zhou and Jain, Harshit and Shi, Jieke and Asyrofi, Muhammad Hilmi and Lo, David},
  booktitle = {2021 IEEE International Conference on Software Maintenance and Evolution (ICSME)},
  title     = {BiasHeal: On-the-Fly Black-Box Healing of Bias in Sentiment Analysis Systems},
  year      = {2021},
  volume    = {},
  number    = {},
  pages     = {644-648},
  doi       = {10.1109/ICSME52107.2021.00073}
}

@misc{asrdebugger,
  doi       = {10.48550/ARXIV.2302.00330},
  url       = {https://arxiv.org/abs/2302.00330},
  author    = {Yang, Zhou and Shi, Jieke and Asyrofi, Muhammad Hilmi and Xu, Bowen and Zhou, Xin and Han, DongGyun and Lo, David},
  keywords  = {Software Engineering (cs.SE), FOS: Computer and information sciences, FOS: Computer and information sciences},
  title     = {Prioritizing Speech Test Cases},
  publisher = {arXiv},
  year      = {2023},
  copyright = {arXiv.org perpetual, non-exclusive license}
}

@article{hu_tosem,
  author  = {Hu, Qiang and Guo, Yuejun and Cordy, Maxime and Xie, Xiaofei and Ma, Lei and Papadakis, Mike and Le Traon, Yves},
  title   = {An Empirical Study on Data Distribution-Aware Test Selection for Deep Learning Enhancement},
  year    = {2022},
  journal = {ACM Transactions on Software Engineering and Methodology (TOSEM)}
}

@misc{ma2023ai,
  title         = {Is AI the better programming partner? Human-Human Pair Programming vs. Human-AI pAIr Programming},
  author        = {Qianou Ma and Tongshuang Wu and Kenneth Koedinger},
  year          = {2023},
  eprint        = {2306.05153},
  archiveprefix = {arXiv},
  primaryclass  = {cs.HC}
}

@article{DeepCruiser,
  author     = {Xiaoning Du and
                Xiaofei Xie and
                Yi Li and
                Lei Ma and
                Jianjun Zhao and
                Yang Liu},
  title      = {DeepCruiser: Automated Guided Testing for Stateful Deep Learning Systems},
  journal    = {CoRR},
  volume     = {abs/1812.05339},
  year       = {2018},
  url        = {http://arxiv.org/abs/1812.05339},
  eprinttype = {arXiv},
  eprint     = {1812.05339},
  timestamp  = {Fri, 11 Feb 2022 09:12:45 +0100},
  biburl     = {https://dblp.org/rec/journals/corr/abs-1812-05339.bib},
  bibsource  = {dblp computer science bibliography, https://dblp.org}
}

@misc{owasp_benchmark,
  title        = {{OWASP Benchmark Project}},
  howpublished = {\url{https://owasp.org/www-project-benchmark/}},
  note         = {Accessed: 2023-12-19}
}


@inproceedings{tang2022mitigating,
  title     = {Mitigating membership inference attacks by $\{$Self-Distillation$\}$ through a novel ensemble architecture},
  author    = {Tang, Xinyu and Mahloujifar, Saeed and Song, Liwei and Shejwalkar, Virat and Nasr, Milad and Houmansadr, Amir and Mittal, Prateek},
  booktitle = {31st USENIX Security Symposium (USENIX Security 22)},
  pages     = {1433--1450},
  year      = {2022}
}

@inproceedings{DP-SGD,
  author    = {Abadi, Martin and Chu, Andy and Goodfellow, Ian and McMahan, H. Brendan and Mironov, Ilya and Talwar, Kunal and Zhang, Li},
  title     = {Deep Learning with Differential Privacy},
  year      = {2016},
  isbn      = {9781450341394},
  publisher = {Association for Computing Machinery},
  address   = {New York, NY, USA},
  url       = {https://doi.org/10.1145/2976749.2978318},
  doi       = {10.1145/2976749.2978318},
  abstract  = {Machine learning techniques based on neural networks are achieving remarkable results in a wide variety of domains. Often, the training of models requires large, representative datasets, which may be crowdsourced and contain sensitive information. The models should not expose private information in these datasets. Addressing this goal, we develop new algorithmic techniques for learning and a refined analysis of privacy costs within the framework of differential privacy. Our implementation and experiments demonstrate that we can train deep neural networks with non-convex objectives, under a modest privacy budget, and at a manageable cost in software complexity, training efficiency, and model quality.},
  booktitle = {Proceedings of the 2016 ACM SIGSAC Conference on Computer and Communications Security},
  pages     = {308–318},
  numpages  = {11},
  keywords  = {differential privacy, deep learning},
  location  = {Vienna, Austria},
  series    = {CCS '16}
}


@online{gzip,
  author = {GNU Project},
  title  = {GNU Gzip},
  year   = {2023},
  url    = {https://www.gnu.org/software/gzip/}
}

@online{gzip-implementation,
  author = {GitHub Users},
  title  = {npc\_gzip},
  year   = {2023},
  url    = {https://github.com/bazingagin/npc_gzip}
},
}

@online{gzip-discussion,
  author = {GitHub Users},
  title  = {Problem with accuracy calculation?},
  year   = {2023},
  url    = {https://github.com/bazingagin/npc_gzip/issues/3}
}


@article{truex2019demystifying,
  title     = {Demystifying membership inference attacks in machine learning as a service},
  author    = {Truex, Stacey and Liu, Ling and Gursoy, Mehmet Emre and Yu, Lei and Wei, Wenqi},
  journal   = {IEEE Transactions on Services Computing},
  volume    = {14},
  number    = {6},
  pages     = {2073--2089},
  year      = {2019},
  publisher = {IEEE}
}

@misc{diabetes,
  author       = {Dua, Dheeru and Graff, Casey},
  title        = {UCI machine learning repository},
  year         = {2017},
  howpublished = {\url{http://archive.ics.uci.edu/ml}},
  note         = {Accessed: 2023-03-25}
}


@inproceedings{10.1145/3133956.3134012,
  author    = {Hitaj, Briland and Ateniese, Giuseppe and Perez-Cruz, Fernando},
  title     = {Deep Models Under the GAN: Information Leakage from Collaborative Deep Learning},
  year      = {2017},
  isbn      = {9781450349468},
  publisher = {Association for Computing Machinery},
  address   = {New York, NY, USA},
  url       = {https://doi.org/10.1145/3133956.3134012},
  doi       = {10.1145/3133956.3134012},
  abstract  = {Deep Learning has recently become hugely popular in machine learning for its ability to solve end-to-end learning systems, in which the features and the classifiers are learned simultaneously, providing significant improvements in classification accuracy in the presence of highly-structured and large databases.Its success is due to a combination of recent algorithmic breakthroughs, increasingly powerful computers, and access to significant amounts of data.Researchers have also considered privacy implications of deep learning. Models are typically trained in a centralized manner with all the data being processed by the same training algorithm. If the data is a collection of users' private data, including habits, personal pictures, geographical positions, interests, and more, the centralized server will have access to sensitive information that could potentially be mishandled. To tackle this problem, collaborative deep learning models have recently been proposed where parties locally train their deep learning structures and only share a subset of the parameters in the attempt to keep their respective training sets private. Parameters can also be obfuscated via differential privacy (DP) to make information extraction even more challenging, as proposed by Shokri and Shmatikov at CCS'15.Unfortunately, we show that any privacy-preserving collaborative deep learning is susceptible to a powerful attack that we devise in this paper. In particular, we show that a distributed, federated, or decentralized deep learning approach is fundamentally broken and does not protect the training sets of honest participants. The attack we developed exploits the real-time nature of the learning process that allows the adversary to train a Generative Adversarial Network (GAN) that generates prototypical samples of the targeted training set that was meant to be private (the samples generated by the GAN are intended to come from the same distribution as the training data). Interestingly, we show that record-level differential privacy applied to the shared parameters of the model, as suggested in previous work, is ineffective (i.e., record-level DP is not designed to address our attack).},
  booktitle = {Proceedings of the 2017 ACM SIGSAC Conference on Computer and Communications Security},
  pages     = {603–618},
  numpages  = {16},
  keywords  = {deep learning, collaborative learning, privacy, security},
  location  = {Dallas, Texas, USA},
  series    = {CCS '17}
}

@inproceedings{nasr2019comprehensive,
  title        = {Comprehensive privacy analysis of deep learning: Passive and active white-box inference attacks against centralized and federated learning},
  author       = {Nasr, Milad and Shokri, Reza and Houmansadr, Amir},
  booktitle    = {2019 IEEE symposium on security and privacy (SP)},
  pages        = {739--753},
  year         = {2019},
  organization = {IEEE}
}

@inproceedings{yeom2018privacy,
  title        = {Privacy risk in machine learning: Analyzing the connection to overfitting},
  author       = {Yeom, Samuel and Giacomelli, Irene and Fredrikson, Matt and Jha, Somesh},
  booktitle    = {2018 IEEE 31st computer security foundations symposium (CSF)},
  pages        = {268--282},
  year         = {2018},
  organization = {IEEE}
}

@inproceedings{mengge-etal-2020-coarse,
  title     = {{C}oarse-to-{F}ine {P}re-training for {N}amed {E}ntity {R}ecognition},
  author    = {Mengge, Xue and Yu, Bowen and Zhang, Zhenyu and Liu, Tingwen and Zhang, Yue and Wang, Bin},
  booktitle = {Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP)},
  year      = {2020},
  pages     = {6345--6354}
}

@inproceedings{Nasr-defense,
  author    = {Nasr, Milad and Shokri, Reza and Houmansadr, Amir},
  title     = {Machine Learning with Membership Privacy Using Adversarial Regularization},
  year      = {2018},
  isbn      = {9781450356930},
  publisher = {Association for Computing Machinery},
  address   = {New York, NY, USA},
  url       = {https://doi.org/10.1145/3243734.3243855},
  doi       = {10.1145/3243734.3243855},
  abstract  = {Machine learning models leak significant amount of information about their training sets, through their predictions. This is a serious privacy concern for the users of machine learning as a service. To address this concern, in this paper, we focus on mitigating the risks of black-box inference attacks against machine learning models. We introduce a mechanism to train models with membership privacy, which ensures indistinguishability between the predictions of a model on its training data and other data points (from the same distribution). This requires minimizing the accuracy of the best black-box membership inference attack against the model. We formalize this as a min-max game, and design an adversarial training algorithm that minimizes the prediction loss of the model as well as the maximum gain of the inference attacks. This strategy, which can guarantee membership privacy (as prediction indistinguishability), acts also as a strong regularizer and helps generalizing the model. We evaluate the practical feasibility of our privacy mechanism on training deep neural networks using benchmark datasets. We show that the min-max strategy can mitigate the risks of membership inference attacks (near random guess), and can achieve this with a negligible drop in the model's prediction accuracy (less than 4%).},
  booktitle = {Proceedings of the 2018 ACM SIGSAC Conference on Computer and Communications Security},
  pages     = {634–646},
  numpages  = {13},
  keywords  = {data privacy, min-max game, adversarial process, membership privacy, machine learning, inference attacks, indistinguishability},
  location  = {Toronto, Canada},
  series    = {CCS '18}
}

@inproceedings{10.3115/1218955.1219032,
  author    = {Lin, Chin-Yew and Och, Franz Josef},
  title     = {Automatic Evaluation of Machine Translation Quality Using Longest Common Subsequence and Skip-Bigram Statistics},
  year      = {2004},
  publisher = {Association for Computational Linguistics},
  address   = {USA},
  url       = {https://doi.org/10.3115/1218955.1219032},
  doi       = {10.3115/1218955.1219032},
  abstract  = {In this paper we describe two new objective automatic evaluation methods for machine translation. The first method is based on longest common subsequence between a candidate translation and a set of reference translations. Longest common subsequence takes into account sentence level structure similarity naturally and identifies longest co-occurring in-sequence n-grams automatically. The second method relaxes strict n-gram matching to skip-bigram matching. Skip-bigram is any pair of words in their sentence order. Skip-bigram cooccurrence statistics measure the overlap of skip-bigrams between a candidate translation and a set of reference translations. The empirical results show that both methods correlate with human judgments very well in both adequacy and fluency.},
  booktitle = {Proceedings of the 42nd Annual Meeting on Association for Computational Linguistics},
  pages     = {605–es},
  location  = {Barcelona, Spain},
  series    = {ACL '04}
}

@article{hisamoto-etal-2020-membership,
  title     = {Membership Inference Attacks on Sequence-to-Sequence Models: {I}s My Data In Your Machine Translation System?},
  author    = {Hisamoto, Sorami  and
               Post, Matt  and
               Duh, Kevin},
  journal   = {Transactions of the Association for Computational Linguistics},
  volume    = {8},
  year      = {2020},
  address   = {Cambridge, MA},
  publisher = {MIT Press},
  url       = {https://aclanthology.org/2020.tacl-1.4},
  doi       = {10.1162/tacl_a_00299},
  pages     = {49--63},
  abstract  = {Data privacy is an important issue for {``}machine learning as a service{''} providers. We focus on the problem of membership inference attacks: Given a data sample and black-box access to a model{'}s API, determine whether the sample existed in the model{'}s training data. Our contribution is an investigation of this problem in the context of sequence-to-sequence models, which are important in applications such as machine translation and video captioning. We define the membership inference problem for sequence generation, provide an open dataset based on state-of-the-art machine translation models, and report initial results on whether these models leak private information against several kinds of membership inference attacks.}
}

@article{cooper2014mental,
  title  = {Mental workload of common voice-based vehicle interactions across six different vehicle systems},
  author = {Cooper, Joel M and Ingebretsen, Hailey and Strayer, David L},
  year   = {2014}
}

@inproceedings{50459,
  title     = {Automatic Speech Recognition of Disordered Speech: Personalized models outperforming human listeners on short phrases},
  author    = {Jordan R. Green and Bob MacDonald and Pan-Pan Jiang and Julie Cattiau and Rus Heywood and Richard Cave and Katie Seaver and Marilyn Ladewig and Jimmy Tobin and Michael Brenner and Philip Q Nelson and Katrin Tomanek},
  year      = {2021},
  booktitle = {Proc. Interspeech 2021}
}


@inproceedings{personal,
  author    = {Khe Chai Sim and
               Angad Chandorkar and
               Fan Gao and
               Mason Chua and
               Tsendsuren Munkhdalai and
               Fran{\c{c}}oise Beaufays},
  editor    = {Hynek Hermansky and
               Honza Cernock{\'{y}} and
               Luk{\'{a}}s Burget and
               Lori Lamel and
               Odette Scharenborg and
               Petr Motl{\'{\i}}cek},
  title     = {Robust Continuous On-Device Personalization for Automatic Speech Recognition},
  booktitle = {Interspeech 2021, 22nd Annual Conference of the International Speech
               Communication Association, Brno, Czechia, 30 August - 3 September
               2021},
  pages     = {1284--1288},
  publisher = {{ISCA}},
  year      = {2021},
  url       = {https://doi.org/10.21437/Interspeech.2021-318},
  doi       = {10.21437/Interspeech.2021-318},
  timestamp = {Mon, 14 Mar 2022 16:42:12 +0100},
  biburl    = {https://dblp.org/rec/conf/interspeech/SimCGCMB21.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}


@inproceedings{deeproad,
  author    = {Zhang, Mengshi and Zhang, Yuqun and Zhang, Lingming and Liu, Cong and Khurshid, Sarfraz},
  title     = {DeepRoad: GAN-Based Metamorphic Testing and Input Validation Framework for Autonomous Driving Systems},
  year      = {2018},
  isbn      = {9781450359375},
  publisher = {Association for Computing Machinery},
  address   = {New York, NY, USA},
  url       = {https://doi.org/10.1145/3238147.3238187},
  doi       = {10.1145/3238147.3238187},
  abstract  = {While Deep Neural Networks (DNNs) have established the fundamentals of image-based autonomous driving systems, they may exhibit erroneous behaviors and cause fatal accidents. To address the safety issues in autonomous driving systems, a recent set of testing techniques have been designed to automatically generate artificial driving scenes to enrich test suite, e.g., generating new input images transformed from the original ones. However, these techniques are insufficient due to two limitations: first, many such synthetic images often lack diversity of driving scenes, and hence compromise the resulting efficacy and reliability. Second, for machine-learning-based systems, a mismatch between training and application domain can dramatically degrade system accuracy, such that it is necessary to validate inputs for improving system robustness. In this paper, we propose DeepRoad, an unsupervised DNN-based framework for automatically testing the consistency of DNN-based autonomous driving systems and online validation. First, DeepRoad automatically synthesizes large amounts of diverse driving scenes without using image transformation rules (e.g. scale, shear and rotation). In particular, DeepRoad is able to produce driving scenes with various weather conditions (including those with rather extreme conditions) by applying Generative Adversarial Networks (GANs) along with the corresponding real-world weather scenes. Second, DeepRoad utilizes metamorphic testing techniques to check the consistency of such systems using synthetic images. Third, DeepRoad validates input images for DNN-based systems by measuring the distance of the input and training images using their VGGNet features. We implement DeepRoad to test three well-recognized DNN-based autonomous driving systems in Udacity self-driving car challenge. The experimental results demonstrate that DeepRoad can detect thousands of inconsistent behaviors for these systems, and effectively validate input images to potentially enhance the system robustness as well.},
  booktitle = {Proceedings of the 33rd ACM/IEEE International Conference on Automated Software Engineering},
  pages     = {132–142},
  numpages  = {11},
  keywords  = {Software testing, Test generation, Deep Neural Networks, Input validation},
  location  = {Montpellier, France},
  series    = {ASE '18}
}


@inproceedings{Fang2020,
  author    = {Fang, Anjie and Filice, Simone and Limsopatham, Nut and Rokhlenko, Oleg},
  year      = {2020},
  month     = {07},
  pages     = {699-708},
  title     = {Using Phoneme Representations to Build Predictive Models Robust to ASR Errors},
  booktitle = {Proceedings of the 43rd International ACM SIGIR Conference on Research and Development in Information Retrieval (SIGIR '20)},
  doi       = {10.1145/3397271.3401050}
}


@inproceedings{shor19_interspeech,
  author    = {Joel Shor and Dotan Emanuel and Oran Lang and Omry Tuval and Michael Brenner and Julie Cattiau and Fernando Vieira and Maeve McNally and Taylor Charbonneau and Melissa Nollstadt and Avinatan Hassidim and Yossi Matias},
  title     = {{Personalizing ASR for Dysarthric and Accented Speech with Limited Data}},
  year      = 2019,
  booktitle = {Proc. Interspeech 2019},
  pages     = {784--788},
  doi       = {10.21437/Interspeech.2019-1427}
}

@article{strayer2014measuring,
  title  = {Measuring cognitive distraction in the automobile II: Assessing in-vehicle voice-based interactive technologies},
  author = {Strayer, David L and Turrill, Jonna and Coleman, James R and Ortiz, Emily V and Cooper, Joel M},
  year   = {2014}
}

@misc{bitch,
  author    = {Ramesh, Krithika and KhudaBukhsh, Ashiqur R. and Kumar, Sumeet},
  title     = {'Beach' to 'Bitch': Inadvertent Unsafe Transcription of Kids' Content on YouTube},
  publisher = {AAAI},
  year      = {2022}
}


@inproceedings{fast,
  title     = {Fast {W}ord{P}iece Tokenization},
  author    = {Song, Xinying  and
               Salcianu, Alex  and
               Song, Yang  and
               Dopson, Dave  and
               Zhou, Denny},
  booktitle = {Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing},
  month     = nov,
  year      = {2021},
  address   = {Online and Punta Cana, Dominican Republic},
  publisher = {Association for Computational Linguistics},
  url       = {https://aclanthology.org/2021.emnlp-main.160},
  doi       = {10.18653/v1/2021.emnlp-main.160},
  pages     = {2089--2103},
  abstract  = {Tokenization is a fundamental preprocessing step for almost all NLP tasks. In this paper, we propose efficient algorithms for the WordPiece tokenization used in BERT, from single-word tokenization to general text (e.g., sentence) tokenization. When tokenizing a single word, WordPiece uses a longest-match-first strategy, known as maximum matching. The best known algorithms so far are O(n{\^{}}2) (where n is the input length) or O(nm) (where m is the maximum vocabulary token length). We propose a novel algorithm whose tokenization complexity is strictly O(n). Our method is inspired by the Aho-Corasick algorithm. We introduce additional linkages on top of the trie built from the vocabulary, allowing smart transitions when the trie matching cannot continue. For general text, we further propose an algorithm that combines pre-tokenization (splitting the text into words) and our linear-time WordPiece method into a single pass. Experimental results show that our method is 8.2x faster than HuggingFace Tokenizers and 5.1x faster than TensorFlow Text on average for general text tokenization.}
}

@inproceedings{shi2022identifier,
  author    = {Jieke Shi and Zhou Yang and Junda He and Bowen Xu and David Lo},
  booktitle = {2022 IEEE International Conference on Software Analysis, Evolution and Reengineering (SANER)},
  title     = {Can Identifier Splitting Improve Open-Vocabulary Language Model of Code?},
  year      = {2022},
  volume    = {},
  publisher = {IEEE Computer Society}
}


@inproceedings{monash-fairness,
  title     = {Exploring and Repairing Gender Fairness Violations in Word Embedding-based Sentiment Analysis Model through Adversarial Patches},
  booktitle = {2023 IEEE International Conference on Software Analysis, Evolution and Reengineering (SANER)},
  author    = {Khoo, Lin Sze and Bay, Jia Qi and Yap, Ming Lee Kimberly and Lim, Mei Kuan and Chong, Chun Yong and Yang, Zhou and Lo, David},
  year      = {2023},
  volume    = {},
  publisher = {IEEE Computer Society}
}

@inproceedings{10.1145/3551349.3560438,
  author    = {Al Madi, Naser},
  title     = {How Readable is Model-Generated Code? Examining Readability and Visual Inspection of GitHub Copilot},
  year      = {2023},
  isbn      = {9781450394758},
  publisher = {Association for Computing Machinery},
  address   = {New York, NY, USA},
  url       = {https://doi.org/10.1145/3551349.3560438},
  doi       = {10.1145/3551349.3560438},
  abstract  = {Background: Recent advancements in large language models have motivated the practical use of such models in code generation and program synthesis. However, little is known about the effects of such tools on code readability and visual attention in practice. Objective: In this paper, we focus on GitHub Copilot to address the issues of readability and visual inspection of model generated code. Readability and low complexity are vital aspects of good source code, and visual inspection of generated code is important in light of automation bias. Method: Through a human experiment (n=21) we compare model generated code to code written completely by human programmers. We use a combination of static code analysis and human annotators to assess code readability, and we use eye tracking to assess the visual inspection of code. Results: Our results suggest that model generated code is comparable in complexity and readability to code written by human pair programmers. At the same time, eye tracking data suggests, to a statistically significant level, that programmers direct less visual attention to model generated code. Conclusion: Our findings highlight that reading code is more important than ever, and programmers should beware of complacency and automation bias with model generated code.},
  booktitle = {Proceedings of the 37th IEEE/ACM International Conference on Automated Software Engineering},
  articleno = {205},
  numpages  = {5},
  keywords  = {Readability, Empirical Study, Copilot, GitHub, Eye Tracking},
  location  = {Rochester, MI, USA},
  series    = {ASE '22}
}

@misc{wang2023investigating,
  title         = {Investigating and Designing for Trust in AI-powered Code Generation Tools},
  author        = {Ruotong Wang and Ruijia Cheng and Denae Ford and Thomas Zimmermann},
  year          = {2023},
  eprint        = {2305.11248},
  archiveprefix = {arXiv},
  primaryclass  = {cs.HC}
}

@article{10.1145/3236386.3241340,
  author     = {Lipton, Zachary C.},
  title      = {The Mythos of Model Interpretability: In Machine Learning, the Concept of Interpretability is Both Important and Slippery.},
  year       = {2018},
  issue_date = {May-June 2018},
  publisher  = {Association for Computing Machinery},
  address    = {New York, NY, USA},
  volume     = {16},
  number     = {3},
  issn       = {1542-7730},
  url        = {https://doi.org/10.1145/3236386.3241340},
  doi        = {10.1145/3236386.3241340},
  abstract   = {Supervised machine-learning models boast remarkable predictive capabilities. But can you trust your model? Will it work in deployment? What else can it tell you about the world?},
  journal    = {Queue},
  month      = {jun},
  pages      = {31–57},
  numpages   = {27}
}


@inproceedings{lin2009select,
  author  = {Lin, Hui and Bilmes, Jeff},
  year    = {2009},
  month   = {09},
  pages   = {2859-2862},
  title   = {How to select a good training-data subset for transcription: Submodular active selection for sequences},
  journal = {Proceedings of the Annual Conference of the International Speech Communication Association, INTERSPEECH},
  doi     = {10.21437/Interspeech.2009-730}
}

@article{haryono2022androevolve,
  title={AndroEvolve: automated Android API update with data flow analysis and variable denormalization},
  author={Haryono, Stefanus A and Thung, Ferdian and Lo, David and Jiang, Lingxiao and Lawall, Julia and Kang, Hong Jin and Serrano, Lucas and Muller, Gilles},
  journal={Empirical Software Engineering},
  volume={27},
  number={3},
  pages={73},
  year={2022},
  publisher={Springer}
}

@inproceedings{10.1145/3387904.3389285,
  author    = {Haryono, Stefanus A. and Thung, Ferdian and Kang, Hong Jin and Serrano, Lucas and Muller, Gilles and Lawall, Julia and Lo, David and Jiang, Lingxiao},
  title     = {Automatic Android Deprecated-API Usage Update by Learning from Single Updated Example},
  year      = {2020},
  isbn      = {9781450379588},
  publisher = {Association for Computing Machinery},
  address   = {New York, NY, USA},
  url       = {https://doi.org/10.1145/3387904.3389285},
  doi       = {10.1145/3387904.3389285},
  abstract  = {Due to the deprecation of APIs in the Android operating system, developers have to update usages of the APIs to ensure that their applications work for both the past and current versions of Android. Such updates may be widespread, non-trivial, and time-consuming. Therefore, automation of such updates will be of great benefit to developers. AppEvolve, which is the state-of-the-art tool for automating such updates, relies on having before- and after-update examples to learn from. In this work, we propose an approach named CocciEvolve that performs such updates using only a single after-update example. CocciEvolve learns edits by extracting the relevant update to a block of code from an after-update example. From preliminary experiments, we find that CocciEvolve can successfully perform 96 out of 112 updates, with a success rate of 85\%.},
  booktitle = {Proceedings of the 28th International Conference on Program Comprehension},
  pages     = {401–405},
  numpages  = {5},
  keywords  = {single example, program transformation, Android, API update},
  location  = {Seoul, Republic of Korea},
  series    = {ICPC '20}
}

@inproceedings{9240704,
  author    = {Zhang, Ting and Xu, Bowen and Thung, Ferdian and Haryono, Stefanus Agus and Lo, David and Jiang, Lingxiao},
  booktitle = {2020 IEEE International Conference on Software Maintenance and Evolution (ICSME)},
  title     = {Sentiment Analysis for Software Engineering: How Far Can Pre-trained Transformer Models Go?},
  year      = {2020},
  volume    = {},
  number    = {},
  pages     = {70-80},
  doi       = {10.1109/ICSME46990.2020.00017}
}

@article{lan2019albert,
  title   = {Albert: A lite bert for self-supervised learning of language representations},
  author  = {Lan, Zhenzhong and Chen, Mingda and Goodman, Sebastian and Gimpel, Kevin and Sharma, Piyush and Soricut, Radu},
  journal = {arXiv preprint arXiv:1909.11942},
  year    = {2019}
}

@article{RoBERTa,
  author     = {Yinhan Liu and
                Myle Ott and
                Naman Goyal and
                Jingfei Du and
                Mandar Joshi and
                Danqi Chen and
                Omer Levy and
                Mike Lewis and
                Luke Zettlemoyer and
                Veselin Stoyanov},
  title      = {RoBERTa: {A} Robustly Optimized {BERT} Pretraining Approach},
  journal    = {CoRR},
  volume     = {abs/1907.11692},
  year       = {2019},
  url        = {http://arxiv.org/abs/1907.11692},
  eprinttype = {arXiv},
  eprint     = {1907.11692},
  timestamp  = {Thu, 01 Aug 2019 08:59:33 +0200},
  biburl     = {https://dblp.org/rec/journals/corr/abs-1907-11692.bib},
  bibsource  = {dblp computer science bibliography, https://dblp.org}
}

@inproceedings{bert,
  title     = {{BERT}: Pre-training of Deep Bidirectional Transformers for Language Understanding},
  author    = {Devlin, Jacob  and
               Chang, Ming-Wei  and
               Lee, Kenton  and
               Toutanova, Kristina},
  booktitle = {Proceedings of the 2019 Conference of the North {A}merican Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 1 (Long and Short Papers)},
  month     = jun,
  year      = {2019},
  address   = {Minneapolis, Minnesota},
  publisher = {Association for Computational Linguistics},
  url       = {https://aclanthology.org/N19-1423},
  doi       = {10.18653/v1/N19-1423},
  pages     = {4171--4186},
  abstract  = {We introduce a new language representation model called BERT, which stands for Bidirectional Encoder Representations from Transformers. Unlike recent language representation models (Peters et al., 2018a; Radford et al., 2018), BERT is designed to pre-train deep bidirectional representations from unlabeled text by jointly conditioning on both left and right context in all layers. As a result, the pre-trained BERT model can be fine-tuned with just one additional output layer to create state-of-the-art models for a wide range of tasks, such as question answering and language inference, without substantial task-specific architecture modifications. BERT is conceptually simple and empirically powerful. It obtains new state-of-the-art results on eleven natural language processing tasks, including pushing the GLUE score to 80.5 (7.7 point absolute improvement), MultiNLI accuracy to 86.7{\%} (4.6{\%} absolute improvement), SQuAD v1.1 question answering Test F1 to 93.2 (1.5 point absolute improvement) and SQuAD v2.0 Test F1 to 83.1 (5.1 point absolute improvement).}
}

@inproceedings{bert-attack,
  title     = {BERT-ATTACK: Adversarial Attack Against BERT Using BERT},
  author    = {Li, Linyang and Ma, Ruotian and Guo, Qipeng and Xue, Xiangyang and Qiu, Xipeng},
  booktitle = {Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP)},
  pages     = {6193--6202},
  year      = {2020}
}

@inproceedings{simoncini2021seqattack,
  title     = {SeqAttack: On adversarial attacks for named entity recognition},
  author    = {Simoncini, Walter and Spanakis, Gerasimos},
  booktitle = {Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing: System Demonstrations},
  pages     = {308--318},
  year      = {2021}
}

@article{mann1947test,
  title     = {On a test of whether one of two random variables is stochastically larger than the other},
  author    = {Mann, Henry B and Whitney, Donald R},
  journal   = {The annals of mathematical statistics},
  pages     = {50--60},
  year      = {1947},
  publisher = {JSTOR}
}

@misc{art,
  title        = {Adversarial Robustness Toolbox (ART)},
  howpublished = {\url{https://github.com/Trusted-AI/adversarial-robustness-toolbox}},
  note         = {Accessed: 2021-11-19}
}



@inproceedings{google_coverage,
  author    = {Ivankovi\'{c}, Marko and Petrovi\'{c}, Goran and Just, Ren\'{e} and Fraser, Gordon},
  title     = {Code Coverage at Google},
  year      = {2019},
  isbn      = {9781450355728},
  publisher = {Association for Computing Machinery},
  address   = {New York, NY, USA},
  url       = {https://doi.org/10.1145/3338906.3340459},
  doi       = {10.1145/3338906.3340459},
  abstract  = {Code coverage is a measure of the degree to which a test suite exercises a software system. Although coverage is well established in software engineering research, deployment in industry is often inhibited by the perceived usefulness and the computational costs of analyzing coverage at scale. At Google, coverage information is computed for one billion lines of code daily, for seven programming languages. A key aspect of making coverage information actionable is to apply it at the level of changesets and code review. This paper describes Google’s code coverage infrastructure and how the computed code coverage information is visualized and used. It also describes the challenges and solutions for adopting code coverage at scale. To study how code coverage is adopted and perceived by developers, this paper analyzes adoption rates, error rates, and average code coverage ratios over a five-year period, and it reports on 512 responses, received from surveying 3000 developers. Finally, this paper provides concrete suggestions for how to implement and use code coverage in an industrial setting.},
  booktitle = {Proceedings of the 2019 27th ACM Joint Meeting on European Software Engineering Conference and Symposium on the Foundations of Software Engineering},
  pages     = {955–963},
  numpages  = {9},
  keywords  = {coverage, industrial study, test infrastructure},
  location  = {Tallinn, Estonia},
  series    = {ESEC/FSE 2019}
}


@inproceedings{icse_no_correaltion,
  author    = {Inozemtseva, Laura and Holmes, Reid},
  title     = {Coverage is Not Strongly Correlated with Test Suite Effectiveness},
  year      = {2014},
  isbn      = {9781450327565},
  publisher = {Association for Computing Machinery},
  address   = {New York, NY, USA},
  url       = {https://doi.org/10.1145/2568225.2568271},
  doi       = {10.1145/2568225.2568271},
  abstract  = { The coverage of a test suite is often used as a proxy for its ability to detect faults. However, previous studies that investigated the correlation between code coverage and test suite effectiveness have failed to reach a consensus about the nature and strength of the relationship between these test suite characteristics. Moreover, many of the studies were done with small or synthetic programs, making it unclear whether their results generalize to larger programs, and some of the studies did not account for the confounding influence of test suite size. In addition, most of the studies were done with adequate suites, which are are rare in practice, so the results may not generalize to typical test suites.  We have extended these studies by evaluating the relationship between test suite size, coverage, and effectiveness for large Java programs. Our study is the largest to date in the literature: we generated 31,000 test suites for five systems consisting of up to 724,000 lines of source code. We measured the statement coverage, decision coverage, and modified condition coverage of these suites and used mutation testing to evaluate their fault detection effectiveness.  We found that there is a low to moderate correlation between coverage and effectiveness when the number of test cases in the suite is controlled for. In addition, we found that stronger forms of coverage do not provide greater insight into the effectiveness of the suite. Our results suggest that coverage, while useful for identifying under-tested parts of a program, should not be used as a quality target because it is not a good indicator of test suite effectiveness. },
  booktitle = {Proceedings of the 36th International Conference on Software Engineering},
  pages     = {435–445},
  numpages  = {11},
  keywords  = {Coverage, test suite effectiveness, test suite quality},
  location  = {Hyderabad, India},
  series    = {ICSE 2014}
}

@inproceedings{resnet,
  author    = {He, Kaiming and Zhang, Xiangyu and Ren, Shaoqing and Sun, Jian},
  booktitle = {2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},
  title     = {Deep Residual Learning for Image Recognition},
  year      = {2016},
  volume    = {},
  number    = {},
  pages     = {770-778},
  doi       = {10.1109/CVPR.2016.90},
  url       = {https://doi.org/10.1109/CVPR.2016.90},
  abstract  = {Deeper neural networks are more difficult to train. We present a residual learning framework to ease the training of networks that are substantially deeper than those used previously. We explicitly reformulate the layers as learning residual functions with reference to the layer inputs, instead of learning unreferenced functions. We provide comprehensive empirical evidence showing that these residual networks are easier to optimize, and can gain accuracy from considerably increased depth. On the ImageNet dataset we evaluate residual nets with a depth of up to 152 layers - 8× deeper than VGG nets [40] but still having lower complexity. An ensemble of these residual nets achieves 3.57% error on the ImageNet test set. This result won the 1st place on the ILSVRC 2015 classification task. We also present analysis on CIFAR-10 with 100 and 1000 layers. The depth of representations is of central importance for many visual recognition tasks. Solely due to our extremely deep representations, we obtain a 28% relative improvement on the COCO object detection dataset. Deep residual nets are foundations of our submissions to ILSVRC & COCO 2015 competitions1, where we also won the 1st places on the tasks of ImageNet detection, ImageNet localization, COCO detection, and COCO segmentation.}
}


@inproceedings{asrevolve,
  author    = {Asyrofi, Muhammad Hilmi and Yang, Zhou and Shi, Jicke and Quan, Chu Wei and Lo, David},
  booktitle = {2021 IEEE International Conference on Software Maintenance and Evolution (ICSME)},
  title     = {Can Differential Testing Improve Automatic Speech Recognition Systems?},
  year      = {2021},
  volume    = {},
  number    = {},
  pages     = {674-678},
  doi       = {10.1109/ICSME52107.2021.00079}
}

@inproceedings{eurosat,
  author    = {Helber, Patrick and Bischke, Benjamin and Dengel, Andreas and Borth, Damian},
  booktitle = {IGARSS 2018 - 2018 IEEE International Geoscience and Remote Sensing Symposium},
  title     = {Introducing Eurosat: A Novel Dataset and Deep Learning Benchmark for Land Use and Land Cover Classification},
  year      = {2018},
  volume    = {},
  number    = {},
  pages     = {204-207},
  doi       = {10.1109/IGARSS.2018.8519248},
  url       = {https://doi.org/10.1109/IGARSS.2018.8519248}
}

@article{ye2021automated,
  title     = {Automated patch assessment for program repair at scale},
  author    = {Ye, He and Martinez, Matias and Monperrus, Martin},
  journal   = {Empirical Software Engineering},
  volume    = {26},
  number    = {2},
  pages     = {1--38},
  year      = {2021},
  publisher = {Springer}
}


@article{align,
  author     = {Nicholas Ruiz and
                Marcello Federico},
  title      = {Phonetically-Oriented Word Error Alignment for Speech Recognition
                Error Analysis in Speech Translation},
  journal    = {CoRR},
  volume     = {abs/1904.11024},
  year       = {2019},
  url        = {http://arxiv.org/abs/1904.11024},
  eprinttype = {arXiv},
  eprint     = {1904.11024},
  timestamp  = {Thu, 02 May 2019 15:13:44 +0200},
  biburl     = {https://dblp.org/rec/journals/corr/abs-1904-11024.bib},
  bibsource  = {dblp computer science bibliography, https://dblp.org}
}

@inproceedings{8301638,
  author    = {Këpuska, Veton and Bohouta, Gamal},
  booktitle = {2018 IEEE 8th Annual Computing and Communication Workshop and Conference (CCWC)},
  title     = {Next-generation of virtual personal assistants (Microsoft Cortana, Apple Siri, Amazon Alexa and Google Home)},
  year      = {2018},
  volume    = {},
  number    = {},
  pages     = {99-103},
  doi       = {10.1109/CCWC.2018.8301638}
}

@inproceedings{healthcare,
  author    = {Kocaballi, A. Baki and Quiroz, Juan C. and Laranjo, Liliana and Rezazadegan, Dana and Kocielnik, Rafal and Clark, Leigh and Liao, Q. Vera and Park, Sun Young and Moore, Robert J. and Miner, Adam},
  title     = {Conversational Agents for Health and Wellbeing},
  year      = {2020},
  isbn      = {9781450368193},
  publisher = {Association for Computing Machinery},
  address   = {New York, NY, USA},
  url       = {https://doi.org/10.1145/3334480.3375154},
  doi       = {10.1145/3334480.3375154},
  abstract  = {Conversational agents have increasingly been deployed in healthcare applications. However, significant challenges remain in developing this technology. Recent research in this area has highlighted that: i) patient safety was rarely evaluated; ii) health outcomes were poorly measured, and iii) no standardised evaluation methods were employed. The conversational agents in healthcare are lagging behind the developments in other domains. This one-day workshop aims to create a roadmap for healthcare conversational agents to develop standardised design and evaluation frameworks. This will prioritise health outcomes and patient safety while ensuring a high-quality user experience. In doing so, this workshop will bring together researchers and practitioners from HCI, healthcare and related speech and chatbot domains to collaborate on these key challenges.},
  booktitle = {Extended Abstracts of the 2020 CHI Conference on Human Factors in Computing Systems},
  pages     = {1–8},
  numpages  = {8},
  keywords  = {voice interface, conversational agent, health informatics, healthcare, speech interface, chatbots},
  location  = {Honolulu, HI, USA},
  series    = {CHI EA '20}
}

@inproceedings{robot_control,
  author    = {Yoshimura, Naoya and Yoshida, Hironori and Matulic, Fabrice and Igarashi, Takeo},
  title     = {Extending Discrete Verbal Commands with Continuous Speech for Flexible Robot Control},
  year      = {2019},
  isbn      = {9781450359719},
  publisher = {Association for Computing Machinery},
  address   = {New York, NY, USA},
  url       = {https://doi.org/10.1145/3290607.3312791},
  doi       = {10.1145/3290607.3312791},
  abstract  = {Speech is a direct and intuitive method to control a robot. While natural speech can capture a rich variety of commands, verbal input is poorly suited to finer grained and real-time control of continuous actions such as short and precise motion commands. For these types of operations, continuous non-verbal speech is more suitable, but it lacks the naturalness and vocabulary breadth of verbal speech. In this work, we propose to combine the two types of vocal input by extending the last vowel of a verbal command to support real-time and smooth control of robot actions. We demonstrate the effectiveness of this novel hybrid speech input method in a beverage-pouring task, where users instruct a robot arm to pour specific quantities of liquid into a cup. A user evaluation reveals that hybrid speech improves on simple verbal-only commands.},
  booktitle = {Extended Abstracts of the 2019 CHI Conference on Human Factors in Computing Systems},
  pages     = {1–6},
  numpages  = {6},
  keywords  = {human robot interaction, voice inputs, continuous control},
  location  = {Glasgow, Scotland Uk},
  series    = {CHI EA '19}
}

@misc{baffle,
  doi       = {10.48550/ARXIV.2210.04688},
  url       = {https://arxiv.org/abs/2210.04688},
  author    = {Gong, Chen and Yang, Zhou and Bai, Yunpeng and He, Junda and Shi, Jieke and Sinha, Arunesh and Xu, Bowen and Hou, Xinwen and Fan, Guoliang and Lo, David},
  keywords  = {Machine Learning (cs.LG), Artificial Intelligence (cs.AI), FOS: Computer and information sciences, FOS: Computer and information sciences},
  title     = {Mind Your Data! Hiding Backdoors in Offline Reinforcement Learning Datasets},
  publisher = {arXiv},
  year      = {2022},
  copyright = {arXiv.org perpetual, non-exclusive license}
}


@inproceedings{6854213,
  author    = {Wei, Kai and Liu, Yuzong and Kirchhoff, Katrin and Bartels, Chris and Bilmes, Jeff},
  booktitle = {2014 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)},
  title     = {Submodular subset selection for large-scale speech training data},
  year      = {2014},
  volume    = {},
  number    = {},
  pages     = {3311-3315},
  doi       = {10.1109/ICASSP.2014.6854213}
}

@inproceedings{7178848,
  author    = {Ni, Chongjia and Wang, Lei and Liu, Haibo and Leung, Cheung-Chi and Lu, Li and Ma, Bin},
  booktitle = {2015 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)},
  title     = {Submodular data selection with acoustic and phonetic features for automatic speech recognition},
  year      = {2015},
  volume    = {},
  number    = {},
  pages     = {4629-4633},
  doi       = {10.1109/ICASSP.2015.7178848}
}

@article{wav2vec2,
  title   = {wav2vec 2.0: A framework for self-supervised learning of speech representations},
  author  = {Baevski, Alexei and Zhou, Yuhao and Mohamed, Abdelrahman and Auli, Michael},
  journal = {Advances in Neural Information Processing Systems},
  volume  = {33},
  pages   = {12449--12460},
  year    = {2020}
}

@article{HuBERT,
  author  = {Hsu, Wei-Ning and Bolte, Benjamin and Tsai, Yao-Hung Hubert and Lakhotia, Kushal and Salakhutdinov, Ruslan and Mohamed, Abdelrahman},
  journal = {IEEE/ACM Transactions on Audio, Speech, and Language Processing},
  title   = {HuBERT: Self-Supervised Speech Representation Learning by Masked Prediction of Hidden Units},
  year    = {2021},
  volume  = {29},
  number  = {},
  pages   = {3451-3460},
  doi     = {10.1109/TASLP.2021.3122291}
}

@inproceedings{IndicTTS,
  author    = {Vignesh, S. Rupak and Shanmugam, S. Aswin and Murthy, Hema A.},
  booktitle = {2016 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)},
  title     = {Significance of Pseudo-syllables in building better acoustic models for Indian English TTS},
  year      = {2016},
  volume    = {},
  number    = {},
  pages     = {5620-5624},
  doi       = {10.1109/ICASSP.2016.7472753}
}

@inproceedings{FGSM,
  title     = {Explaining and Harnessing Adversarial Examples},
  author    = {Ian Goodfellow and Jonathon Shlens and Christian Szegedy},
  year      = {2015},
  url       = {http://arxiv.org/abs/1412.6572},
  booktitle = {International Conference on Learning Representations},
  abstract  = {Several machine learning models, including neural networks, consistently misclassify adversarial examples---inputs formed by applying small but intentionally worst-case perturbations to examples from the dataset, such that the perturbed input results in the model outputting an incorrect answer with high confidence. Early attempts at explaining this phenomenon focused on nonlinearity and overfitting. We argue instead that the primary cause of neural networks' vulnerability to adversarial perturbation is their linear nature. This explanation is supported by new quantitative results while giving the first explanation of the most intriguing fact about them: their generalization across architectures and training sets. Moreover, this view yields a simple and fast method of generating adversarial examples. Using this approach to provide examples for adversarial training, we reduce the test set error of a maxout network on the MNIST dataset.}
}

@inproceedings{SSIM,
  author    = {Hor\'{e}, Alain and Ziou, Djemel},
  booktitle = {2010 20th International Conference on Pattern Recognition},
  title     = {Image Quality Metrics: PSNR vs. SSIM},
  year      = {2010},
  volume    = {},
  number    = {},
  pages     = {2366-2369},
  doi       = {10.1109/ICPR.2010.579}
}

@misc{replication-saner-22,
  title        = {Replication Package},
  howpublished = {\url{https://github.com/soarsmu/Revisiting_Neuron_Coverage.git}},
  note         = {Accessed: 2021-11-19}
}

@inproceedings{CONTA,
  author    = {Zhang, Dong and Zhang, Hanwang and Tang, Jinhui and Hua, Xian-Sheng and Sun, Qianru},
  booktitle = {Advances in Neural Information Processing Systems},
  editor    = {H. Larochelle and M. Ranzato and R. Hadsell and M. F. Balcan and H. Lin},
  pages     = {655--666},
  publisher = {Curran Associates, Inc.},
  title     = {Causal Intervention for Weakly-Supervised Semantic Segmentation},
  url       = {https://proceedings.neurips.cc/paper/2020/file/07211688a0869d995947a8fb11b215d6-Paper.pdf},
  volume    = {33},
  year      = {2020}
}



@article{mnih2015human,
  title     = {Human-level control through deep reinforcement learning},
  author    = {Mnih, Volodymyr and Kavukcuoglu, Koray and Silver, David and Rusu, Andrei A and Veness, Joel and Bellemare, Marc G and Graves, Alex and Riedmiller, Martin and Fidjeland, Andreas K and Ostrovski, Georg and others},
  journal   = {nature},
  volume    = {518},
  number    = {7540},
  pages     = {529--533},
  year      = {2015},
  doi       = {https://doi.org/10.1038/nature14236},
  url       = {https://doi.org/10.1038/nature14236},
  publisher = {Nature Publishing Group},
  abstract  = {The theory of reinforcement learning provides a normative account1, deeply rooted in psychological2 and neuroscientific3 perspectives on animal behaviour, of how agents may optimize their control of an environment. To use reinforcement learning successfully in situations approaching real-world complexity, however, agents are confronted with a difficult task: they must derive efficient representations of the environment from high-dimensional sensory inputs, and use these to generalize past experience to new situations. Remarkably, humans and other animals seem to solve this problem through a harmonious combination of reinforcement learning and hierarchical sensory processing systems4,5, the former evidenced by a wealth of neural data revealing notable parallels between the phasic signals emitted by dopaminergic neurons and temporal difference reinforcement learning algorithms3. While reinforcement learning agents have achieved some successes in a variety of domains6,7,8, their applicability has previously been limited to domains in which useful features can be handcrafted, or to domains with fully observed, low-dimensional state spaces. Here we use recent advances in training deep neural networks9,10,11 to develop a novel artificial agent, termed a deep Q-network, that can learn successful policies directly from high-dimensional sensory inputs using end-to-end reinforcement learning. We tested this agent on the challenging domain of classic Atari 2600 games12. We demonstrate that the deep Q-network agent, receiving only the pixels and the game score as inputs, was able to surpass the performance of all previous algorithms and achieve a level comparable to that of a professional human games tester across a set of 49 games, using the same algorithm, network architecture and hyperparameters. This work bridges the divide between high-dimensional sensory inputs and actions, resulting in the first artificial agent that is capable of learning to excel at a diverse array of challenging tasks.}
}

@article{abdel2014convolutional,
  author   = {Abdel-Hamid, Ossama and Mohamed, Abdel-rahman and Jiang, Hui and Deng, Li and Penn, Gerald and Yu, Dong},
  journal  = {IEEE/ACM Transactions on Audio, Speech, and Language Processing},
  title    = {Convolutional Neural Networks for Speech Recognition},
  year     = {2014},
  volume   = {22},
  number   = {10},
  pages    = {1533-1545},
  doi      = {10.1109/TASLP.2014.2339736},
  url      = {https://doi.org/10.1109/TASLP.2014.2339736},
  abstract = {Recently, the hybrid deep neural network (DNN)-hidden Markov model (HMM) has been shown to significantly improve speech recognition performance over the conventional Gaussian mixture model (GMM)-HMM. The performance improvement is partially attributed to the ability of the DNN to model complex correlations in speech features. In this paper, we show that further error rate reduction can be obtained by using convolutional neural networks (CNNs). We first present a concise description of the basic CNN and explain how it can be used for speech recognition. We further propose a limited-weight-sharing scheme that can better model speech features. The special structure such as local connectivity, weight sharing, and pooling in CNNs exhibits some degree of invariance to small shifts of speech features along the frequency axis, which is important to deal with speaker and environment variations. Experimental results show that CNNs reduce the error rate by 6%-10% compared with DNNs on the TIMIT phone recognition and the voice search large vocabulary speech recognition tasks.}
}


@inproceedings{DBLP:journals/corr/BahdanauCB14,
  author    = {Dzmitry Bahdanau and
               Kyunghyun Cho and
               Yoshua Bengio},
  editor    = {Yoshua Bengio and
               Yann LeCun},
  title     = {Neural Machine Translation by Jointly Learning to Align and Translate},
  booktitle = {3rd International Conference on Learning Representations, {ICLR} 2015,
               San Diego, CA, USA, May 7-9, 2015, Conference Track Proceedings},
  year      = {2015},
  url       = {http://arxiv.org/abs/1409.0473},
  timestamp = {Wed, 17 Jul 2019 10:40:54 +0200},
  biburl    = {https://dblp.org/rec/journals/corr/BahdanauCB14.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}


@inbook{AdversarialTraining,
  author    = {Shafahi, Ali and Najibi, Mahyar and Ghiasi, Mohammad Amin and Xu, Zheng and Dickerson, John and Studer, Christoph and Davis, Larry S and Taylor, Gavin and Goldstein, Tom},
  booktitle = {Advances in Neural Information Processing Systems},
  editor    = {H. Wallach and H. Larochelle and A. Beygelzimer and F. d\textquotesingle Alch\'{e}-Buc and E. Fox and R. Garnett},
  pages     = {},
  publisher = {Curran Associates, Inc.},
  title     = {Adversarial training for free!},
  url       = {https://proceedings.neurips.cc/paper/2019/file/7503cfacd12053d309b6bed5c89de212-Paper.pdf},
  volume    = {32},
  year      = {2019}
}


@inproceedings{icassp2021,
  author    = {Awasthi, Abhijeet and Kansal, Aman and Sarawagi, Sunita and Jyothi, Preethi},
  booktitle = {ICASSP 2021 - 2021 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)},
  title     = {Error-Driven Fixed-Budget ASR Personalization for Accented Speakers},
  year      = {2021},
  volume    = {},
  number    = {},
  pages     = {7033-7037},
  doi       = {10.1109/ICASSP39728.2021.9414830}
}

@inproceedings{carlini21extracting,
  author    = {Carlini, Nicholas and Tramer, Florian and Wallace, Eric and Jagielski, Matthew and Herbert-Voss, Ariel and Lee, Katherine and Roberts, Adam and Brown, Tom and Song, Dawn and Erlingsson, Ulfar and Oprea, Alina and Raffel, Colin},
  title     = {Extracting Training Data from Large Language Models},
  booktitle = {USENIX Security Symposium},
  year      = {2021}
}

@inproceedings{6947957,
  author    = {Mendonça, Gustavo and Candeias, Sara and Perdigão, Fernando and Shulby, Christopher and Toniazzo, Rean and Klautau, Aldebaro and Aluísio, Sandra},
  booktitle = {2014 International Telecommunications Symposium (ITS)},
  title     = {A method for the extraction of phonetically-rich triphone sentences},
  year      = {2014},
  volume    = {},
  number    = {},
  pages     = {1-5},
  doi       = {10.1109/ITS.2014.6947957}
}

@misc{CovTesting,
  title        = {Yan et al's Replication Package},
  howpublished = {\url{https://github.com/RU-System-Software-and-Security/CovTesting.git}},
  note         = {Accessed: 2021-11-19}
}



@inproceedings{10.1109/ICSE.2017.62,
  author    = {Pearson, Spencer and Campos, Jos\'{e} and Just, Ren\'{e} and Fraser, Gordon and Abreu, Rui and Ernst, Michael D. and Pang, Deric and Keller, Benjamin},
  title     = {Evaluating and Improving Fault Localization},
  year      = {2017},
  isbn      = {9781538638682},
  publisher = {IEEE Press},
  url       = {https://doi.org/10.1109/ICSE.2017.62},
  doi       = {10.1109/ICSE.2017.62},
  abstract  = {Most fault localization techniques take as input a faulty program, and produce as output a ranked list of suspicious code locations at which the program may be defective. When researchers propose a new fault localization technique, they typically evaluate it on programs with known faults. The technique is scored based on where in its output list the defective code appears. This enables the comparison of multiple fault localization techniques to determine which one is better.Previous research has evaluated fault localization techniques using artificial faults, generated either by mutation tools or manually. In other words, previous research has determined which fault localization techniques are best at finding artificial faults. However, it is not known which fault localization techniques are best at finding real faults. It is not obvious that the answer is the same, given previous work showing that artificial faults have both similarities to and differences from real faults.We performed a replication study to evaluate 10 claims in the literature that compared fault localization techniques (from the spectrum-based and mutation-based families). We used 2995 artificial faults in 6 real-world programs. Our results support 7 of the previous claims as statistically significant, but only 3 as having non-negligible effect sizes. Then, we evaluated the same 10 claims, using 310 real faults from the 6 programs. Every previous result was refuted or was statistically and practically insignificant. Our experiments show that artificial faults are not useful for predicting which fault localization techniques perform best on real faults.In light of these results, we identified a design space that includes many previously-studied fault localization techniques as well as hundreds of new techniques. We experimentally determined which factors in the design space are most important, using an overall set of 395 real faults. Then, we extended this design space with new techniques. Several of our novel techniques outperform all existing techniques, notably in terms of ranking defective code in the top-5 or top-10 reports.},
  booktitle = {Proceedings of the 39th International Conference on Software Engineering},
  pages     = {609–620},
  numpages  = {12},
  location  = {Buenos Aires, Argentina},
  series    = {ICSE '17}
}



@inproceedings{10.1145/2597008.2597148,
  author    = {Wang, Shaowei and Lo, David},
  title     = {Version History, Similar Report, and Structure: Putting Them Together for Improved Bug Localization},
  year      = {2014},
  isbn      = {9781450328791},
  publisher = {Association for Computing Machinery},
  address   = {New York, NY, USA},
  url       = {https://doi.org/10.1145/2597008.2597148},
  doi       = {10.1145/2597008.2597148},
  abstract  = { During the evolution of a software system, a large number of bug reports are submitted. Locating the source code files that need to be fixed to resolve the bugs is a challenging problem. Thus, there is a need for a technique that can automatically figure out these buggy files. A number of bug localization solutions that take in a bug report and output a ranked list of files sorted based on their likelihood to be buggy have been proposed in the literature. However, the accuracy of these tools still need to be improved.  In this paper, to address this need, we propose AmaLgam, a new method for locating relevant buggy files that puts together version history, similar reports, and structure. To do this, AmaLgam integrates a bug prediction technique used in Google which analyzes version history, with a bug localization technique named BugLocator which analyzes similar reports from bug report system, and the state-of-the-art bug localization technique BLUiR which considers structure. We perform a large-scale experiment on four open source projects, namely AspectJ, Eclipse, SWT and ZXing to localize more than 3,000 bugs. Compared with a history-aware bug localization solution of Sisman and Kak, our approach achieves a 46.1% improvement in terms of mean average precision (MAP). Compared with BugLocator, our approach achieves a 24.4% improvement in terms of MAP. Compared with BLUiR, our approach achieves a 16.4% improvement in terms of MAP. },
  booktitle = {Proceedings of the 22nd International Conference on Program Comprehension},
  pages     = {53–63},
  numpages  = {11},
  keywords  = {Structure, Bug Localization, Version History, Similar Report},
  location  = {Hyderabad, India},
  series    = {ICPC 2014}
}

@inproceedings{10.1145/1101908.1101949,
  author    = {Jones, James A. and Harrold, Mary Jean},
  title     = {Empirical Evaluation of the Tarantula Automatic Fault-Localization Technique},
  year      = {2005},
  isbn      = {1581139934},
  publisher = {Association for Computing Machinery},
  address   = {New York, NY, USA},
  url       = {https://doi.org/10.1145/1101908.1101949},
  doi       = {10.1145/1101908.1101949},
  abstract  = {The high cost of locating faults in programs has motivated the development of techniques that assist in fault localization by automating part of the process of searching for faults. Empirical studies that compare these techniques have reported the relative effectiveness of four existing techniques on a set of subjects. These studies compare the rankings that the techniques compute for statements in the subject programs and the effectiveness of these rankings in locating the faults. However, it is unknown how these four techniques compare with Tarantula, another existing fault-localization technique, although this technique also provides a way to rank statements in terms of their suspiciousness. Thus, we performed a study to compare the Tarantula technique with the four techniques previously compared. This paper presents our study---it overviews the Tarantula technique along with the four other techniques studied, describes our experiment, and reports and discusses the results. Our studies show that, on the same set of subjects, the Tarantula technique consistently outperforms the other four techniques in terms of effectiveness in fault localization, and is comparable in efficiency to the least expensive of the other four techniques.},
  booktitle = {Proceedings of the 20th IEEE/ACM International Conference on Automated Software Engineering},
  pages     = {273–282},
  numpages  = {10},
  keywords  = {empirical study, fault localization, program analysis, automated debugging},
  location  = {Long Beach, CA, USA},
  series    = {ASE '05}
}

@inproceedings{ciregan2012multi,
  author    = {J. Schmidhuber and U. Meier and D. Ciresan},
  booktitle = {2012 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},
  title     = {Multi-column deep neural networks for image classification},
  year      = {2012},
  volume    = {},
  issn      = {1063-6919},
  pages     = {3642-3649},
  keywords  = {neural nets;graphics processing units;handwritten character recognition;image classification;image recognition;learning (artificial intelligence);traffic sign recognition benchmark;multicolumn deep neural networks;image classification;computer vision;machine learning;human performance;handwritten digits recognition;traffic signs;artificial neural network architectures;convolutional winner-take-all neurons;retina;visual cortex;sparsely connected neural layers;graphics cards;fast training;mnist handwriting benchmark;training;error analysis;neurons;computer architecture;benchmark testing;graphics processing unit},
  doi       = {10.1109/CVPR.2012.6248110},
  url       = {https://doi.ieeecomputersociety.org/10.1109/CVPR.2012.6248110},
  publisher = {IEEE Computer Society},
  address   = {Los Alamitos, CA, USA},
  month     = {jun}
}

 @misc{chatgpt,
  title   = {Introducing chatgpt},
  url     = {https://openai.com/blog/chatgpt},
  journal = {Introducing ChatGPT}
} 

@inproceedings{chatgpt-repair,
  title         = {An Analysis of the Automatic Bug Fixing Performance of ChatGPT},
  author        = {Dominik Sobania and Martin Briesch and Carol Hanna and Justyna Petke},
  year          = {2023},
  eprint        = {2301.08653},
  archiveprefix = {arXiv},
  primaryclass  = {cs.SE}
}

@misc{chatgpt-test-library,
  title         = {Keep the Conversation Going: Fixing 162 out of 337 bugs for 0.42 each using ChatGPT},
  author        = {Chunqiu Steven Xia and Lingming Zhang},
  year          = {2023},
  eprint        = {2304.00385},
  archiveprefix = {arXiv},
  primaryclass  = {cs.SE}
}

@inproceedings{chatgpt-test-education,
  title         = {ChatGPT and Software Testing Education: Promises \& Perils},
  author        = {Sajed Jalil and Suzzana Rafi and Thomas D. LaToza and Kevin Moran and Wing Lam},
  year          = {2023},
  eprint        = {2302.03287},
  archiveprefix = {arXiv},
  primaryclass  = {cs.SE}
}

@misc{deng2023large,
  title         = {Large Language Models are Zero-Shot Fuzzers: Fuzzing Deep-Learning Libraries via Large Language Models},
  author        = {Yinlin Deng and Chunqiu Steven Xia and Haoran Peng and Chenyuan Yang and Lingming Zhang},
  year          = {2023},
  eprint        = {2212.14834},
  archiveprefix = {arXiv},
  primaryclass  = {cs.SE}
}

@inproceedings{chatgpt-refactor,
  title         = {ChatGPT Prompt Patterns for Improving Code Quality, Refactoring, Requirements Elicitation, and Software Design},
  author        = {Jules White and Sam Hays and Quchen Fu and Jesse Spencer-Smith and Douglas C. Schmidt},
  year          = {2023},
  eprint        = {2303.07839},
  archiveprefix = {arXiv},
  primaryclass  = {cs.SE}
}

@article{kim2021datasets,
  title     = {Are datasets for information retrieval-based bug localization techniques trustworthy?},
  author    = {Kim, Misoo and Lee, Eunseok},
  journal   = {Empirical Software Engineering},
  volume    = {26},
  number    = {3},
  pages     = {1--66},
  year      = {2021},
  publisher = {Springer}
}


@inproceedings{choi2017gram,
  author    = {Choi, Edward and Bahadori, Mohammad Taha and Song, Le and Stewart, Walter F. and Sun, Jimeng},
  title     = {GRAM: Graph-Based Attention Model for Healthcare Representation Learning},
  year      = {2017},
  isbn      = {9781450348874},
  publisher = {Association for Computing Machinery},
  address   = {New York, NY, USA},
  url       = {https://doi.org/10.1145/3097983.3098126},
  doi       = {10.1145/3097983.3098126},
  abstract  = {Deep learning methods exhibit promising performance for predictive modeling in healthcare, but two important challenges remain: - Data insufficiency: Often in healthcare predictive modeling, the sample size is insufficient for deep learning methods to achieve satisfactory results.Interpretation: The representations learned by deep learning methods should align with medical knowledge.To address these challenges, we propose GRaph-based Attention Model (GRAM) that supplements electronic health records (EHR) with hierarchical information inherent to medical ontologies. Based on the data volume and the ontology structure, GRAM represents a medical concept as a combination of its ancestors in the ontology via an attention mechanism.We compared predictive performance (i.e. accuracy, data needs, interpretability) of GRAM to various methods including the recurrent neural network (RNN) in two sequential diagnoses prediction tasks and one heart failure prediction task. Compared to the basic RNN, GRAM achieved 10% higher accuracy for predicting diseases rarely observed in the training data and 3% improved area under the ROC curve for predicting heart failure using an order of magnitude less training data. Additionally, unlike other methods, the medical concept representations learned by GRAM are well aligned with the medical ontology. Finally, GRAM exhibits intuitive attention behaviors by adaptively generalizing to higher level concepts when facing data insufficiency at the lower level concepts.},
  booktitle = {Proceedings of the 23rd ACM SIGKDD International Conference on Knowledge Discovery and Data Mining},
  pages     = {787–795},
  numpages  = {9},
  keywords  = {electronic health records, attention model, predictive healthcare, graph},
  location  = {Halifax, NS, Canada},
  series    = {KDD '17}
}



@inproceedings{gopinath2014code,
  author    = {Gopinath, Rahul and Jensen, Carlos and Groce, Alex},
  title     = {Code Coverage for Suite Evaluation by Developers},
  year      = {2014},
  isbn      = {9781450327565},
  publisher = {Association for Computing Machinery},
  address   = {New York, NY, USA},
  url       = {https://doi.org/10.1145/2568225.2568278},
  doi       = {10.1145/2568225.2568278},
  abstract  = { One of the key challenges of developers testing code is determining a test suite's quality -- its ability to find faults. The most common approach is to use code coverage as a measure for test suite quality, and diminishing returns in coverage or high absolute coverage as a stopping rule. In testing research, suite quality is often evaluated by a suite's ability to kill mutants (artificially seeded potential faults). Determining which criteria best predict mutation kills is critical to practical estimation of test suite quality. Previous work has only used small sets of programs, and usually compares multiple suites for a single program. Practitioners, however, seldom compare suites --- they evaluate one suite. Using suites (both manual and automatically generated) from a large set of real-world open-source projects shows that evaluation results differ from those for suite-comparison: statement (not block, branch, or path) coverage predicts mutation kills best. },
  booktitle = {Proceedings of the 36th International Conference on Software Engineering},
  pages     = {72–82},
  numpages  = {11},
  keywords  = {evaluation of coverage criteria, statistical analysis, test frameworks},
  location  = {Hyderabad, India},
  series    = {ICSE 2014}
}

@techreport{CIFAR10,
  author      = {Alex Krizhevsky},
  title       = {Learning multiple layers of features from tiny images},
  institution = {CS Toronto},
  year        = {2009},
  url         = {https://www.cs.toronto.edu/~kriz/learning-features-2009-TR.pdf}
}

@article{activation,
  author     = {Bryant Chen and
                Wilka Carvalho and
                Nathalie Baracaldo and
                Heiko Ludwig and
                Benjamin Edwards and
                Taesung Lee and
                Ian M. Molloy and
                Biplav Srivastava},
  title      = {Detecting Backdoor Attacks on Deep Neural Networks by Activation Clustering},
  journal    = {CoRR},
  volume     = {abs/1811.03728},
  year       = {2018},
  url        = {http://arxiv.org/abs/1811.03728},
  eprinttype = {arXiv},
  eprint     = {1811.03728},
  timestamp  = {Wed, 02 Jun 2021 09:13:29 +0200},
  biburl     = {https://dblp.org/rec/journals/corr/abs-1811-03728.bib},
  bibsource  = {dblp computer science bibliography, https://dblp.org}
}

@inproceedings{surprise,
  author    = {Kim, Jinhan and Feldt, Robert and Yoo, Shin},
  title     = {Guiding Deep Learning System Testing Using Surprise Adequacy},
  year      = {2019},
  publisher = {IEEE Press},
  url       = {https://doi.org/10.1109/ICSE.2019.00108},
  doi       = {10.1109/ICSE.2019.00108},
  abstract  = {Deep Learning (DL) systems are rapidly being adopted in safety and security critical domains, urgently calling for ways to test their correctness and robustness. Testing of DL systems has traditionally relied on manual collection and labelling of data. Recently, a number of coverage criteria based on neuron activation values have been proposed. These criteria essentially count the number of neurons whose activation during the execution of a DL system satisfied certain properties, such as being above predefined thresholds. However, existing coverage criteria are not sufficiently fine grained to capture subtle behaviors exhibited by DL systems. Moreover, evaluations have focused on showing correlation between adversarial examples and proposed criteria rather than evaluating and guiding their use for actual testing of DL systems. We propose a novel test adequacy criterion for testing of DL systems, called Surprise Adequacy for Deep Learning Systems (SADL), which is based on the behaviour of DL systems with respect to their training data. We measure the surprise of an input as the difference in DL system's behaviour between the input and the training data (i.e., what was learnt during training), and subsequently develop this as an adequacy criterion: a good test input should be sufficiently but not overtly surprising compared to training data. Empirical evaluation using a range of DL systems from simple image classifiers to autonomous driving car platforms shows that systematic sampling of inputs based on their surprise can improve classification accuracy of DL systems against adversarial examples by up to 77.5% via retraining.},
  booktitle = {Proceedings of the 41st International Conference on Software Engineering},
  pages     = {1039–1049},
  numpages  = {11},
  keywords  = {deep learning systems, test adequacy},
  location  = {Montreal, Quebec, Canada},
  series    = {ICSE '19}
}

@article{mnist,
  author  = {Deng, Li},
  journal = {IEEE Signal Processing Magazine},
  title   = {The MNIST Database of Handwritten Digit Images for Machine Learning Research [Best of the Web]},
  year    = {2012},
  volume  = {29},
  number  = {6},
  pages   = {141-142},
  doi     = {10.1109/MSP.2012.2211477},
  url     = {https://doi.org/10.1109/MSP.2012.2211477}
}


@inproceedings{42503,
  author    = {Christian Szegedy and
               Wojciech Zaremba and
               Ilya Sutskever and
               Joan Bruna and
               Dumitru Erhan and
               Ian J. Goodfellow and
               Rob Fergus},
  editor    = {Yoshua Bengio and
               Yann LeCun},
  title     = {Intriguing properties of neural networks},
  booktitle = {2nd International Conference on Learning Representations, {ICLR} 2014,
               Banff, AB, Canada, April 14-16, 2014, Conference Track Proceedings},
  year      = {2014},
  url       = {http://arxiv.org/abs/1312.6199},
  timestamp = {Thu, 25 Jul 2019 14:35:25 +0200},
  biburl    = {https://dblp.org/rec/journals/corr/SzegedyZSBEGF13.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@inproceedings{correlation_fse_2020_2,
  author    = {Harel-Canada, Fabrice and Wang, Lingxiao and Gulzar, Muhammad Ali and Gu, Quanquan and Kim, Miryung},
  title     = {Is Neuron Coverage a Meaningful Measure for Testing Deep Neural Networks?},
  year      = {2020},
  isbn      = {9781450370431},
  publisher = {Association for Computing Machinery},
  address   = {New York, NY, USA},
  url       = {https://doi.org/10.1145/3368089.3409754},
  doi       = {10.1145/3368089.3409754},
  abstract  = {Recent effort to test deep learning systems has produced an intuitive and compelling test criterion called neuron coverage (NC), which resembles the notion of traditional code coverage. NC measures the proportion of neurons activated in a neural network and it is implicitly assumed that increasing NC improves the quality of a test suite. In an attempt to automatically generate a test suite that increases NC, we design a novel diversity promoting regularizer that can be plugged into existing adversarial attack algorithms. We then assess whether such attempts to increase NC could generate a test suite that (1) detects adversarial attacks successfully, (2) produces natural inputs, and (3) is unbiased to particular class predictions. Contrary to expectation, our extensive evaluation finds that increasing NC actually makes it harder to generate an effective test suite: higher neuron coverage leads to fewer defects detected, less natural inputs, and more biased prediction preferences. Our results invoke skepticism that increasing neuron coverage may not be a meaningful objective for generating tests for deep neural networks and call for a new test generation technique that considers defect detection, naturalness, and output impartiality in tandem.},
  booktitle = {Proceedings of the 28th ACM Joint Meeting on European Software Engineering Conference and Symposium on the Foundations of Software Engineering},
  pages     = {851–862},
  numpages  = {12},
  keywords  = {Software Engineering, Machine Learning, Testing, Adversarial Attack, Neuron Coverage},
  location  = {Virtual Event, USA},
  series    = {ESEC/FSE 2020}
}
 

@inproceedings{svhn,
  title     = {Reading Digits in Natural Images with Unsupervised Feature Learning},
  author    = {Yuval Netzer and Tao Wang and Adam Coates and Alessandro Bissacco and Bo Wu and Andrew Y. Ng},
  year      = {2011},
  url       = {http://ufldl.stanford.edu/housenumbers/nips2011_housenumbers.pdf},
  booktitle = {NIPS Workshop on Deep Learning and Unsupervised Feature Learning 2011}
}


@inproceedings{pmlr-v97-engstrom19a,
  title     = {Exploring the Landscape of Spatial Robustness},
  author    = {Engstrom, Logan and Tran, Brandon and Tsipras, Dimitris and Schmidt, Ludwig and Madry, Aleksander},
  booktitle = {Proceedings of the 36th International Conference on Machine Learning},
  pages     = {1802--1811},
  year      = {2019},
  editor    = {Kamalika Chaudhuri and Ruslan Salakhutdinov},
  volume    = {97},
  series    = {Proceedings of Machine Learning Research},
  address   = {Long Beach, California, USA},
  month     = {09--15 Jun},
  publisher = {PMLR},
  pdf       = {http://proceedings.mlr.press/v97/engstrom19a/engstrom19a.pdf},
  url       = {http://proceedings.mlr.press/v97/engstrom19a.html},
  abstract  = {The study of adversarial robustness has so far largely focused on perturbations bound in $\ell_p$-norms. However, state-of-the-art models turn out to be also vulnerable to other, more natural classes of perturbations such as translations and rotations. In this work, we thoroughly investigate the vulnerability of neural network–based classifiers to rotations and translations. While data augmentation offers relatively small robustness, we use ideas from robust optimization and test-time input aggregation to significantly improve robustness. Finally we find that, in contrast to the $\ell_p$-norm case, first-order methods cannot reliably find worst-case perturbations. This highlights spatial robustness as a fundamentally different setting requiring additional study.}
}

@inproceedings{ACFH2020square,
  title     = {Square Attack: a query-efficient black-box adversarial attack via random search},
  author    = {Andriushchenko, Maksym and Croce, Francesco and Flammarion, Nicolas and Hein, Matthias},
  booktitle = {European Conference on Computer Vision (ECCV)},
  year      = {2020},
  url       = {https://arxiv.org/abs/1912.00049}
}



@inproceedings{ICECCS,
  author    = {Dong, Yizhen and Zhang, Peixin and Wang, Jingyi and Liu, Shuang and Sun, Jun and Hao, Jianye and Wang, Xinyu and Wang, Li and Dong, Jinsong and Dai, Ting},
  booktitle = {2020 25th International Conference on Engineering of Complex Computer Systems (ICECCS)},
  title     = {An Empirical Study on Correlation between Coverage and Robustness for Deep Neural Networks},
  year      = {2020},
  volume    = {},
  number    = {},
  pages     = {73-82},
  doi       = {10.1109/ICECCS51672.2020.00016},
  url       = {https://doi.org/10.1109/ICECCS51672.2020.00016},
  abstract  = {Deep neural networks (DNN) are increasingly applied in safety-critical systems, e.g., for face recognition, autonomous car control and malware detection. It is also shown that DNNs are subject to attacks such as adversarial perturbation and thus must be properly tested. Many coverage criteria for DNN since have been proposed, inspired by the success of code coverage criteria for software programs. The expectation is that if a DNN is well tested (and retrained) according to such coverage criteria, it is more likely to be robust. In this work, we conduct an empirical study to evaluate the relationship between coverage, robustness and attack/defense metrics for DNN. Our study is the largest to date and systematically done based on 100 DNN models and 25 metrics. One of our findings is that there is limited correlation between coverage and robustness, i.e., improving coverage does not help improve the robustness. Our dataset and implementation have been made available to serve as a benchmark for future studies on testing DNN.}
}

@inproceedings{FSE_Yan,
  author    = {Yan, Shenao and Tao, Guanhong and Liu, Xuwei and Zhai, Juan and Ma, Shiqing and Xu, Lei and Zhang, Xiangyu},
  title     = {Correlations between Deep Neural Network Model Coverage Criteria and Model Quality},
  year      = {2020},
  isbn      = {9781450370431},
  publisher = {Association for Computing Machinery},
  address   = {New York, NY, USA},
  url       = {https://doi.org/10.1145/3368089.3409671},
  doi       = {10.1145/3368089.3409671},
  abstract  = {Inspired by the great success of using code coverage as guidance in software testing,
               a lot of neural network coverage criteria have been proposed to guide testing of neural
               network models (e.g., model accuracy under adversarial attacks). However, while the
               monotonic relation between code coverage and software quality has been supported by
               many seminal studies in software engineering, it remains largely unclear whether similar
               monotonicity exists between neural network model coverage and model quality. This
               paper sets out to answer this question. Specifically, this paper studies the correlation
               between DNN model quality and coverage criteria, effects of coverage guided adversarial
               example generation compared with gradient decent based methods, effectiveness of coverage
               based retraining compared with existing adversarial training, and the internal relationships
               among coverage criteria.},
  booktitle = {Proceedings of the 28th ACM Joint Meeting on European Software Engineering Conference and Symposium on the Foundations of Software Engineering},
  pages     = {775–787},
  numpages  = {13},
  keywords  = {Deep Neural Networks, Software Testing},
  location  = {Virtual Event, USA},
  series    = {ESEC/FSE 2020}
}

@inproceedings{robot,
  author    = {Wang, Jingyi and Chen, Jialuo and Sun, Youcheng and Ma, Xingjun and Wang, Dongxia and Sun, Jun and Cheng, Peng},
  booktitle = {2021 IEEE/ACM 43rd International Conference on Software Engineering (ICSE)},
  title     = {RobOT: Robustness-Oriented Testing for Deep Learning Systems},
  year      = {2021},
  volume    = {},
  number    = {},
  pages     = {300-311},
  doi       = {10.1109/ICSE43902.2021.00038}
}

@article{10.1007/s10664-021-10066-6,
  author     = {Pan, Rongqi and Bagherzadeh, Mojtaba and Ghaleb, Taher A. and Briand, Lionel},
  title      = {Test Case Selection and Prioritization Using Machine Learning: A Systematic Literature Review},
  year       = {2022},
  issue_date = {Mar 2022},
  publisher  = {Kluwer Academic Publishers},
  address    = {USA},
  volume     = {27},
  number     = {2},
  issn       = {1382-3256},
  url        = {https://doi.org/10.1007/s10664-021-10066-6},
  doi        = {10.1007/s10664-021-10066-6},
  abstract   = {Regression testing is an essential activity to assure that software code changes do not adversely affect existing functionalities. With the wide adoption of Continuous Integration (CI) in software projects, which increases the frequency of running software builds, running all tests can be time-consuming and resource-intensive. To alleviate that problem, Test case Selection and Prioritization (TSP) techniques have been proposed to improve regression testing by selecting and prioritizing test cases in order to provide early feedback to developers. In recent years, researchers have relied on Machine Learning (ML) techniques to achieve effective TSP (ML-based TSP). Such techniques help combine information about test cases, from partial and imperfect sources, into accurate prediction models. This work conducts a systematic literature review focused on ML-based TSP techniques, aiming to perform an in-depth analysis of the state of the art, thus gaining insights regarding future avenues of research. To that end, we analyze 29 primary studies published from 2006 to 2020, which have been identified through a systematic and documented process. This paper addresses five research questions addressing variations in ML-based TSP techniques and feature sets for training and testing ML models, alternative metrics used for evaluating the techniques, the performance of techniques, and the reproducibility of the published studies. We summarize the results related to our research questions in a high-level summary that can be used as a taxonomy for classifying future TSP studies.},
  journal    = {Empirical Softw. Engg.},
  month      = {mar},
  numpages   = {43},
  keywords   = {Software testing, Test case selection, Test case prioritization, Systematic literature review, Continuous integration, Machine learning}
}

@inproceedings{yang2022revisiting,
  author    = {Zhou Yang and Jieke Shi and Muhammad Hilmi Asyrofi and David Lo},
  booktitle = {2022 IEEE International Conference on Software Analysis, Evolution and Reengineering (SANER)},
  title     = {Revisiting Neuron Coverage Metrics and Quality of Deep Neural Networks},
  year      = {2022},
  volume    = {},
  issn      = {1534-5351},
  pages     = {408-419},
  abstract  = {Deep neural networks (DNN) have been widely applied in modern life, including critical domains like autonomous driving, making it essential to ensure the reliability and robustness of DNN-powered systems. As an analogy to code coverage metrics for testing conventional software, researchers have proposed neuron coverage metrics and coverage-driven methods to generate DNN test cases. However, Yan et al. doubt the usefulness of existing coverage criteria in DNN testing. They show that a coverage-driven method is less effective than a gradient-based method in terms of both uncovering defects and improving model robustness. In this paper, we conduct a replication study of the work by Yan et al. and extend the experiments for deeper analysis. A larger model and a dataset of higher resolution images are included to examine the generalizability of the results. We also extend the experiments with more test case generation techniques and adjust the process of improving model robustness to be closer to the practical life cycle of DNN development. Our experiment results confirm the conclusion from Yan et al. that coverage-driven methods are less effective than gradient-based methods. Yan et al. find that using gradient-based methods to retrain cannot repair defects uncovered by coverage-driven methods. They attribute this to the fact that the two types of methods use different perturbation strategies: gradient-based methods perform differentiable transformations while coverage-driven methods can perform additional non-differentiable transformations. We test several hypotheses and further show that even coverage-driven methods are constrained only to perform differentiable transformations, the uncovered defects still cannot be repaired by adversarial training with gradient-based methods. Thus, defensive strategies for coverage-driven methods should be further studied.},
  keywords  = {measurement;deep learning;training;perturbation methods;neurons;neural networks;software},
  publisher = {IEEE Computer Society},
  address   = {Los Alamitos, CA, USA},
  month     = {mar}
}

@inproceedings{harel2020neuron,
  author    = {Harel-Canada, Fabrice and Wang, Lingxiao and Gulzar, Muhammad Ali and Gu, Quanquan and Kim, Miryung},
  title     = {Is Neuron Coverage a Meaningful Measure for Testing Deep Neural Networks?},
  year      = {2020},
  isbn      = {9781450370431},
  publisher = {Association for Computing Machinery},
  address   = {New York, NY, USA},
  url       = {https://doi.org/10.1145/3368089.3409754},
  doi       = {10.1145/3368089.3409754},
  abstract  = {Recent effort to test deep learning systems has produced an intuitive and compelling test criterion called neuron coverage (NC), which resembles the notion of traditional code coverage. NC measures the proportion of neurons activated in a neural network and it is implicitly assumed that increasing NC improves the quality of a test suite. In an attempt to automatically generate a test suite that increases NC, we design a novel diversity promoting regularizer that can be plugged into existing adversarial attack algorithms. We then assess whether such attempts to increase NC could generate a test suite that (1) detects adversarial attacks successfully, (2) produces natural inputs, and (3) is unbiased to particular class predictions. Contrary to expectation, our extensive evaluation finds that increasing NC actually makes it harder to generate an effective test suite: higher neuron coverage leads to fewer defects detected, less natural inputs, and more biased prediction preferences. Our results invoke skepticism that increasing neuron coverage may not be a meaningful objective for generating tests for deep neural networks and call for a new test generation technique that considers defect detection, naturalness, and output impartiality in tandem.},
  booktitle = {Proceedings of the 28th ACM Joint Meeting on European Software Engineering Conference and Symposium on the Foundations of Software Engineering},
  pages     = {851–862},
  numpages  = {12},
  keywords  = {Software Engineering, Testing, Machine Learning, Neuron Coverage, Adversarial Attack},
  location  = {Virtual Event, USA},
  series    = {ESEC/FSE 2020}
}

@inbook{nfrinbook,
  author = {Chung, L. and Leite, Julio},
  year   = {2009},
  month  = {01},
  pages  = {363-379},
  title  = {On Non-Functional Requirements in Software Engineering},
  isbn   = {978-3-642-02462-7},
  doi    = {10.1007/978-3-642-02463-4_19}
}

@inproceedings{10123554,
  author    = {J. Jia and S. Srikant and T. Mitrovska and C. Gan and S. Chang and S. Liu and U. O Reilly},
  booktitle = {2023 IEEE International Conference on Software Analysis, Evolution and Reengineering (SANER)},
  title     = {ClawSAT: Towards Both Robust and Accurate Code Models},
  year      = {2023},
  volume    = {},
  issn      = {},
  pages     = {212-223},
  keywords  = {training;analytical models;codes;systematics;robustness;adversarial machine learning;software},
  doi       = {10.1109/SANER56733.2023.00029},
  url       = {https://doi.ieeecomputersociety.org/10.1109/SANER56733.2023.00029},
  publisher = {IEEE Computer Society},
  address   = {Los Alamitos, CA, USA},
  month     = {mar}
}

@inproceedings{10.1145/3533767.3534390,
  author    = {Zeng, Zhengran and Tan, Hanzhuo and Zhang, Haotian and Li, Jing and Zhang, Yuqun and Zhang, Lingming},
  title     = {An Extensive Study on Pre-Trained Models for Program Understanding and Generation},
  year      = {2022},
  isbn      = {9781450393799},
  publisher = {Association for Computing Machinery},
  address   = {New York, NY, USA},
  url       = {https://doi.org/10.1145/3533767.3534390},
  doi       = {10.1145/3533767.3534390},
  abstract  = {Automatic program understanding and generation techniques could significantly advance the productivity of programmers and have been widely studied by academia and industry. Recently, the advent of pre-trained paradigm enlightens researchers to develop general-purpose pre-trained models which can be applied for a broad range of program understanding and generation tasks. Such pre-trained models, derived by self-supervised objectives on large unlabelled corpora, can be fine-tuned in downstream tasks (such as code search and code generation) with minimal adaptations. Although these pre-trained models claim superiority over the prior techniques, they seldom follow equivalent evaluation protocols, e.g., they are hardly evaluated on the identical benchmarks, tasks, or settings. Consequently, there is a pressing need for a comprehensive study of the pre-trained models on their effectiveness, versatility as well as the limitations to provide implications and guidance for the future development in this area. To this end, we first perform an extensive study of eight open-access pre-trained models over a large benchmark on seven representative code tasks to assess their reproducibility. We further compare the pre-trained models and domain-specific state-of-the-art techniques for validating pre-trained effectiveness. At last, we investigate the robustness of the pre-trained models by inspecting their performance variations under adversarial attacks. Through the study, we find that while we can in general replicate the original performance of the pre-trained models on their evaluated tasks and adopted benchmarks, subtle performance fluctuations can refute the findings in their original papers. Moreover, none of the existing pre-trained models can dominate over all other models. We also find that the pre-trained models can significantly outperform non-pre-trained state-of-the-art techniques in program understanding tasks. Furthermore, we perform the first study for natural language-programming language pre-trained model robustness via adversarial attacks and find that a simple random attack approach can easily fool the state-of-the-art pre-trained models and thus incur security issues. At last, we also provide multiple practical guidelines for advancing future research on pre-trained models for program understanding and generation.},
  booktitle = {Proceedings of the 31st ACM SIGSOFT International Symposium on Software Testing and Analysis},
  pages     = {39–51},
  numpages  = {13},
  keywords  = {Adversarial Attack, Code Representation, Pre-Trained Language Models, Deep Learning},
  location  = {Virtual, South Korea},
  series    = {ISSTA 2022}
}

@inproceedings{rl_coverage,
  author    = {Trujillo, Miller and Linares-V\'{a}squez, Mario and Escobar-Vel\'{a}squez, Camilo and Dusparic, Ivana and Cardozo, Nicol\'{a}s},
  title     = {Does Neuron Coverage Matter for Deep Reinforcement Learning? A Preliminary Study},
  year      = {2020},
  isbn      = {9781450379632},
  publisher = {Association for Computing Machinery},
  address   = {New York, NY, USA},
  url       = {https://doi.org/10.1145/3387940.3391462},
  doi       = {10.1145/3387940.3391462},
  abstract  = {Deep Learning (DL) is powerful family of algorithms used for a wide variety of problems and systems, including safety critical systems. As a consequence, analyzing, understanding, and testing DL models is attracting more practitioners and researchers with the purpose of implementing DL systems that are robust, reliable, efficient, and accurate. First software testing approaches for DL systems have focused on black-box testing, white-box testing, and test cases generation, in particular for deep neural networks (CNNs and RNNs). However, Deep Reinforcement Learning (DRL), which is a branch of DL extending reinforcement learning, is still out of the scope of research providing testing techniques for DL systems. In this paper, we present a first step towards testing of DRL systems. In particular, we investigate whether neuron coverage (a widely used metric for white-box testing of DNNs) could be used also for DRL systems, by analyzing coverage evolutionary patterns, and the correlation with RL rewards.},
  booktitle = {Proceedings of the IEEE/ACM 42nd International Conference on Software Engineering Workshops},
  pages     = {215–220},
  numpages  = {6},
  keywords  = {Coverage analysis, Testing, Reinforcement learning, Deep networks},
  location  = {Seoul, Republic of Korea},
  series    = {ICSEW'20}
}

@misc{catchme,
  doi       = {10.48550/ARXIV.2112.01821},
  url       = {https://arxiv.org/abs/2112.01821},
  author    = {Wu, Xiaoliang and Rajan, Ajitha},
  keywords  = {Sound (cs.SD), Computation and Language (cs.CL), Software Engineering (cs.SE), Audio and Speech Processing (eess.AS), FOS: Computer and information sciences, FOS: Computer and information sciences, FOS: Electrical engineering, electronic engineering, information engineering, FOS: Electrical engineering, electronic engineering, information engineering},
  title     = {Catch Me If You Can: Blackbox Adversarial Attacks on Automatic Speech Recognition using Frequency Masking},
  publisher = {arXiv},
  year      = {2021},
  copyright = {arXiv.org perpetual, non-exclusive license}
}


@article{survey,
  author     = {Zhang, He and Babar, Muhammad Ali and Tell, Paolo},
  title      = {Identifying Relevant Studies in Software Engineering},
  year       = {2011},
  issue_date = {June, 2011},
  publisher  = {Butterworth-Heinemann},
  address    = {USA},
  volume     = {53},
  number     = {6},
  issn       = {0950-5849},
  url        = {https://doi.org/10.1016/j.infsof.2010.12.010},
  doi        = {10.1016/j.infsof.2010.12.010},
  abstract   = {Context: Systematic literature review (SLR) has become an important research methodology in software engineering since the introduction of evidence-based software engineering (EBSE) in 2004. One critical step in applying this methodology is to design and execute appropriate and effective search strategy. This is a time-consuming and error-prone step, which needs to be carefully planned and implemented. There is an apparent need for a systematic approach to designing, executing, and evaluating a suitable search strategy for optimally retrieving the target literature from digital libraries. Objective: The main objective of the research reported in this paper is to improve the search step of undertaking SLRs in software engineering (SE) by devising and evaluating systematic and practical approaches to identifying relevant studies in SE. Method: We have systematically selected and analytically studied a large number of papers (SLRs) to understand the state-of-the-practice of search strategies in EBSE. Having identified the limitations of the current ad-hoc nature of search strategies used by SE researchers for SLRs, we have devised a systematic and evidence-based approach to developing and executing optimal search strategies in SLRs. The proposed approach incorporates the concept of 'quasi-gold standard' (QGS), which consists of collection of known studies, and corresponding 'quasi-sensitivity' into the search process for evaluating search performance. Results: We conducted two participant-observer case studies to demonstrate and evaluate the adoption of the proposed QGS-based systematic search approach in support of SLRs in SE research. Conclusion: We report their findings based on the case studies that the approach is able to improve the rigor of search process in an SLR, as well as it can serve as a supplement to the guidelines for SLRs in EBSE. We plan to further evaluate the proposed approach using a series of case studies on varying research topics in SE.},
  journal    = {Inf. Softw. Technol.},
  month      = {jun},
  pages      = {625–637},
  numpages   = {13},
  keywords   = {Quasi-gold standard, Systematic literature review, Evidence-based software engineering, Search strategy}
}



@inproceedings{DeepGauge,
  author    = {Ma, Lei and Juefei-Xu, Felix and Zhang, Fuyuan and Sun, Jiyuan and Xue, Minhui and Li, Bo and Chen, Chunyang and Su, Ting and Li, Li and Liu, Yang and Zhao, Jianjun and Wang, Yadong},
  title     = {DeepGauge: Multi-Granularity Testing Criteria for Deep Learning Systems},
  year      = {2018},
  isbn      = {9781450359375},
  publisher = {Association for Computing Machinery},
  address   = {New York, NY, USA},
  url       = {https://doi.org/10.1145/3238147.3238202},
  doi       = {10.1145/3238147.3238202},
  abstract  = {Deep learning (DL) defines a new data-driven programming paradigm that constructs the internal system logic of a crafted neuron network through a set of training data. We have seen wide adoption of DL in many safety-critical scenarios. However, a plethora of studies have shown that the state-of-the-art DL systems suffer from various vulnerabilities which can lead to severe consequences when applied to real-world applications. Currently, the testing adequacy of a DL system is usually measured by the accuracy of test data. Considering the limitation of accessible high quality test data, good accuracy performance on test data can hardly provide confidence to the testing adequacy and generality of DL systems. Unlike traditional software systems that have clear and controllable logic and functionality, the lack of interpretability in a DL system makes system analysis and defect detection difficult, which could potentially hinder its real-world deployment. In this paper, we propose DeepGauge, a set of multi-granularity testing criteria for DL systems, which aims at rendering a multi-faceted portrayal of the testbed. The in-depth evaluation of our proposed testing criteria is demonstrated on two well-known datasets, five DL systems, and with four state-of-the-art adversarial attack techniques against DL. The potential usefulness of DeepGauge sheds light on the construction of more generic and robust DL systems.},
  booktitle = {Proceedings of the 33rd ACM/IEEE International Conference on Automated Software Engineering},
  pages     = {120–131},
  numpages  = {12},
  keywords  = {Testing criteria, Deep learning, Deep neural networks, Software testing},
  location  = {Montpellier, France},
  series    = {ASE 2018}
}
@inproceedings{DeepTest,
  author    = {Tian, Yuchi and Pei, Kexin and Jana, Suman and Ray, Baishakhi},
  title     = {DeepTest: Automated Testing of Deep-Neural-Network-Driven Autonomous Cars},
  year      = {2018},
  isbn      = {9781450356381},
  publisher = {Association for Computing Machinery},
  address   = {New York, NY, USA},
  url       = {https://doi.org/10.1145/3180155.3180220},
  doi       = {10.1145/3180155.3180220},
  abstract  = {Recent advances in Deep Neural Networks (DNNs) have led to the development of DNN-driven autonomous cars that, using sensors like camera, LiDAR, etc., can drive without any human intervention. Most major manufacturers including Tesla, GM, Ford, BMW, and Waymo/Google are working on building and testing different types of autonomous vehicles. The lawmakers of several US states including California, Texas, and New York have passed new legislation to fast-track the process of testing and deployment of autonomous vehicles on their roads.However, despite their spectacular progress, DNNs, just like traditional software, often demonstrate incorrect or unexpected corner-case behaviors that can lead to potentially fatal collisions. Several such real-world accidents involving autonomous cars have already happened including one which resulted in a fatality. Most existing testing techniques for DNN-driven vehicles are heavily dependent on the manual collection of test data under different driving conditions which become prohibitively expensive as the number of test conditions increases.In this paper, we design, implement, and evaluate DeepTest, a systematic testing tool for automatically detecting erroneous behaviors of DNN-driven vehicles that can potentially lead to fatal crashes. First, our tool is designed to automatically generated test cases leveraging real-world changes in driving conditions like rain, fog, lighting conditions, etc. DeepTest systematically explore different parts of the DNN logic by generating test inputs that maximize the numbers of activated neurons. DeepTest found thousands of erroneous behaviors under different realistic driving conditions (e.g., blurring, rain, fog, etc.) many of which lead to potentially fatal crashes in three top performing DNNs in the Udacity self-driving car challenge.},
  booktitle = {Proceedings of the 40th International Conference on Software Engineering},
  pages     = {303–314},
  numpages  = {12},
  keywords  = {neuron coverage, deep neural networks, deep learning, autonomous vehicle, testing, self-driving cars},
  location  = {Gothenburg, Sweden},
  series    = {ICSE '18}
}

@misc{niu2023empirical,
  title         = {An Empirical Comparison of Pre-Trained Models of Source Code},
  author        = {Changan Niu and Chuanyi Li and Vincent Ng and Dongxiao Chen and Jidong Ge and Bin Luo},
  year          = {2023},
  eprint        = {2302.04026},
  archiveprefix = {arXiv},
  primaryclass  = {cs.SE}
}


@inproceedings{DeepHunter,
  author    = {Xie, Xiaofei and Ma, Lei and Juefei-Xu, Felix and Xue, Minhui and Chen, Hongxu and Liu, Yang and Zhao, Jianjun and Li, Bo and Yin, Jianxiong and See, Simon},
  title     = {DeepHunter: A Coverage-Guided Fuzz Testing Framework for Deep Neural Networks},
  year      = {2019},
  isbn      = {9781450362245},
  publisher = {Association for Computing Machinery},
  address   = {New York, NY, USA},
  url       = {https://doi.org/10.1145/3293882.3330579},
  doi       = {10.1145/3293882.3330579},
  abstract  = {The past decade has seen the great potential of applying deep neural network (DNN) based software to safety-critical scenarios, such as autonomous driving. Similar to traditional software, DNNs could exhibit incorrect behaviors, caused by hidden defects, leading to severe accidents and losses. In this paper, we propose DeepHunter, a coverage-guided fuzz testing framework for detecting potential defects of general-purpose DNNs. To this end, we first propose a metamorphic mutation strategy to generate new semantically preserved tests, and leverage multiple extensible coverage criteria as feedback to guide the test generation. We further propose a seed selection strategy that combines both diversity-based and recency-based seed selection. We implement and incorporate 5 existing testing criteria and 4 seed selection strategies in DeepHunter. Large-scale experiments demonstrate that (1) our metamorphic mutation strategy is useful to generate new valid tests with the same semantics as the original seed, by up to a 98% validity ratio; (2) the diversity-based seed selection generally weighs more than recency-based seed selection in boosting the coverage and in detecting defects; (3) DeepHunter outperforms the state of the arts by coverage as well as the quantity and diversity of defects identified; (4) guided by corner-region based criteria, DeepHunter is useful to capture defects during the DNN quantization for platform migration.},
  booktitle = {Proceedings of the 28th ACM SIGSOFT International Symposium on Software Testing and Analysis},
  pages     = {146–157},
  numpages  = {12},
  keywords  = {Deep learning testing, coverage-guided fuzzing, metamorphic testing},
  location  = {Beijing, China},
  series    = {ISSTA 2019}
}



@article{DeepXplore,
  author     = {Pei, Kexin and Cao, Yinzhi and Yang, Junfeng and Jana, Suman},
  title      = {DeepXplore: Automated Whitebox Testing of Deep Learning Systems},
  year       = {2019},
  issue_date = {November 2019},
  publisher  = {Association for Computing Machinery},
  address    = {New York, NY, USA},
  volume     = {62},
  number     = {11},
  issn       = {0001-0782},
  url        = {https://doi.org/10.1145/3361566},
  doi        = {10.1145/3361566},
  abstract   = {Deep learning (DL) systems are increasingly deployed in safety- and security-critical domains such as self-driving cars and malware detection, where the correctness and predictability of a system's behavior for corner case inputs are of great importance. Existing DL testing depends heavily on manually labeled data and therefore often fails to expose erroneous behaviors for rare inputs.We design, implement, and evaluate DeepXplore, the first white-box framework for systematically testing real-world DL systems. First, we introduce neuron coverage for measuring the parts of a DL system exercised by test inputs. Next, we leverage multiple DL systems with similar functionality as cross-referencing oracles to avoid manual checking. Finally, we demonstrate how finding inputs for DL systems that both trigger many differential behaviors and achieve high neuron coverage can be represented as a joint optimization problem and solved efficiently using gradient-based search techniques.DeepXplore efficiently finds thousands of incorrect corner case behaviors (e.g., self-driving cars crashing into guard rails and malware masquerading as benign software) in state-of-the-art DL models with thousands of neurons trained on five popular datasets such as ImageNet and Udacity self-driving challenge data. For all tested DL models, on average, DeepXplore generated one test input demonstrating incorrect behavior within one second while running only on a commodity laptop. We further show that the test inputs generated by DeepXplore can also be used to retrain the corresponding DL model to improve the model's accuracy by up to 3%.},
  journal    = {Commun. ACM},
  month      = oct,
  pages      = {137–145},
  numpages   = {9}
}


@inproceedings{l2arctic,
  author    = {Guanlong {Zhao} and Sinem {Sonsaat} and Alif {Silpachai} and Ivana {Lucic} and Evgeny {Chukharev-Hudilainen} and John {Levis} and Ricardo {Gutierrez-Osuna}},
  title     = {L2-ARCTIC: A Non-native English Speech Corpus},
  year      = 2018,
  booktitle = {Proc. Interspeech},
  pages     = {2783–2787},
  doi       = {10.21437/Interspeech.2018-1110},
  url       = {http://dx.doi.org/10.21437/Interspeech.2018-1110}
}

@inproceedings{librispeech,
  author    = {Panayotov, Vassil and Chen, Guoguo and Povey, Daniel and Khudanpur, Sanjeev},
  booktitle = {2015 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)},
  title     = {Librispeech: An ASR corpus based on public domain audio books},
  year      = {2015},
  volume    = {},
  number    = {},
  pages     = {5206-5210},
  doi       = {10.1109/ICASSP.2015.7178964}
}


@inproceedings{DeepCT,
  author    = {Ma, Lei and Juefei-Xu, Felix and Xue, Minhui and Li, Bo and Li, Li and Liu, Yang and Zhao, Jianjun},
  booktitle = {2019 IEEE 26th International Conference on Software Analysis, Evolution and Reengineering (SANER)},
  title     = {DeepCT: Tomographic Combinatorial Testing for Deep Learning Systems},
  year      = {2019},
  volume    = {},
  number    = {},
  pages     = {614-618},
  abstract  = {Deep learning (DL) has achieved remarkable progress over the past decade and has been widely applied to many industry domains. However, the robustness of DL systems recently becomes great concerns, where minor perturbation on the input might cause the DL malfunction. These robustness issues could potentially result in severe consequences when a DL system is deployed to safety-critical applications and hinder the real-world deployment of DL systems. Testing techniques enable the robustness evaluation and vulnerable issue detection of a DL system at an early stage. The main challenge of testing a DL system attributes to the high dimensionality of its inputs and large internal latent feature space, which makes testing each state almost impossible. For traditional software, combinatorial testing (CT) is an effective testing technique to balance the testing exploration effort and defect detection capabilities. In this paper, we perform an exploratory study of CT on DL systems. We propose a set of combinatorial testing criteria specialized for DL systems, as well as a CT coverage guided test generation technique. Our evaluation demonstrates that CT provides a promising avenue for testing DL systems.},
  keywords  = {},
  doi       = {10.1109/SANER.2019.8668044},
  url       = {https://doi.org/10.1109/SANER.2019.8668044},
  issn      = {1534-5351},
  month     = {Feb}
}

@article{feitelson2021we,
  title   = {" We do not appreciate being experimented on": Developer and Researcher Views on the Ethics of Experiments on Open-Source Projects},
  author  = {Feitelson, Dror G},
  journal = {arXiv preprint arXiv:2112.13217},
  year    = {2021}
}

@inproceedings{zhu2021deepmemory,
  title     = {DeepMemory: Model-based Memorization Analysis of Deep Neural Language Models},
  author    = {Zhu, Derui and Chen, Jinfu and Shang, Weiyi and Zhou, Xuebing and Grossklags, Jens and Hassan, Ahmed E.},
  booktitle = {2021 36th IEEE/ACM International Conference on Automated Software Engineering (ASE)},
  pages     = {1003--1015},
  year      = {2021},
  doi       = {10.1109/ASE51524.2021.9678871},
  volume    = {},
  number    = {}
}


@inproceedings{feldman2020learning,
  title        = {Does Learning Require Memorization? A Short Tale about a Long Tail},
  author       = {Feldman, Vitaly},
  booktitle    = {Proceedings of the 52nd Annual ACM SIGACT Symposium on Theory of Computing},
  series       = {STOC 2020},
  pages        = {954--959},
  numpages     = {6},
  year         = {2020},
  organization = {Association for Computing Machinery},
  publisher    = {Association for Computing Machinery},
  address      = {New York, NY, USA},
  location     = {Chicago, IL, USA},
  keywords     = {Privacy-preserving Learning, Long-tailed Distribution, Generalization, Overfitting, Interpolation},
  isbn         = {9781450369794},
  doi          = {10.1145/3357713.3384290},
  url          = {https://doi.org/10.1145/3357713.3384290},
  abstract     = {State-of-the-art results on image recognition tasks are achieved using over-parameterized learning algorithms that (nearly) perfectly fit the training set and are known to fit well even random labels. This tendency to memorize seemingly useless training data labels is not explained by existing theoretical analyses. Memorization of the training data also presents significant privacy risks when the training data contains sensitive personal information and thus it is important to understand whether such memorization is necessary for accurate learning. We provide a simple conceptual explanation and a theoretical model demonstrating that for natural data distributions memorization of labels is necessary for achieving close-to-optimal generalization error. The model is motivated and supported by the results of several recent empirical works. In our model, data is sampled from a mixture of subpopulations and the frequencies of these subpopulations are chosen from some prior. The model allows to quantify the effect of not fitting the training data on the generalization performance of the learned classifier and demonstrates that memorization is necessary whenever frequencies are long-tailed. Image and text data are known to follow such distributions and therefore our results establish a formal link between these empirical phenomena. Our results also have concrete implications for the cost of ensuring differential privacy in learning.}
}


@inproceedings{zheng-jiang-2022-empirical,
  title     = {An Empirical Study of Memorization in {NLP}},
  author    = {Zheng, Xiaosen  and
               Jiang, Jing},
  booktitle = {Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)},
  month     = may,
  year      = {2022},
  address   = {Dublin, Ireland},
  publisher = {Association for Computational Linguistics},
  url       = {https://aclanthology.org/2022.acl-long.434},
  doi       = {10.18653/v1/2022.acl-long.434},
  pages     = {6265--6278},
  abstract  = {A recent study by Feldman (2020) proposed a long-tail theory to explain the memorization behavior of deep learning models. However, memorization has not been empirically verified in the context of NLP, a gap addressed by this work. In this paper, we use three different NLP tasks to check if the long-tail theory holds. Our experiments demonstrate that top-ranked memorized training instances are likely atypical, and removing the top-memorized training instances leads to a more serious drop in test accuracy compared with removing training instances randomly. Furthermore, we develop an attribution method to better understand why a training instance is memorized. We empirically show that our memorization attribution method is faithful, and share our interesting finding that the top-memorized parts of a training instance tend to be features negatively correlated with the class label.}
}

@software{gpt-neo,
  author    = {Black, Sid and
               Gao, Leo and
               Wang, Phil and
               Leahy, Connor and
               Biderman, Stella},
  title     = {{GPT-Neo: Large Scale Autoregressive Language 
               Modeling with Mesh-Tensorflow}},
  month     = mar,
  year      = 2021,
  note      = {{If you use this software, please cite it using 
               these metadata.}},
  publisher = {Zenodo},
  version   = {1.0},
  doi       = {10.5281/zenodo.5297715},
  url       = {https://doi.org/10.5281/zenodo.5297715}
}


@article{bengio2015scheduled,
  title   = {Scheduled sampling for sequence prediction with recurrent neural networks},
  author  = {Bengio, Samy and Vinyals, Oriol and Jaitly, Navdeep and Shazeer, Noam},
  journal = {Advances in neural information processing systems},
  volume  = {28},
  year    = {2015}
}

@inproceedings{8429311,
  author    = {Yeom, Samuel and Giacomelli, Irene and Fredrikson, Matt and Jha, Somesh},
  booktitle = {2018 IEEE 31st Computer Security Foundations Symposium (CSF)},
  title     = {Privacy Risk in Machine Learning: Analyzing the Connection to Overfitting},
  year      = {2018},
  volume    = {},
  number    = {},
  pages     = {268-282},
  doi       = {10.1109/CSF.2018.00027}
}



@article{sedgwick2012multiple,
  title     = {Multiple significance tests: the Bonferroni correction},
  author    = {Sedgwick, Philip},
  journal   = {Bmj},
  volume    = {344},
  year      = {2012},
  publisher = {British Medical Journal Publishing Group}
}

@inproceedings{hu2021lora,
  title     = {Lo{RA}: Low-Rank Adaptation of Large Language Models},
  author    = {Edward J Hu and yelong shen and Phillip Wallis and Zeyuan Allen-Zhu and Yuanzhi Li and Shean Wang and Lu Wang and Weizhu Chen},
  booktitle = {International Conference on Learning Representations},
  year      = {2022},
  url       = {https://openreview.net/forum?id=nZeVKeeFYf9}
}


@book{toothaker1993multiple,
  title     = {Multiple comparison procedures},
  author    = {Toothaker, Larry E},
  number    = {89},
  year      = {1993},
  publisher = {Sage}
}

@inproceedings{compressor,
  author    = {Shi, Jieke and Yang, Zhou and Xu, Bowen and Kang, Hong Jin and Lo, David},
  title     = {Compressing Pre-Trained Models of Code into 3 MB},
  year      = {2023},
  isbn      = {9781450394758},
  publisher = {Association for Computing Machinery},
  address   = {New York, NY, USA},
  url       = {https://doi.org/10.1145/3551349.3556964},
  doi       = {10.1145/3551349.3556964},
  articleno = {24},
  numpages  = {12},
  keywords  = {Pre-Trained Models, Model Compression, Genetic Algorithm},
  location  = {Rochester, MI, USA},
  series    = {ASE '22}
}

@inproceedings{gan-leak,
  author    = {Chen, Dingfan and Yu, Ning and Zhang, Yang and Fritz, Mario},
  title     = {GAN-Leaks: A Taxonomy of Membership Inference Attacks against Generative Models},
  year      = {2020},
  isbn      = {9781450370899},
  publisher = {Association for Computing Machinery},
  address   = {New York, NY, USA},
  url       = {https://doi.org/10.1145/3372297.3417238},
  doi       = {10.1145/3372297.3417238},
  abstract  = {Deep learning has achieved overwhelming success, spanning from discriminative models to generative models. In particular, deep generative models have facilitated a new level of performance in a myriad of areas, ranging from media manipulation to sanitized dataset generation. Despite the great success, the potential risks of privacy breach caused by generative models have not been analyzed systematically. In this paper, we focus on membership inference attack against deep generative models that reveals information about the training data used for victim models. Specifically, we present the first taxonomy of membership inference attacks, encompassing not only existing attacks but also our novel ones. In addition, we propose the first generic attack model that can be instantiated in a large range of settings and is applicable to various kinds of deep generative models. Moreover, we provide a theoretically grounded attack calibration technique, which consistently boosts the attack performance in all cases, across different attack settings, data modalities, and training configurations. We complement the systematic analysis of attack performance by a comprehensive experimental study, that investigates the effectiveness of various attacks w.r.t. model type and training configurations, over three diverse application scenarios (i.e., images, medical data, and location data).},
  booktitle = {Proceedings of the 2020 ACM SIGSAC Conference on Computer and Communications Security},
  pages     = {343–362},
  numpages  = {20},
  keywords  = {privacy-preserving, machine learning, deep learning, membership inference attacks, generative models},
  location  = {Virtual Event, USA},
  series    = {CCS '20}
}

@article{krishna2019thieves,
  title   = {Thieves on sesame street! model extraction of bert-based apis},
  author  = {Krishna, Kalpesh and Tomar, Gaurav Singh and Parikh, Ankur P and Papernot, Nicolas and Iyyer, Mohit},
  journal = {arXiv preprint arXiv:1910.12366},
  year    = {2019}
}

@misc{sun2024neural,
      title={When Neural Code Completion Models Size up the Situation: Attaining Cheaper and Faster Completion through Dynamic Model Inference}, 
      author={Zhensu Sun and Xiaoning Du and Fu Song and Shangwen Wang and Li Li},
      year={2024},
      eprint={2401.09964},
      archivePrefix={arXiv},
      primaryClass={cs.SE}
}

@inproceedings{10172653,
  author    = {Sun, Zhensu and Du, Xiaoning and Song, Fu and Wang, Shangwen and Ni, Mingze and Li, Li},
  booktitle = {2023 IEEE/ACM 45th International Conference on Software Engineering: Companion Proceedings (ICSE-Companion)},
  title     = {Don't Complete It! Preventing Unhelpful Code Completion for Productive and Sustainable Neural Code Completion Systems},
  year      = {2023},
  volume    = {},
  number    = {},
  pages     = {324-325},
  doi       = {10.1109/ICSE-Companion58688.2023.00089}
}

@misc{xu2023xastnn,
  title         = {xASTNN: Improved Code Representations for Industrial Practice},
  author        = {Zhiwei Xu and Min Zhou and Xibin Zhao and Yang Chen and Xi Cheng and Hongyu Zhang},
  year          = {2023},
  eprint        = {2303.07104},
  archiveprefix = {arXiv},
  primaryclass  = {cs.SE}
}

@article{10.1145/3501261,
  author     = {Hellendoorn, Vincent J. and Sawant, Anand Ashok},
  title      = {The Growing Cost of Deep Learning for Source Code},
  year       = {2021},
  issue_date = {January 2022},
  publisher  = {Association for Computing Machinery},
  address    = {New York, NY, USA},
  volume     = {65},
  number     = {1},
  issn       = {0001-0782},
  url        = {https://doi.org/10.1145/3501261},
  doi        = {10.1145/3501261},
  abstract   = {Attempting to mitigate problems associated with the trend toward massive dataset scaling.},
  journal    = {Commun. ACM},
  month      = {dec},
  pages      = {31–33},
  numpages   = {3}
}

@misc{zhuo2024astraios,
      title={Astraios: Parameter-Efficient Instruction Tuning Code Large Language Models}, 
      author={Terry Yue Zhuo and Armel Zebaze and Nitchakarn Suppattarachai and Leandro von Werra and Harm de Vries and Qian Liu and Niklas Muennighoff},
      year={2024},
      eprint={2401.00788},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}

@inproceedings{10.1145/3540250.3558959,
  author    = {Zlotchevski, Andrei and Drain, Dawn and Svyatkovskiy, Alexey and Clement, Colin B. and Sundaresan, Neel and Tufano, Michele},
  title     = {Exploring and Evaluating Personalized Models for Code Generation},
  year      = {2022},
  isbn      = {9781450394130},
  publisher = {Association for Computing Machinery},
  address   = {New York, NY, USA},
  url       = {https://doi.org/10.1145/3540250.3558959},
  doi       = {10.1145/3540250.3558959},
  abstract  = {Large Transformer models achieved the state-of-the-art status for Natural Language Understanding tasks and are increasingly becoming the baseline model architecture for modeling source code. Transformers are usually pre-trained on large unsupervised corpora, learning token representations and transformations relevant to modeling generally available text, and are then fine-tuned on a particular downstream task of interest. While fine-tuning is a tried-and-true method for adapting a model to a new domain -- for example, question-answering on a given topic -- generalization remains an on-going challenge. In this paper, we explore and evaluate transformer model fine-tuning for personalization. In the context of generating unit tests for Java methods, we evaluate learning to personalize to a specific software project using several personalization techniques. We consider three key approaches: (i) custom fine-tuning, which allows all the model parameters to be tuned; (ii) lightweight fine-tuning, which freezes most of the model's parameters, allowing tuning of the token embeddings and softmax layer only or the final layer alone; (iii) prefix tuning, which keeps model parameters frozen, but optimizes a small project-specific prefix vector. Each of these techniques offers a trade-off in total compute cost and predictive performance, which we evaluate by code and task-specific metrics, training time, and total computational operations. We compare these fine-tuning strategies for code generation and discuss the potential generalization and cost benefits of each in various deployment scenarios.},
  booktitle = {Proceedings of the 30th ACM Joint European Software Engineering Conference and Symposium on the Foundations of Software Engineering},
  pages     = {1500–1508},
  numpages  = {9},
  keywords  = {Code Generation, Personalized Models},
  location  = {Singapore, Singapore},
  series    = {ESEC/FSE 2022}
}

@article{avatar,
  title   = {Smaller, Faster, Greener: Compressing Pre-trained Code Models via Surrogate-Assisted Optimization},
  author  = {Shi, Jieke and Yang, Zhou and Kang, Hong Jin and Xu, Bowen and He, Junda and Lo, David},
  journal = {arXiv preprint arXiv:2309.04076},
  year    = {2023}
}

@inproceedings{Zhang2022diet,
  author    = {Zhang, Zhaowei and Zhang, Hongyu and Shen, Beijun and Gu, Xiaodong},
  title     = {Diet Code is Healthy: Simplifying Programs for Pre-Trained Models of Code},
  year      = {2022},
  isbn      = {9781450394130},
  publisher = {Association for Computing Machinery},
  address   = {New York, NY, USA},
  url       = {https://doi.org/10.1145/3540250.3549094},
  doi       = {10.1145/3540250.3549094},
  abstract  = {Pre-trained code representation models such as CodeBERT have demonstrated superior performance in a variety of software engineering tasks, yet they are often heavy in complexity, quadratically with the length of the input sequence. Our empirical analysis of CodeBERT's attention reveals that CodeBERT pays more attention to certain types of tokens and statements such as keywords and data-relevant statements. Based on these findings, we propose DietCode, which aims at lightweight leverage of large pre-trained models for source code. DietCode simplifies the input program of CodeBERT with three strategies, namely, word dropout, frequency filtering, and an attention-based strategy that selects statements and tokens that receive the most attention weights during pre-training. Hence, it gives a substantial reduction in the computational cost without hampering the model performance. Experimental results on two downstream tasks show that DietCode provides comparable results to CodeBERT with 40\% less computational cost in fine-tuning and testing.},
  booktitle = {Proceedings of the 30th ACM Joint European Software Engineering Conference and Symposium on the Foundations of Software Engineering},
  pages     = {1073–1084},
  numpages  = {12},
  keywords  = {Program simplification, Learning program representations, Pre-trained models, Code intelligence},
  location  = {Singapore, Singapore},
  series    = {ESEC/FSE 2022}
}

@inproceedings{steal-rl,
  author    = {Chen, Kangjie and Guo, Shangwei and Zhang, Tianwei and Xie, Xiaofei and Liu, Yang},
  title     = {Stealing Deep Reinforcement Learning Models for Fun and Profit},
  year      = {2021},
  isbn      = {9781450382878},
  publisher = {Association for Computing Machinery},
  address   = {New York, NY, USA},
  url       = {https://doi.org/10.1145/3433210.3453090},
  doi       = {10.1145/3433210.3453090},
  abstract  = {This paper presents the first model extraction attack against Deep Reinforcement Learning (DRL), which enables an external adversary to precisely recover a black-box DRL model only from its interaction with the environment. Model extraction attacks against supervised Deep Learning models have been widely studied. However, those techniques cannot be applied to the reinforcement learning scenario due to DRL models' high complexity, stochasticity and limited observable information. We propose a novel methodology to overcome the above challenges. The key insight of our approach is that the process of DRL model extraction is equivalent to imitation learning, a well-established solution to learn sequential decision-making policies. Based on this observation, our methodology first builds a classifier to reveal the training algorithm family of the targeted black-box DRL model only based on its predicted actions, and then leverages state-of-the-art imitation learning techniques to replicate the model from the identified algorithm family. Experimental results indicate that our methodology can effectively recover the DRL models with high fidelity and accuracy. We also demonstrate two use cases to show that our model extraction attack can (1) significantly improve the success rate of adversarial attacks, and (2) steal DRL models stealthily even they are protected by DNN watermarks. These pose a severe threat to the intellectual property and privacy protection of DRL applications.},
  booktitle = {Proceedings of the 2021 ACM Asia Conference on Computer and Communications Security},
  pages     = {307–319},
  numpages  = {13},
  keywords  = {deep reinforcement learning, model extraction, imitation learning},
  location  = {Virtual Event, Hong Kong},
  series    = {ASIA CCS '21}
}

@inproceedings{7958568,
  author    = {Shokri, Reza and Stronati, Marco and Song, Congzheng and Shmatikov, Vitaly},
  booktitle = {2017 IEEE Symposium on Security and Privacy (SP)},
  title     = {Membership Inference Attacks Against Machine Learning Models},
  year      = {2017},
  volume    = {},
  number    = {},
  pages     = {3-18},
  doi       = {10.1109/SP.2017.41}
}


@inproceedings{duplicate-code,
  author    = {Allamanis, Miltiadis},
  title     = {The Adverse Effects of Code Duplication in Machine Learning Models of Code},
  year      = {2019},
  isbn      = {9781450369954},
  publisher = {Association for Computing Machinery},
  address   = {New York, NY, USA},
  url       = {https://doi.org/10.1145/3359591.3359735},
  doi       = {10.1145/3359591.3359735},
  abstract  = {The field of big code relies on mining large corpora of code to perform some learning task towards creating better tools for software engineers. A significant threat to this approach was recently identified by Lopes et al. (2017) who found a large amount of near-duplicate code on GitHub. However, the impact of code duplication has not been noticed by researchers devising machine learning models for source code. In this work, we explore the effects of code duplication on machine learning models showing that reported performance metrics are sometimes inflated by up to 100\% when testing on duplicated code corpora compared to the performance on de-duplicated corpora which more accurately represent how machine learning models of code are used by software engineers. We present a duplication index for widely used datasets, list best practices for collecting code corpora and evaluating machine learning models on them. Finally, we release tools to help the community avoid this problem in future research.},
  booktitle = {Proceedings of the 2019 ACM SIGPLAN International Symposium on New Ideas, New Paradigms, and Reflections on Programming and Software},
  pages     = {143–153},
  numpages  = {11},
  keywords  = {big code, machine learning, duplication, dataset collection, code naturalness},
  location  = {Athens, Greece},
  series    = {Onward! 2019}
}

@inproceedings{beam-search,
  title     = {Beam Search Strategies for Neural Machine Translation},
  author    = {Freitag, Markus  and
               Al-Onaizan, Yaser},
  booktitle = {Proceedings of the First Workshop on Neural Machine Translation},
  month     = aug,
  year      = {2017},
  address   = {Vancouver},
  publisher = {Association for Computational Linguistics},
  url       = {https://aclanthology.org/W17-3207},
  doi       = {10.18653/v1/W17-3207},
  pages     = {56--60},
  abstract  = {The basic concept in Neural Machine Translation (NMT) is to train a large Neural Network that maximizes the translation performance on a given parallel corpus. NMT is then using a simple left-to-right beam-search decoder to generate new translations that approximately maximize the trained conditional probability. The current beam search strategy generates the target sentence word by word from left-to-right while keeping a fixed amount of active candidates at each time step. First, this simple search is less adaptive as it also expands candidates whose scores are much worse than the current best. Secondly, it does not expand hypotheses if they are not within the best scoring candidates, even if their scores are close to the best one. The latter one can be avoided by increasing the beam size until no performance improvement can be observed. While you can reach better performance, this has the drawback of a slower decoding speed. In this paper, we concentrate on speeding up the decoder by applying a more flexible beam search strategy whose candidate size may vary at each time step depending on the candidate scores. We speed up the original decoder by up to 43{\%} for the two language pairs German to English and Chinese to English without losing any translation quality.}
}

@misc{AWSCodeWhisperer,
  title        = {AWS CodeWhisperer: Features},
  howpublished = {\url{https://aws.amazon.com/codewhisperer/features/}},
  note         = {Accessed: March 29, 2023}
}


@misc{tree-sitter,
  author       = {The Tree-sitter Contributors},
  title        = {{Tree-sitter}: {A}n {A} incremental parsing library},
  howpublished = {\url{https://tree-sitter.github.io/tree-sitter/}},
  year         = {Accessed on 25th March, 2023}
}

@inproceedings{basak2023secretbench,
  title     = {SecretBench: A Dataset of Software Secrets},
  author    = {Setu Kumar Basak and Lorenzo Neil and Bradley Reaves and Laurie Williams},
  year      = {2023},
  title     = {NICHE: A Curated Dataset of Engineered Machine Learning Projects in Python},
  booktitle = {Proceedings of the 20th International Conference on Mining Software Repositories},
  numpages  = {5},
  series    = {MSR '23}
}

@inproceedings{9609166,
  author    = {Zhou, Xin and Han, DongGyun and Lo, David},
  booktitle = {2021 IEEE International Conference on Software Maintenance and Evolution (ICSME)},
  title     = {Assessing Generalizability of CodeBERT},
  year      = {2021},
  volume    = {},
  number    = {},
  pages     = {425-436},
  doi       = {10.1109/ICSME52107.2021.00044}
}


@inproceedings{10.5555/3241094.3241142,
  author    = {Tram\`{e}r, Florian and Zhang, Fan and Juels, Ari and Reiter, Michael K. and Ristenpart, Thomas},
  title     = {Stealing Machine Learning Models via Prediction APIs},
  year      = {2016},
  isbn      = {9781931971324},
  publisher = {USENIX Association},
  address   = {USA},
  abstract  = {Machine learning (ML) models may be deemed confidential due to their sensitive training data, commercial value, or use in security applications. Increasingly often, confidential ML models are being deployed with publicly accessible query interfaces. ML-as-a-service ("predictive analytics") systems are an example: Some allow users to train models on potentially sensitive data and charge others for access on a pay-per-query basis.The tension between model confidentiality and public access motivates our investigation of model extraction attacks. In such attacks, an adversary with black-box access, but no prior knowledge of an ML model's parameters or training data, aims to duplicate the functionality of (i.e., "steal") the model. Unlike in classical learning theory settings, ML-as-a-service offerings may accept partial feature vectors as inputs and include confidence values with predictions. Given these practices, we show simple, efficient attacks that extract target ML models with near-perfect fidelity for popular model classes including logistic regression, neural networks, and decision trees. We demonstrate these attacks against the online services of BigML and Amazon Machine Learning. We further show that the natural countermeasure of omitting confidence values from model outputs still admits potentially harmful model extraction attacks. Our results highlight the need for careful ML model deployment and new model extraction countermeasures.},
  booktitle = {Proceedings of the 25th USENIX Conference on Security Symposium},
  pages     = {601–618},
  numpages  = {18},
  location  = {Austin, TX, USA},
  series    = {SEC'16}
}

@article{chelba2013one,
  title   = {One billion word benchmark for measuring progress in statistical language modeling},
  author  = {Chelba, Ciprian and Mikolov, Tomas and Schuster, Mike and Ge, Qi and Brants, Thorsten and Koehn, Phillipp and Robinson, Tony},
  journal = {arXiv preprint arXiv:1312.3005},
  year    = {2013}
}

@inproceedings{peters-etal-2018-deep,
  title     = {Deep Contextualized Word Representations},
  author    = {Peters, Matthew E.  and
               Neumann, Mark  and
               Iyyer, Mohit  and
               Gardner, Matt  and
               Clark, Christopher  and
               Lee, Kenton  and
               Zettlemoyer, Luke},
  booktitle = {Proceedings of the 2018 Conference of the North {A}merican Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 1 (Long Papers)},
  month     = jun,
  year      = {2018},
  address   = {New Orleans, Louisiana},
  publisher = {Association for Computational Linguistics},
  url       = {https://aclanthology.org/N18-1202},
  doi       = {10.18653/v1/N18-1202},
  pages     = {2227--2237},
  abstract  = {We introduce a new type of deep contextualized word representation that models both (1) complex characteristics of word use (e.g., syntax and semantics), and (2) how these uses vary across linguistic contexts (i.e., to model polysemy). Our word vectors are learned functions of the internal states of a deep bidirectional language model (biLM), which is pre-trained on a large text corpus. We show that these representations can be easily added to existing models and significantly improve the state of the art across six challenging NLP problems, including question answering, textual entailment and sentiment analysis. We also present an analysis showing that exposing the deep internals of the pre-trained network is crucial, allowing downstream models to mix different types of semi-supervision signals.}
}

@inproceedings{assessingcode2vec,
  author    = {Kang, Hong Jin and Bissyand\'{e}, Tegawend\'{e} F. and Lo, David},
  title     = {Assessing the Generalizability of Code2vec Token Embeddings},
  year      = {2020},
  isbn      = {9781728125084},
  publisher = {IEEE Press},
  url       = {https://doi.org/10.1109/ASE.2019.00011},
  doi       = {10.1109/ASE.2019.00011},
  abstract  = {Many Natural Language Processing (NLP) tasks, such as sentiment analysis or syntactic parsing, have benefited from the development of word embedding models. In particular, regardless of the training algorithms, the learned embeddings have often been shown to be generalizable to different NLP tasks. In contrast, despite recent momentum on word embeddings for source code, the literature lacks evidence of their generalizability beyond the example task they have been trained for.In this experience paper, we identify 3 potential downstream tasks, namely code comments generation, code authorship identification, and code clones detection, that source code token embedding models can be applied to. We empirically assess a recently proposed code token embedding model, namely code2vec's token embeddings. Code2vec was trained on the task of predicting method names, and while there is potential for using the vectors it learns on other tasks, it has not been explored in literature. Therefore, we fill this gap by focusing on its generalizability for the tasks we have identified. Eventually, we show that source code token embeddings cannot be readily leveraged for the downstream tasks. Our experiments even show that our attempts to use them do not result in any improvements over less sophisticated methods. We call for more research into effective and general use of code embeddings.},
  booktitle = {Proceedings of the 34th IEEE/ACM International Conference on Automated Software Engineering},
  pages     = {1–12},
  numpages  = {12},
  keywords  = {big code, code embeddings, distributed representations},
  location  = {San Diego, California},
  series    = {ASE '19}
}

@inproceedings{8260656,
  author    = {Hosseini, Hossein and Xiao, Baicen and Jaiswal, Mayoore and Poovendran, Radha},
  booktitle = {2017 16th IEEE International Conference on Machine Learning and Applications (ICMLA)},
  title     = {On the Limitation of Convolutional Neural Networks in Recognizing Negative Images},
  year      = {2017},
  volume    = {},
  number    = {},
  pages     = {352-358},
  doi       = {10.1109/ICMLA.2017.0-136}
}

@inproceedings{DeepCom,
  author    = {Hu, Xing and Li, Ge and Xia, Xin and Lo, David and Jin, Zhi},
  title     = {Deep Code Comment Generation},
  year      = {2018},
  isbn      = {9781450357142},
  publisher = {Association for Computing Machinery},
  address   = {New York, NY, USA},
  url       = {https://doi.org/10.1145/3196321.3196334},
  doi       = {10.1145/3196321.3196334},
  abstract  = {During software maintenance, code comments help developers comprehend programs and reduce additional time spent on reading and navigating source code. Unfortunately, these comments are often mismatched, missing or outdated in the software projects. Developers have to infer the functionality from the source code. This paper proposes a new approach named DeepCom to automatically generate code comments for Java methods. The generated comments aim to help developers understand the functionality of Java methods. DeepCom applies Natural Language Processing (NLP) techniques to learn from a large code corpus and generates comments from learned features. We use a deep neural network that analyzes structural information of Java methods for better comments generation. We conduct experiments on a large-scale Java corpus built from 9,714 open source projects from GitHub. We evaluate the experimental results on a machine translation metric. Experimental results demonstrate that our method DeepCom outperforms the state-of-the-art by a substantial margin.},
  booktitle = {Proceedings of the 26th Conference on Program Comprehension},
  pages     = {200–210},
  numpages  = {11},
  keywords  = {program comprehension, comment generation, deep learning},
  location  = {Gothenburg, Sweden},
  series    = {ICPC '18}
}

@article{10.1145/3501256,
  author     = {Zhou, Yu and Zhang, Xiaoqing and Shen, Juanjuan and Han, Tingting and Chen, Taolue and Gall, Harald},
  title      = {Adversarial Robustness of Deep Code Comment Generation},
  year       = {2022},
  issue_date = {October 2022},
  publisher  = {Association for Computing Machinery},
  address    = {New York, NY, USA},
  volume     = {31},
  number     = {4},
  issn       = {1049-331X},
  url        = {https://doi.org/10.1145/3501256},
  doi        = {10.1145/3501256},
  abstract   = {Deep neural networks (DNNs) have shown remarkable performance in a variety of domains such as computer vision, speech recognition, and natural language processing. Recently they also have been applied to various software engineering tasks, typically involving processing source code. DNNs are well-known to be vulnerable to adversarial examples, i.e., fabricated inputs that could lead to various misbehaviors of the DNN model while being perceived as benign by humans. In this paper, we focus on the code comment generation task in software engineering and study the robustness issue of the DNNs when they are applied to this task. We propose ACCENT(Adversarial Code Comment gENeraTor), an identifier substitution approach to craft adversarial code snippets, which are syntactically correct and semantically close to the original code snippet, but may mislead the DNNs to produce completely irrelevant code comments. In order to improve the robustness, ACCENT also incorporates a novel training method, which can be applied to existing code comment generation models. We conduct comprehensive experiments to evaluate our approach by attacking the mainstream encoder-decoder architectures on two large-scale publicly available datasets. The results show that ACCENT efficiently produces stable attacks with functionality-preserving adversarial examples, and the generated examples have better transferability compared with the baselines. We also confirm, via experiments, the effectiveness in improving model robustness with our training method.},
  journal    = {ACM Trans. Softw. Eng. Methodol.},
  month      = {jul},
  articleno  = {60},
  numpages   = {30},
  keywords   = {deep learning, robustness, Code comment generation, adversarial attack}
}

@misc{codellama,
  author = {Meta},
  title  = {Code Llama},
  url    = {https://ai.meta.com/blog/code-llama-large-language-model-coding/}
} 

@misc{tabnineweb,
  author = {Tabnine},
  title  = {AI assistant that speeds up delivery
            and keeps your code safe},
  url    = {https://www.tabnine.com}
} 

@misc{CodeGeeXweb,
  author = {CodeGeeX },
  title  = {CodeGeeX},
  url    = {https://codegeex.cn}
} 

@misc{overflowAIweb,
  author = {Stack Overflow},
  title  = {Announcing OverflowAI},
  url    = {https://stackoverflow.blog/2023/07/27/announcing-overflowai/}
} 

@inproceedings{brockschmidt2018generative,
  title     = {Generative Code Modeling with Graphs},
  author    = {Marc Brockschmidt and Miltiadis Allamanis and Alexander L. Gaunt and Oleksandr Polozov},
  booktitle = {International Conference on Learning Representations},
  year      = {2019},
  url       = {https://openreview.net/forum?id=Bke4KsA5FX}
}

@inproceedings{allamanis2018learning,
  title     = {Learning to Represent Programs with Graphs},
  author    = {Miltiadis Allamanis and Marc Brockschmidt and Mahmoud Khademi},
  booktitle = {International Conference on Learning Representations},
  year      = {2018},
  url       = {https://openreview.net/forum?id=BJOFETxR-}
}

@article{code2vec,
  author     = {Alon, Uri and Zilberstein, Meital and Levy, Omer and Yahav, Eran},
  title      = {Code2vec: Learning Distributed Representations of Code},
  year       = {2019},
  issue_date = {January 2019},
  publisher  = {Association for Computing Machinery},
  address    = {New York, NY, USA},
  volume     = {3},
  number     = {POPL},
  url        = {https://doi.org/10.1145/3290353},
  doi        = {10.1145/3290353},
  abstract   = {We present a neural model for representing snippets of code as continuous distributed vectors (``code embeddings''). The main idea is to represent a code snippet as a single fixed-length code vector, which can be used to predict semantic properties of the snippet. To this end, code is first decomposed to a collection of paths in its abstract syntax tree. Then, the network learns the atomic representation of each path while simultaneously learning how to aggregate a set of them. We demonstrate the effectiveness of our approach by using it to predict a method's name from the vector representation of its body. We evaluate our approach by training a model on a dataset of 12M methods. We show that code vectors trained on this dataset can predict method names from files that were unobserved during training. Furthermore, we show that our model learns useful method name vectors that capture semantic similarities, combinations, and analogies. A comparison of our approach to previous techniques over the same dataset shows an improvement of more than 75\%, making it the first to successfully predict method names based on a large, cross-project corpus. Our trained model, visualizations and vector similarities are available as an interactive online demo at http://code2vec.org. The code, data and trained models are available at https://github.com/tech-srl/code2vec.},
  journal    = {Proc. ACM Program. Lang.},
  month      = jan,
  articleno  = {40},
  numpages   = {29},
  keywords   = {Distributed Representations, Machine Learning, Big Code}
}

@inproceedings{malhotra2019active,
  title     = {Active Learning Methods for Low Resource End-to-End Speech Recognition.},
  author    = {Malhotra, Karan and Bansal, Shubham and Ganapathy, Sriram},
  booktitle = {INTERSPEECH},
  pages     = {2215--2219},
  year      = {2019}
}

@inproceedings{4960685,
  author    = {Varadarajan, Balakrishnan and Yu, Dong and Li Deng and Acero, Alex},
  booktitle = {2009 IEEE International Conference on Acoustics, Speech and Signal Processing},
  title     = {Maximizing global entropy reduction for active learning in speech recognition},
  year      = {2009},
  volume    = {},
  number    = {},
  pages     = {4721-4724},
  doi       = {10.1109/ICASSP.2009.4960685}
}

@inproceedings{py150,
  author    = {Raychev, Veselin and Bielik, Pavol and Vechev, Martin},
  title     = {Probabilistic Model for Code with Decision Trees},
  year      = {2016},
  isbn      = {9781450344449},
  publisher = {Association for Computing Machinery},
  address   = {New York, NY, USA},
  url       = {https://doi.org/10.1145/2983990.2984041},
  doi       = {10.1145/2983990.2984041},
  abstract  = {In this paper we introduce a new approach for learning precise and general probabilistic models of code based on decision tree learning. Our approach directly benefits an emerging class of statistical programming tools which leverage probabilistic models of code learned over large codebases (e.g., GitHub) to make predictions about new programs (e.g., code completion, repair, etc). The key idea is to phrase the problem of learning a probabilistic model of code as learning a decision tree in a domain specific language over abstract syntax trees (called TGen). This allows us to condition the prediction of a program element on a dynamically computed context. Further, our problem formulation enables us to easily instantiate known decision tree learning algorithms such as ID3, but also to obtain new variants we refer to as ID3+ and E13, not previously explored and ones that outperform ID3 in prediction accuracy. Our approach is general and can be used to learn a probabilistic model of any programming language. We implemented our approach in a system called Deep3 and evaluated it for the challenging task of learning probabilistic models of JavaScript and Python. Our experimental results indicate that Deep3 predicts elements of JavaScript and Python code with precision above 82% and 69%, respectively. Further, Deep3 often significantly outperforms state-of-the-art approaches in overall prediction accuracy.},
  booktitle = {Proceedings of the 2016 ACM SIGPLAN International Conference on Object-Oriented Programming, Systems, Languages, and Applications},
  pages     = {731–747},
  numpages  = {17},
  keywords  = {Probabilistic Models of Code, Code Completion, Decision Trees},
  location  = {Amsterdam, Netherlands},
  series    = {OOPSLA 2016}
}

@misc{zlibnet,
  title        = {A Massively Spiffy Yet Delicately Unobtrusive Compression Library},
  howpublished = {\url{https://zlib.net/}},
  note         = {Accessed on March 27, 2023}
}

@article{gpt-2,
  title  = {Language Models are Unsupervised Multitask Learners},
  author = {Radford, Alec and Wu, Jeff and Child, Rewon and Luan, David and Amodei, Dario and Sutskever, Ilya},
  year   = {2019}
}

@article{10.1145/3022671.2984041,
  author     = {Raychev, Veselin and Bielik, Pavol and Vechev, Martin},
  title      = {Probabilistic Model for Code with Decision Trees},
  year       = {2016},
  issue_date = {October 2016},
  publisher  = {Association for Computing Machinery},
  address    = {New York, NY, USA},
  volume     = {51},
  number     = {10},
  issn       = {0362-1340},
  url        = {https://doi.org/10.1145/3022671.2984041},
  doi        = {10.1145/3022671.2984041},
  abstract   = {In this paper we introduce a new approach for learning precise and general probabilistic models of code based on decision tree learning. Our approach directly benefits an emerging class of statistical programming tools which leverage probabilistic models of code learned over large codebases (e.g., GitHub) to make predictions about new programs (e.g., code completion, repair, etc). The key idea is to phrase the problem of learning a probabilistic model of code as learning a decision tree in a domain specific language over abstract syntax trees (called TGen). This allows us to condition the prediction of a program element on a dynamically computed context. Further, our problem formulation enables us to easily instantiate known decision tree learning algorithms such as ID3, but also to obtain new variants we refer to as ID3+ and E13, not previously explored and ones that outperform ID3 in prediction accuracy. Our approach is general and can be used to learn a probabilistic model of any programming language. We implemented our approach in a system called Deep3 and evaluated it for the challenging task of learning probabilistic models of JavaScript and Python. Our experimental results indicate that Deep3 predicts elements of JavaScript and Python code with precision above 82% and 69%, respectively. Further, Deep3 often significantly outperforms state-of-the-art approaches in overall prediction accuracy.},
  journal    = {SIGPLAN Not.},
  month      = {oct},
  pages      = {731–747},
  numpages   = {17},
  keywords   = {Probabilistic Models of Code, Code Completion, Decision Trees}
}



@misc{wong2022exploring,
  title         = {Exploring the Verifiability of Code Generated by GitHub Copilot},
  author        = {Dakota Wong and Austin Kothig and Patrick Lam},
  year          = {2022},
  eprint        = {2209.01766},
  archiveprefix = {arXiv},
  primaryclass  = {cs.SE}
}

@misc{khoury2023secure,
  title         = {How Secure is Code Generated by ChatGPT?},
  author        = {Raphaël Khoury and Anderson R. Avila and Jacob Brunelle and Baba Mamadou Camara},
  year          = {2023},
  eprint        = {2304.09655},
  archiveprefix = {arXiv},
  primaryclass  = {cs.CR}
}

@article{daSilva2020,
  author  = {Rodrigo Fernandes Gomes da Silva and Chanchal K. Roy and Mohammad Masudur Rahman and Kevin A. Schneider and Klérisson Paixão and Carlos Eduardo de Carvalho Dantas and Marcelo de Almeida Maia},
  title   = {CROKAGE: Effective Solution Recommendation for Programming Tasks by Leveraging Crowd Knowledge},
  journal = {Empirical Software Engineering},
  volume  = {25},
  number  = {6},
  pages   = {4707--4758},
  year    = {2020},
  doi     = {10.1007/s10664-020-09863-2},
  url     = {https://doi.org/10.1007/s10664-020-09863-2}
}


@inproceedings{chatgptreadble,
  author    = {Dantas, Carlos and Rocha, Adriano and Maia, Marcelo},
  title     = {Assessing the Readability of ChatGPT Code Snippet Recommendations: A Comparative Study},
  year      = {2023},
  isbn      = {9798400707872},
  publisher = {Association for Computing Machinery},
  address   = {New York, NY, USA},
  url       = {https://doi-org.libproxy.smu.edu.sg/10.1145/3613372.3613413},
  doi       = {10.1145/3613372.3613413},
  abstract  = {Developers often rely on code search engines to find high-quality and reusable code snippets online, such as those available on Stack Overflow. Recently, ChatGPT, a language model trained for dialog tasks, has been gaining attention as a promising approach for code snippet generation. However, there is still a need for in-depth analysis of the quality of its recommendations. In this work, we propose the evaluation of the readability of code snippets generated by ChatGPT, comparing them with those recommended by CROKAGE, a state-of-the-art code search engine for Stack Overflow. We compare the recommended snippets of both approaches using readability issues raised by the automated static analysis tool (ASAT) SonarQube. Our results show that ChatGPT can generate cleaner code snippets and more consistent naming and code conventions than those written by humans and recommended by CROKAGE. However, in some cases, ChatGPT generates code that lacks recent features from Java API such as try-with-resources, lambdas, and others. Overall, our findings suggest that ChatGPT can provide valuable assistance to developers searching for didactic and high-quality code snippets online. However, it is still important for developers to review the generated code, either manually or assisted by an ASAT, to prevent potential readability issues, as the correctness of the generated code snippets.},
  booktitle = {Proceedings of the XXXVII Brazilian Symposium on Software Engineering},
  pages     = {283–292},
  numpages  = {10},
  keywords  = {readability, ChatGPT, code snippets, SonarQube, Stack Overflow},
  location  = {Campo Grande, Brazil},
  series    = {SBES '23}
}

@inproceedings{copilotreadble,
  author    = {Al Madi, Naser},
  title     = {How Readable is Model-Generated Code? Examining Readability and Visual Inspection of GitHub Copilot},
  year      = {2023},
  isbn      = {9781450394758},
  publisher = {Association for Computing Machinery},
  address   = {New York, NY, USA},
  url       = {https://doi.org/10.1145/3551349.3560438},
  doi       = {10.1145/3551349.3560438},
  abstract  = {Background: Recent advancements in large language models have motivated the practical use of such models in code generation and program synthesis. However, little is known about the effects of such tools on code readability and visual attention in practice. Objective: In this paper, we focus on GitHub Copilot to address the issues of readability and visual inspection of model generated code. Readability and low complexity are vital aspects of good source code, and visual inspection of generated code is important in light of automation bias. Method: Through a human experiment (n=21) we compare model generated code to code written completely by human programmers. We use a combination of static code analysis and human annotators to assess code readability, and we use eye tracking to assess the visual inspection of code. Results: Our results suggest that model generated code is comparable in complexity and readability to code written by human pair programmers. At the same time, eye tracking data suggests, to a statistically significant level, that programmers direct less visual attention to model generated code. Conclusion: Our findings highlight that reading code is more important than ever, and programmers should beware of complacency and automation bias with model generated code.},
  booktitle = {Proceedings of the 37th IEEE/ACM International Conference on Automated Software Engineering},
  articleno = {205},
  numpages  = {5},
  keywords  = {GitHub, Copilot, Eye Tracking, Readability, Empirical Study},
  location  = {Rochester, MI, USA},
  series    = {ASE '22}
}

@inproceedings{Dafny,
  author    = {Leino, K. Rustan M.},
  editor    = {Clarke, Edmund M.
               and Voronkov, Andrei},
  title     = {Dafny: An Automatic Program Verifier for Functional Correctness},
  booktitle = {Logic for Programming, Artificial Intelligence, and Reasoning},
  year      = {2010},
  publisher = {Springer Berlin Heidelberg},
  address   = {Berlin, Heidelberg},
  pages     = {348--370},
  abstract  = {Traditionally, the full verification of a program's functional correctness has been obtained with pen and paper or with interactive proof assistants, whereas only reduced verification tasks, such as extended static checking, have enjoyed the automation offered by satisfiability-modulo-theories (SMT) solvers. More recently, powerful SMT solvers and well-designed program verifiers are starting to break that tradition, thus reducing the effort involved in doing full verification.},
  isbn      = {978-3-642-17511-4}
}



@article{confidence,
  author     = {Hakkani-T\"{u}r, Dilek and Riccardi, Giuseppe and Tur, Gokhan},
  title      = {An Active Approach to Spoken Language Processing},
  year       = {2006},
  issue_date = {October 2006},
  publisher  = {Association for Computing Machinery},
  address    = {New York, NY, USA},
  volume     = {3},
  number     = {3},
  issn       = {1550-4875},
  url        = {https://doi.org/10.1145/1177055.1177056},
  doi        = {10.1145/1177055.1177056},
  abstract   = {State of the art data-driven speech and language processing systems require a large amount of human intervention ranging from data annotation to system prototyping. In the traditional supervised passive approach, the system is trained on a given number of annotated data samples and evaluated using a separate test set. Then more data is collected arbitrarily, annotated, and the whole cycle is repeated. In this article, we propose the active approach where the system itself selects its own training data, evaluates itself and re-trains when necessary. We first employ active learning which aims to automatically select the examples that are likely to be the most informative for a given task. We use active learning for both selecting the examples to label and the examples to re-label in order to correct labeling errors. Furthermore, the system automatically evaluates itself using active evaluation to keep track of the unexpected events and decides on-demand to label more examples. The active approach enables dynamic adaptation of spoken language processing systems to unseen or unexpected events for nonstationary input while reducing the manual annotation effort significantly. We have evaluated the active approach with the AT&amp;T spoken dialog system used for customer care applications. In this article, we present our results for both automatic speech recognition and spoken language understanding.},
  journal    = {ACM Trans. Speech Lang. Process.},
  month      = {oct},
  pages      = {1–31},
  numpages   = {31},
  keywords   = {unsupervised learning, active learning, spoken dialog systems, Passive learning, adaptive learning, spoken language understanding, active evaluation, automatic speech recognition, speech and language processing}
}

@book{kotz2005encyclopedia,
  title     = {Encyclopedia of Statistical Sciences, Volume 1},
  author    = {Kotz, Samuel and Balakrishnan, Narayanaswamy and Read, Campbell B and Vidakovic, Brani},
  year      = {2005},
  publisher = {John Wiley \& Sons}
}

@article{hochreiter1997long,
  title     = {Long short-term memory},
  author    = {Hochreiter, Sepp and Schmidhuber, J{\"u}rgen},
  journal   = {Neural computation},
  volume    = {9},
  number    = {8},
  pages     = {1735--1780},
  year      = {1997},
  publisher = {MIT Press}
}

@book{wasserman_faust_1994,
  place      = {Cambridge},
  series     = {Structural Analysis in the Social Sciences},
  title      = {Social Network Analysis: Methods and Applications},
  doi        = {10.1017/CBO9780511815478},
  publisher  = {Cambridge University Press},
  author     = {Wasserman, Stanley and Faust, Katherine},
  year       = {1994},
  collection = {Structural Analysis in the Social Sciences}
}

@inproceedings{sensei,
  author    = {Gao, Xiang and Saha, Ripon K. and Prasad, Mukul R. and Roychoudhury, Abhik},
  title     = {Fuzz Testing Based Data Augmentation to Improve Robustness of Deep Neural Networks},
  year      = {2020},
  isbn      = {9781450371216},
  publisher = {Association for Computing Machinery},
  address   = {New York, NY, USA},
  url       = {https://doi.org/10.1145/3377811.3380415},
  doi       = {10.1145/3377811.3380415},
  abstract  = {Deep neural networks (DNN) have been shown to be notoriously brittle to small perturbations in their input data. This problem is analogous to the over-fitting problem in test-based program synthesis and automatic program repair, which is a consequence of the incomplete specification, i.e., the limited tests or training examples, that the program synthesis or repair algorithm has to learn from. Recently, test generation techniques have been successfully employed to augment existing specifications of intended program behavior, to improve the generalizability of program synthesis and repair. Inspired by these approaches, in this paper, we propose a technique that re-purposes software testing methods, specifically mutation-based fuzzing, to augment the training data of DNNs, with the objective of enhancing their robustness. Our technique casts the DNN data augmentation problem as an optimization problem. It uses genetic search to generate the most suitable variant of an input data to use for training the DNN, while simultaneously identifying opportunities to accelerate training by skipping augmentation in many instances. We instantiate this technique in two tools, Sensei and Sensei-SA, and evaluate them on 15 DNN models spanning 5 popular image data-sets. Our evaluation shows that Sensei can improve the robust accuracy of the DNN, compared to the state of the art, on each of the 15 models, by upto 11.9\% and 5.5\% on average. Further, Sensei-SA can reduce the average DNN training time by 25\%, while still improving robust accuracy.},
  booktitle = {Proceedings of the ACM/IEEE 42nd International Conference on Software Engineering},
  pages     = {1147–1158},
  numpages  = {12},
  keywords  = {DNN, data augmentation, genetic algorithm, robustness},
  location  = {Seoul, South Korea},
  series    = {ICSE '20}
}


@article{roy2007survey,
  title   = {A survey on software clone detection research},
  author  = {Roy, Chanchal Kumar and Cordy, James R},
  journal = {Queen’s School of Computing TR},
  volume  = {541},
  number  = {115},
  pages   = {64--68},
  year    = {2007}
}

@inproceedings{9794113,
  author    = {Feng, Runhan and Yan, Ziyang and Peng, Shiyan and Zhang, Yuanyuan},
  booktitle = {2022 IEEE/ACM 44th International Conference on Software Engineering (ICSE)},
  title     = {Automated Detection of Password Leakage from Public GitHub Repositories},
  year      = {2022},
  volume    = {},
  number    = {},
  pages     = {175-186},
  doi       = {10.1145/3510003.3510150}
}


@misc{alkaswan2023targeted,
  title         = {Targeted Attack on GPT-Neo for the SATML Language Model Data Extraction Challenge},
  author        = {Ali Al-Kaswan and Maliheh Izadi and Arie van Deursen},
  year          = {2023},
  eprint        = {2302.07735},
  archiveprefix = {arXiv},
  primaryclass  = {cs.CL}
}

@inproceedings{LinB09-3,
  title     = {How to select a good training-data subset for transcription: submodular active selection for sequences},
  author    = {Hui Lin and Jeff Bilmes},
  year      = {2009},
  url       = {http://www.isca-speech.org/archive/interspeech_2009/i09_2859.html},
  researchr = {https://researchr.org/publication/LinB09-3},
  cites     = {0},
  citedby   = {0},
  pages     = {2859-2862},
  booktitle = {INTERSPEECH 2009, 10th Annual Conference of the International Speech Communication Association, Brighton, United Kingdom, September 6-10, 2009},
  publisher = {ISCA}
}

@inproceedings{aequevox,
  author    = {Rajan, Sai Sathiesh and Udeshi, Sakshi and Chattopadhyay, Sudipta},
  editor    = {Johnsen, Einar Broch and Wimmer, Manuel},
  title     = {AequeVox: Automated Fairness Testing of Speech Recognition Systems},
  booktitle = {Fundamental Approaches to Software Engineering},
  year      = {2022},
  publisher = {Springer International Publishing},
  pages     = {245--267}
}


@article{ma2019privacy,
  title     = {Privacy-preserving outsourced speech recognition for smart IoT devices},
  author    = {Ma, Zhuo and Liu, Yang and Liu, Ximeng and Ma, Jianfeng and Li, Feifei},
  journal   = {IEEE Internet of Things Journal},
  volume    = {6},
  number    = {5},
  pages     = {8406--8420},
  year      = {2019},
  publisher = {IEEE}
}

@article{wav2vec,
  author     = {Steffen Schneider and
                Alexei Baevski and
                Ronan Collobert and
                Michael Auli},
  title      = {wav2vec: Unsupervised Pre-training for Speech Recognition},
  journal    = {CoRR},
  volume     = {abs/1904.05862},
  year       = {2019},
  url        = {http://arxiv.org/abs/1904.05862},
  eprinttype = {arXiv},
  eprint     = {1904.05862},
  timestamp  = {Thu, 25 Apr 2019 13:55:01 +0200},
  biburl     = {https://dblp.org/rec/journals/corr/abs-1904-05862.bib},
  bibsource  = {dblp computer science bibliography, https://dblp.org}
}

@inproceedings{crossasr,
  author    = {Asyrofi, Muhammad Hilmi and Thung, Ferdian and Lo, David and Jiang, Lingxiao},
  booktitle = {2020 IEEE International Conference on Software Maintenance and Evolution (ICSME)},
  title     = {CrossASR: Efficient Differential Testing of Automatic Speech Recognition via Text-To-Speech},
  year      = {2020},
  volume    = {},
  number    = {},
  pages     = {640-650},
  doi       = {10.1109/ICSME46990.2020.00066}
}

@article{crowdsourcing,
  title   = {Crowdsourcing platform for large-scale speech data collection},
  author  = {Freitas, Joao and Calado, Ant{\'o}nio and Braga, Daniela and Silva, Pedro and Dias, M},
  journal = {Proc. Fala},
  year    = {2010}
}


@article{deepspeech,
  title   = {{Deep Speech}: Scaling up end-to-end speech recognition},
  author  = {Awni Y. Hannun and Carl Case and Jared Casper and Bryan Catanzaro and Greg Diamos and Erich Elsen and Ryan Prenger and Sanjeev Satheesh and Shubho Sengupta and Adam Coates and Andrew Y. Ng},
  journal = {ArXiv},
  year    = {2014},
  volume  = {abs/1412.5567}
}

@article{tjoa2020survey,
  title     = {A survey on explainable artificial intelligence (xai): Toward medical xai},
  author    = {Tjoa, Erico and Guan, Cuntai},
  journal   = {IEEE transactions on neural networks and learning systems},
  volume    = {32},
  number    = {11},
  pages     = {4793--4813},
  year      = {2020},
  publisher = {IEEE}
}

@article{zhuang2022randomness,
  title   = {Randomness in neural network training: Characterizing the impact of tooling},
  author  = {Zhuang, Donglin and Zhang, Xingyao and Song, Shuaiwen and Hooker, Sara},
  journal = {Proceedings of Machine Learning and Systems},
  volume  = {4},
  pages   = {316--336},
  year    = {2022}
}


@inproceedings{quartznet,
  title     = {QuartzNet: Deep Automatic Speech Recognition with 1D Time-Channel Separable Convolutions},
  author    = {Samuel Kriman and Stanislav Beliaev and Boris Ginsburg and Jocelyn Huang and Oleksii Kuchaiev and Vitaly Lavrukhin and Ryan Leary and Jason Li and Yang Zhang},
  booktitle = {ICASSP 2022 - 2021 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)},
  year      = {2020},
  volume    = {},
  number    = {},
  pages     = {6124–6128}
}


@book{cohen1988statistical,
  title     = {Statistical Power Analysis for the Behavioral Sciences},
  author    = {Cohen, Jacob},
  year      = {1988},
  edition   = {2nd},
  publisher = {Lawrence Erlbaum Associates},
  address   = {Hillsdale, NJ}
}


@inproceedings{ai_2,
  author    = {Gehr, Timon and Mirman, Matthew and Drachsler-Cohen, Dana and Tsankov, Petar and Chaudhuri, Swarat and Vechev, Martin},
  booktitle = {2018 IEEE Symposium on Security and Privacy (SP)},
  title     = {AI2: Safety and Robustness Certification of Neural Networks with Abstract Interpretation},
  year      = {2018},
  volume    = {},
  number    = {},
  pages     = {3-18},
  abstract  = {We present AI2, the first sound and scalable analyzer for deep neural networks. Based on overapproximation, AI2 can automatically prove safety properties (e.g., robustness) of realistic neural networks (e.g., convolutional neural networks). The key insight behind AI2 is to phrase reasoning about safety and robustness of neural networks in terms of classic abstract interpretation, enabling us to leverage decades of advances in that area. Concretely, we introduce abstract transformers that capture the behavior of fully connected and convolutional neural network layers with rectified linear unit activations (ReLU), as well as max pooling layers. This allows us to handle real-world neural networks, which are often built out of those types of layers. We present a complete implementation of AI2 together with an extensive evaluation on 20 neural networks. Our results demonstrate that: (i) AI2 is precise enough to prove useful specifications (e.g., robustness), (ii) AI2 can be used to certify the effectiveness of state-of-the-art defenses for neural networks, (iii) AI2 is significantly faster than existing analyzers based on symbolic analysis, which often take hours to verify simple fully connected networks, and (iv) AI2 can handle deep convolutional networks, which are beyond the reach of existing methods.},
  keywords  = {},
  doi       = {10.1109/SP.2018.00058},
  url       = {https://doi.org/10.1109/SP.2018.00058},
  issn      = {2375-1207},
  month     = {May}
}

@article{bencheikh2023exploring,
  title  = {Exploring the Efficacy of ChatGPT in Generating Requirements: An Experimental Study},
  author = {Bencheikh, Leila and H{\"o}glund, Niklas},
  year   = {2023}
}


@inproceedings{10.1145/3427228.3427258,
author = {Du, Kun and Yang, Hao and Zhang, Yubao and Duan, Haixin and Wang, Haining and Hao, Shuang and Li, Zhou and Yang, Min},
title = {Understanding Promotion-as-a-Service on GitHub},
year = {2020},
isbn = {9781450388580},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3427228.3427258},
doi = {10.1145/3427228.3427258},
abstract = {As the world’s leading software development platform, GitHub has become a social networking site for programmers and recruiters who leverage its social features, such as star and fork, for career and business development. However, in this paper, we found a group of GitHub accounts that conducted promotion services in GitHub, called “promoters”, by performing paid star and fork operations on specified repositories. We also uncovered a stealthy way of tampering with historical commits, through which these promoters are able to fake commits retroactively. By exploiting such a promotion service, any GitHub user can pretend to be a skillful developer with high influence. To understand promotion services in GitHub, we first investigated the underground promotion market of GitHub and identified 1,023 suspected promotion accounts from the market. Then, we developed an SVM (Support Vector Machine) classifier to detect promotion accounts from all active users extracted from GH Archive ranging from 2015 to 2019. In total, we detected 63,872 suspected promotion accounts. We further analyzed these suspected promotion accounts, showing that (1) a hidden functionality in GitHub is abused to boost the reputation of an account by forging historical commits and (2) a group of small businesses exploit GitHub promotion services to promote their products. We estimated that suspicious promoters could have made a profit of $3.41 million and $4.37 million in 2018 and 2019, respectively.},
booktitle = {Proceedings of the 36th Annual Computer Security Applications Conference},
pages = {597–610},
numpages = {14},
keywords = {Promoter Detection, GitHub, Promotion-as-a-Service},
location = {<conf-loc>, <city>Austin</city>, <country>USA</country>, </conf-loc>},
series = {ACSAC '20}
}

@inproceedings{10.1145/3593434.3593468,
  author    = {Ahmad, Aakash and Waseem, Muhammad and Liang, Peng and Fahmideh, Mahdi and Aktar, Mst Shamima and Mikkonen, Tommi},
  title     = {Towards Human-Bot Collaborative Software Architecting with ChatGPT},
  year      = {2023},
  isbn      = {9798400700446},
  publisher = {Association for Computing Machinery},
  address   = {New York, NY, USA},
  url       = {https://doi.org/10.1145/3593434.3593468},
  doi       = {10.1145/3593434.3593468},
  abstract  = {Architecting software-intensive systems can be a complex process. It deals with the daunting tasks of unifying stakeholders’ perspectives, designers’ intellect, tool-based automation, pattern-driven reuse, and so on, to sketch a blueprint that guides software implementation and evaluation. Despite its benefits, architecture-centric software engineering (ACSE) suffers from a multitude of challenges. ACSE challenges could stem from a lack of standardized processes, socio-technical limitations, and scarcity of human expertise etc. that can impede the development of existing and emergent classes of software. Software Development Bots (DevBots) trained on large language models can help synergise architects’ knowledge with artificially intelligent decision support to enable rapid architecting in a human-bot collaborative ACSE. An emerging solution to enable this collaboration is ChatGPT, a disruptive technology not primarily introduced for software engineering, but is capable of articulating and refining architectural artifacts based on natural language processing. We detail a case study that involves collaboration between a novice software architect and ChatGPT to architect a service-based software. Future research focuses on harnessing empirical evidence about architects’ productivity and explores socio-technical aspects of architecting with ChatGPT to tackle challenges of ACSE.},
  booktitle = {Proceedings of the 27th International Conference on Evaluation and Assessment in Software Engineering},
  pages     = {279–285},
  numpages  = {7},
  keywords  = {Large Language Models, DevBots, ChatGPT, Software Architecture},
  location  = {Oulu, Finland},
  series    = {EASE '23}
}

@inproceedings{DeepConcolic,
  author    = {Sun, Youcheng and Wu, Min and Ruan, Wenjie and Huang, Xiaowei and Kwiatkowska, Marta and Kroening, Daniel},
  title     = {Concolic Testing for Deep Neural Networks},
  year      = {2018},
  isbn      = {9781450359375},
  publisher = {Association for Computing Machinery},
  address   = {New York, NY, USA},
  url       = {https://doi-org.libproxy.smu.edu.sg/10.1145/3238147.3238172},
  doi       = {10.1145/3238147.3238172},
  abstract  = {Concolic testing combines program execution and symbolic analysis to explore the execution paths of a software program. In this paper, we develop the first concolic testing approach for Deep Neural Networks (DNNs). More specifically, we utilise quantified linear arithmetic over rationals to express test requirements that have been studied in the literature, and then develop a coherent method to perform concolic testing with the aim of better coverage. Our experimental results show the effectiveness of the concolic testing approach in both achieving high coverage and finding adversarial examples.},
  booktitle = {Proceedings of the 33rd ACM/IEEE International Conference on Automated Software Engineering},
  pages     = {109–119},
  numpages  = {11},
  keywords  = {symbolic execution, concolic testing, neural networks},
  location  = {Montpellier, France},
  series    = {ASE 2018}
}

@inproceedings{crossasrpp,
  author    = {Asyrofi, Muhammad Hilmi and Yang, Zhou and Lo, David},
  title     = {CrossASR++: A Modular Differential Testing Framework for Automatic Speech Recognition},
  year      = {2021},
  isbn      = {9781450385626},
  publisher = {Association for Computing Machinery},
  address   = {New York, NY, USA},
  url       = {https://doi.org/10.1145/3468264.3473124},
  doi       = {10.1145/3468264.3473124},
  abstract  = {Developers need to perform adequate testing to ensure the quality of Automatic Speech Recognition (ASR) systems. However, manually collecting required test cases is tedious and time-consuming. Our recent work proposes CrossASR, a differential testing method for ASR systems. This method first utilizes Text-to-Speech (TTS) to generate audios from texts automatically and then feed these audios into different ASR systems for cross-referencing to uncover failed test cases. It also leverages a failure estimator to find failing test cases more efficiently. Such a method is inherently self-improvable: the performance can increase by leveraging more advanced TTS and ASR systems. So, in this accompanying tool demo paper, we further engineer CrossASR and propose CrossASR++, an easy-to-use ASR testing tool that can be conveniently extended to incorporate different TTS and ASR systems, and failure estimators. We also make CrossASR++ chunk texts from a given corpus dynamically and enable the estimator to work in a more effective and flexible way. We demonstrate that the new features can help CrossASR++ discover more failed test cases. Using the same TTS and ASR systems, CrossASR++ can uncover 26.2% more failed test cases for 4 ASRs than the original tool. Moreover, by simply adding one more ASR for cross-referencing, we can increase the number of failed test cases uncovered for each of the 4 ASR systems by 25.07%, 39.63%, 20.95% and 8.17% respectively. We also extend CrossASR++ with 5 additional failure estimators. Compared to worst estimator, the best one can discover 10.41% more failed test cases within the same amount of time. The demo video for CrossASR++ can be viewed at https://youtu.be/ddRk-f0QV-g and the source code can be found at https://github.com/soarsmu/CrossASRplus.},
  booktitle = {Proceedings of the 29th ACM Joint Meeting on European Software Engineering Conference and Symposium on the Foundations of Software Engineering},
  pages     = {1575–1579},
  numpages  = {5},
  keywords  = {Cross-Referencing, Automatic Speech Recognition, Text-to-Speech, Test Case Generation},
  location  = {Athens, Greece},
  series    = {ESEC/FSE 2021}
}

@inproceedings{6289079,
  author    = {Schuster, Mike and Nakajima, Kaisuke},
  booktitle = {2012 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)},
  title     = {Japanese and Korean voice search},
  year      = {2012},
  volume    = {},
  number    = {},
  pages     = {5149-5152},
  doi       = {10.1109/ICASSP.2012.6289079}
}

@article{wordpiece,
  author     = {Yonghui Wu and
                Mike Schuster and
                Zhifeng Chen and
                Quoc V. Le and
                Mohammad Norouzi and
                Wolfgang Macherey and
                Maxim Krikun and
                Yuan Cao and
                Qin Gao and
                Klaus Macherey and
                Jeff Klingner and
                Apurva Shah and
                Melvin Johnson and
                Xiaobing Liu and
                Lukasz Kaiser and
                Stephan Gouws and
                Yoshikiyo Kato and
                Taku Kudo and
                Hideto Kazawa and
                Keith Stevens and
                George Kurian and
                Nishant Patil and
                Wei Wang and
                Cliff Young and
                Jason Smith and
                Jason Riesa and
                Alex Rudnick and
                Oriol Vinyals and
                Greg Corrado and
                Macduff Hughes and
                Jeffrey Dean},
  title      = {Google's Neural Machine Translation System: Bridging the Gap between
                Human and Machine Translation},
  journal    = {CoRR},
  volume     = {abs/1609.08144},
  year       = {2016},
  url        = {http://arxiv.org/abs/1609.08144},
  eprinttype = {arXiv},
  eprint     = {1609.08144},
  timestamp  = {Thu, 14 Jan 2021 12:12:19 +0100},
  biburl     = {https://dblp.org/rec/journals/corr/WuSCLNMKCGMKSJL16.bib},
  bibsource  = {dblp computer science bibliography, https://dblp.org}
}

@article{10.1145/375360.375365,
  author     = {Navarro, Gonzalo},
  title      = {A Guided Tour to Approximate String Matching},
  year       = {2001},
  issue_date = {March 2001},
  publisher  = {Association for Computing Machinery},
  address    = {New York, NY, USA},
  volume     = {33},
  number     = {1},
  issn       = {0360-0300},
  url        = {https://doi.org/10.1145/375360.375365},
  doi        = {10.1145/375360.375365},
  abstract   = {We survey the current techniques to cope with the problem of string matching that allows errors. This is becoming a more and more relevant issue for many fast growing areas such as information retrieval and computational biology. We focus on online searching and mostly on edit distance, explaining the problem and its relevance, its statistical behavior, its history and current developments, and the central ideas of the algorithms and their complexities. We present a number of experiments to compare the performance of the different algorithms and show which are the best choices. We conclude with some directions for future work and open problems.},
  journal    = {ACM Comput. Surv.},
  month      = {mar},
  pages      = {31–88},
  numpages   = {58},
  keywords   = {text searching allowing errors, edit distance, Levenshtein distance, online string matching}
}

@inproceedings{phonme_rich,
  author    = {Shinohara, Yusuke},
  booktitle = {2014 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)},
  title     = {A submodular optimization approach to sentence set selection},
  year      = {2014},
  volume    = {},
  number    = {},
  pages     = {4112-4115},
  doi       = {10.1109/ICASSP.2014.phonme_rich}
}

@inproceedings{asdf-paper,
  author    = {Yuen, Daniel Hao Xian and Pang, Andrew Yong Chen and Yang, Zhou and Chong, Chun Yong and Lim, Mei Kuan and Lo, David},
  title     = {ASDF: A Differential Testing Framework for Automatic Speech Recognition Systems},
  booktitle = {16th {IEEE} Conference on Software Testing, Verification and Validation,
               {ICST}},
  publisher = {{IEEE}},
  year      = {2023}
}



@electronic{asdf,
  howpublished = {Online},
  month        = jan,
  organization = {GitHub},
  title        = {ASR Differential Testing Framework (ASDF)},
  url          = {https://github.com/danielyuenhx/asdf-differential-testing},
  year         = {2023}
}

@electronic{crossasr++,
  howpublished = {Online},
  month        = dec,
  organization = {GitHub},
  title        = {CrossASR++},
  url          = {https://github.com/soarsmu/CrossASRplus},
  year         = {2021}
}



@electronic{wordhoard,
  author       = {John Bumgarner},
  howpublished = {Online},
  month        = may,
  organization = {GitHub},
  title        = {WordHoard},
  url          = {https://github.com/johnbumgarner/wordhoard},
  year         = {2022}
}


@electronic{wav2letter-repo,
  howpublished = {Online},
  month        = dec,
  organization = {GitHub},
  title        = {wav2letter},
  url          = {https://github.com/flashlight/wav2letter},
  year         = {2022}
}

@electronic{gtts-repo,
  howpublished = {Online},
  month        = dec,
  organization = {GitHub},
  title        = {gTTS},
  url          = {https://github.com/pndurette/gTTS},
  year         = {2022}
}

@article{sedgwick2014spearman,
  title     = {Spearman’s rank correlation coefficient},
  author    = {Sedgwick, Philip},
  journal   = {Bmj},
  volume    = {349},
  year      = {2014},
  publisher = {British Medical Journal Publishing Group}
}

@article{Whang,
  author  = {Whang, Steven and Lee, Jae-Gil},
  year    = {2020},
  month   = {08},
  pages   = {3429-3432},
  title   = {Data collection and quality challenges for deep learning},
  volume  = {13},
  journal = {Proceedings of the VLDB Endowment},
  doi     = {10.14778/3415478.3415562}
}

 @misc{heaven_2022,
  title     = {Ai is wrestling with a replication crisis},
  url       = {shorturl.at/djMN3},
  journal   = {MIT Technology Review},
  publisher = {MIT Technology Review},
  author    = {Heaven, Will Douglas},
  year      = {2022},
  month     = {Apr}
} 

@article{strickland2019ibm,
  title     = {IBM Watson, heal thyself: How IBM overpromised and underdelivered on AI health care},
  author    = {Strickland, Eliza},
  journal   = {IEEE Spectrum},
  volume    = {56},
  number    = {4},
  pages     = {24--31},
  year      = {2019},
  publisher = {IEEE}
}

@article{danilevsky2020survey,
  title   = {A survey of the state of explainable AI for natural language processing},
  author  = {Danilevsky, Marina and Qian, Kun and Aharonov, Ranit and Katsis, Yannis and Kawas, Ban and Sen, Prithviraj},
  journal = {arXiv preprint arXiv:2010.00711},
  year    = {2020}
}

@article{chowdhary2020natural,
  title     = {Natural language processing},
  author    = {Chowdhary, KR1442},
  journal   = {Fundamentals of artificial intelligence},
  pages     = {603--649},
  year      = {2020},
  publisher = {Springer}
}

@inproceedings{7995975,
  author    = {Chen, Zhilu and Huang, Xinming},
  booktitle = {2017 IEEE Intelligent Vehicles Symposium (IV)},
  title     = {End-to-end learning for lane keeping of self-driving cars},
  year      = {2017},
  volume    = {},
  number    = {},
  pages     = {1856-1860},
  doi       = {10.1109/IVS.2017.7995975}
}


@article{lalwani2018implementation,
  title   = {Implementation of a Chatbot System using AI and NLP},
  author  = {Lalwani, Tarun and Bhalotia, Shashank and Pal, Ashish and Rathod, Vasundhara and Bisen, Shreya},
  journal = {International Journal of Innovative Research in Computer Science \& Technology (IJIRCST) Volume-6, Issue-3},
  year    = {2018}
}

@inproceedings{5558972,
  author    = {Alnusair, Awny and Zhao, Tian and Bodden, Eric},
  booktitle = {2010 IEEE International Conference on Information Reuse \& Integration},
  title     = {Effective API navigation and reuse},
  year      = {2010},
  volume    = {},
  number    = {},
  pages     = {7-12},
  doi       = {10.1109/IRI.2010.5558972}
}

@inproceedings{alsulami_source_2017,
  title     = {Source code authorship attribution using long short-term memory based networks},
  doi       = {10.1007/978-3-319-66402-6_6},
  language  = {English (US)},
  urldate   = {2021-08-21},
  booktitle = {Computer {Security} - {ESORICS} 2017},
  publisher = {Springer Verlag},
  author    = {Alsulami, Bander and Dauber, Edwin and Harang, Richard and Mancoridis, Spiros and Greenstadt, Rachel},
  year      = {2017},
  pages     = {65--82}
}


@article{zhang2019explorative,
  title   = {An explorative study of github repositories of ai papers},
  author  = {Zhang, Boyang},
  journal = {arXiv preprint arXiv:1903.01555},
  year    = {2019}
}

@inproceedings{gonzalez2020state,
  title     = {The state of the ml-universe: 10 years of artificial intelligence \& machine learning software development on github},
  author    = {Gonzalez, Danielle and Zimmermann, Thomas and Nagappan, Nachiappan},
  booktitle = {Proceedings of the 17th International Conference on Mining Software Repositories},
  pages     = {431--442},
  year      = {2020}
}

@article{tomavsev2020ai,
  title     = {AI for social good: unlocking the opportunity for positive impact},
  author    = {Toma{\v{s}}ev, Nenad and Cornebise, Julien and Hutter, Frank and Mohamed, Shakir and Picciariello, Angela and Connelly, Bec and Belgrave, Danielle and Ezer, Daphne and Haert, Fanny Cachat van der and Mugisha, Frank and others},
  journal   = {Nature Communications},
  volume    = {11},
  number    = {1},
  pages     = {1--6},
  year      = {2020},
  publisher = {Nature Publishing Group}
}


@article{goralski2020artificial,
  title     = {Artificial intelligence and sustainable development},
  author    = {Goralski, Margaret A and Tan, Tay Keong},
  journal   = {The International Journal of Management Education},
  volume    = {18},
  number    = {1},
  pages     = {100330},
  year      = {2020},
  publisher = {Elsevier}
}

@article{carvalho2019off,
  title   = {Off-the-shelf artificial intelligence technologies for sentiment and emotion analysis: a tutorial on using IBM natural language processing},
  author  = {Carvalho, Arthur and Levitt, Adam and Levitt, Seth and Khaddam, Edward and Benamati, John},
  journal = {Communications of the Association for Information Systems},
  volume  = {44},
  number  = {1},
  pages   = {43},
  year    = {2019}
}

@article{izadi2022predicting,
  title     = {Predicting the objective and priority of issue reports in software repositories},
  author    = {Izadi, Maliheh and Akbari, Kiana and Heydarnoori, Abbas},
  journal   = {Empirical Software Engineering},
  volume    = {27},
  number    = {2},
  pages     = {1--37},
  year      = {2022},
  publisher = {Springer}
}


@inproceedings{9794048,
  author    = {Izadi, Maliheh and Gismondi, Roberta and Gousios, Georgios},
  booktitle = {2022 IEEE/ACM 44th International Conference on Software Engineering (ICSE)},
  title     = {CodeFill: Multi-token Code Completion by Jointly learning from Structure and Naming Sequences},
  year      = {2022},
  volume    = {},
  number    = {},
  pages     = {401-412},
  doi       = {10.1145/3510003.3510172}
}

@inproceedings{10.1145/3510003.3510222,
  author    = {Ye, He and Martinez, Matias and Monperrus, Martin},
  title     = {Neural Program Repair with Execution-Based Backpropagation},
  year      = {2022},
  isbn      = {9781450392211},
  publisher = {Association for Computing Machinery},
  address   = {New York, NY, USA},
  url       = {https://doi.org/10.1145/3510003.3510222},
  doi       = {10.1145/3510003.3510222},
  abstract  = {Neural machine translation (NMT) architectures have achieved promising results for automatic program repair. Yet, they have the limitation of generating low-quality patches (e.g., not compilable patches). This is because the existing works only optimize a purely syntactic loss function based on characters and tokens without incorporating program-specific information during neural network weight optimization. In this paper, we propose a novel program repair model called RewardRepair. The core novelty of RewardRepair is to improve NMT-based program repair with a loss function based on program compilation and test execution information, rewarding the network to produce patches that compile and that do not overfit. We conduct several experiments to evaluate RewardRepair showing that it is feasible and effective to use compilation and test execution results to optimize the underlying neural repair model. RewardRepair correctly repairs 207 bugs over four benchmarks. we report on repair success for 121 bugs that are fixed for the first time in the literature. Also, RewardRepair produces up to 45.3% of compilable patches, an improvement over the 39% by the state-of-the-art.},
  booktitle = {Proceedings of the 44th International Conference on Software Engineering},
  pages     = {1506–1518},
  numpages  = {13},
  location  = {Pittsburgh, Pennsylvania},
  series    = {ICSE '22}
}

@inproceedings{9462962,
  author    = {Mazuera-Rozo, Alejandro and Mojica-Hanke, Anamaria and Linares-Vásquez, Mario and Bavota, Gabriele},
  booktitle = {2021 IEEE/ACM 29th International Conference on Program Comprehension (ICPC)},
  title     = {Shallow or Deep? An Empirical Study on Detecting Vulnerabilities using Deep Learning},
  year      = {2021},
  volume    = {},
  number    = {},
  pages     = {276-287},
  doi       = {10.1109/ICPC52881.2021.00034}
}

@article{Wilcoxon,
  issn      = {00994987},
  url       = {http://www.jstor.org/stable/3001968},
  author    = {Frank Wilcoxon},
  journal   = {Biometrics Bulletin},
  number    = {6},
  pages     = {80--83},
  publisher = {[International Biometric Society, Wiley]},
  title     = {Individual Comparisons by Ranking Methods},
  urldate   = {2023-01-03},
  volume    = {1},
  year      = {1945}
}

@misc{zhao2023survey,
  title         = {A Survey of Large Language Models},
  author        = {Wayne Xin Zhao and Kun Zhou and Junyi Li and Tianyi Tang and Xiaolei Wang and Yupeng Hou and Yingqian Min and Beichen Zhang and Junjie Zhang and Zican Dong and Yifan Du and Chen Yang and Yushuo Chen and Zhipeng Chen and Jinhao Jiang and Ruiyang Ren and Yifan Li and Xinyu Tang and Zikang Liu and Peiyu Liu and Jian-Yun Nie and Ji-Rong Wen},
  year          = {2023},
  eprint        = {2303.18223},
  archiveprefix = {arXiv},
  primaryclass  = {cs.CL}
}

@inproceedings{checklist,
  title     = {Beyond Accuracy: Behavioral Testing of {NLP} Models with {C}heck{L}ist},
  author    = {Ribeiro, Marco Tulio  and
               Wu, Tongshuang  and
               Guestrin, Carlos  and
               Singh, Sameer},
  booktitle = {Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics},
  month     = jul,
  year      = {2020},
  address   = {Online},
  publisher = {Association for Computational Linguistics},
  url       = {https://aclanthology.org/2020.acl-main.442},
  doi       = {10.18653/v1/2020.acl-main.442},
  pages     = {4902--4912},
  abstract  = {Although measuring held-out accuracy has been the primary approach to evaluate generalization, it often overestimates the performance of NLP models, while alternative approaches for evaluating models either focus on individual tasks or on specific behaviors. Inspired by principles of behavioral testing in software engineering, we introduce CheckList, a task-agnostic methodology for testing NLP models. CheckList includes a matrix of general linguistic capabilities and test types that facilitate comprehensive test ideation, as well as a software tool to generate a large and diverse number of test cases quickly. We illustrate the utility of CheckList with tests for three tasks, identifying critical failures in both commercial and state-of-art models. In a user study, a team responsible for a commercial sentiment analysis model found new and actionable bugs in an extensively tested model. In another user study, NLP practitioners with CheckList created twice as many tests, and found almost three times as many bugs as users without it.}
}

@inproceedings{6405375,
  author    = {Thung, Ferdian and Wang, Shaowei and Lo, David and Jiang, Lingxiao},
  booktitle = {2012 IEEE 23rd International Symposium on Software Reliability Engineering},
  title     = {An Empirical Study of Bugs in Machine Learning Systems},
  year      = {2012},
  volume    = {},
  number    = {},
  pages     = {271-280},
  doi       = {10.1109/ISSRE.2012.22}
}

@misc{she2023pitfalls,
  title         = {Pitfalls in Language Models for Code Intelligence: A Taxonomy and Survey},
  author        = {Xinyu She and Yue Liu and Yanjie Zhao and Yiling He and Li Li and Chakkrit Tantithamthavorn and Zhan Qin and Haoyu Wang},
  year          = {2023},
  eprint        = {2310.17903},
  archiveprefix = {arXiv},
  primaryclass  = {cs.SE}
}

@misc{fan2023large,
  title         = {Large Language Models for Software Engineering: Survey and Open Problems},
  author        = {Angela Fan and Beliz Gokkaya and Mark Harman and Mitya Lyubarskiy and Shubho Sengupta and Shin Yoo and Jie M. Zhang},
  year          = {2023},
  eprint        = {2310.03533},
  archiveprefix = {arXiv},
  primaryclass  = {cs.SE}
}

@misc{nguyenduc2023generative,
  title         = {Generative Artificial Intelligence for Software Engineering -- A Research Agenda},
  author        = {Anh Nguyen-Duc and Beatriz Cabrero-Daniel and Adam Przybylek and Chetan Arora and Dron Khanna and Tomas Herda and Usman Rafiq and Jorge Melegati and Eduardo Guerra and Kai-Kristian Kemell and Mika Saari and Zheying Zhang and Huy Le and Tho Quan and Pekka Abrahamsson},
  year          = {2023},
  eprint        = {2310.18648},
  archiveprefix = {arXiv},
  primaryclass  = {cs.SE}
}


@misc{codellm_survey,
  title         = {Large Language Models for Software Engineering: A Systematic Literature Review},
  author        = {Xinyi Hou and Yanjie Zhao and Yue Liu and Zhou Yang and Kailong Wang and Li Li and Xiapu Luo and David Lo and John Grundy and Haoyu Wang},
  year          = {2023},
  eprint        = {2308.10620},
  archiveprefix = {arXiv},
  primaryclass  = {cs.SE}
}

@inproceedings{8305957,
  author    = {Sun, Xiaobing and Zhou, Tianchi and Li, Gengjie and Hu, Jiajun and Yang, Hui and Li, Bin},
  booktitle = {2017 24th Asia-Pacific Software Engineering Conference (APSEC)},
  title     = {An Empirical Study on Real Bugs for Machine Learning Programs},
  year      = {2017},
  volume    = {},
  number    = {},
  pages     = {348-357},
  doi       = {10.1109/APSEC.2017.41}
}

@misc{zheng2023survey,
  title         = {A Survey of Large Language Models for Code: Evolution, Benchmarking, and Future Trends},
  author        = {Zibin Zheng and Kaiwen Ning and Yanlin Wang and Jingwen Zhang and Dewu Zheng and Mingxi Ye and Jiachi Chen},
  year          = {2023},
  eprint        = {2311.10372},
  archiveprefix = {arXiv},
  primaryclass  = {cs.SE}
}

@article{gao2023constructing,
  title={Constructing Effective In-Context Demonstration for Code Intelligence Tasks: An Empirical Study},
  author={Gao, Shuzheng and Wen, Xin-Cheng and Gao, Cuiyun and Wang, Wenxuan and Lyu, Michael R},
  journal={arXiv preprint arXiv:2304.07575},
  year={2023}
}

@misc{lo2023trustworthy,
  title         = {Trustworthy and Synergistic Artificial Intelligence for Software Engineering: Vision and Roadmaps},
  author        = {David Lo},
  year          = {2023},
  eprint        = {2309.04142},
  archiveprefix = {arXiv},
  primaryclass  = {cs.SE}
}

@inproceedings{10.1145/3377811.3380395,
  author    = {Humbatova, Nargiz and Jahangirova, Gunel and Bavota, Gabriele and Riccio, Vincenzo and Stocco, Andrea and Tonella, Paolo},
  title     = {Taxonomy of Real Faults in Deep Learning Systems},
  year      = {2020},
  isbn      = {9781450371216},
  publisher = {Association for Computing Machinery},
  address   = {New York, NY, USA},
  abstract  = {The growing application of deep neural networks in safety-critical domains makes the analysis of faults that occur in such systems of enormous importance. In this paper we introduce a large taxonomy of faults in deep learning (DL) systems. We have manually analysed 1059 artefacts gathered from GitHub commits and issues of projects that use the most popular DL frameworks (TensorFlow, Keras and PyTorch) and from related Stack Overflow posts. Structured interviews with 20 researchers and practitioners describing the problems they have encountered in their experience have enriched our taxonomy with a variety of additional faults that did not emerge from the other two sources. Our final taxonomy was validated with a survey involving an additional set of 21 developers, confirming that almost all fault categories (13/15) were experienced by at least 50% of the survey participants.},
  booktitle = {Proceedings of the ACM/IEEE 42nd International Conference on Software Engineering},
  pages     = {1110–1121},
  numpages  = {12},
  keywords  = {taxonomy, deep learning, software testing, real faults},
  location  = {Seoul, South Korea},
  series    = {ICSE '20}
}

@article{Spohrer_2021,
  title        = {The Role of Open-Source Software in Artificial Intelligence},
  volume       = {42},
  url          = {https://ojs.aaai.org/index.php/aimagazine/article/view/7488},
  abstractnote = {&lt;div&gt;
                  &lt;p class=&quot;abstract&quot;&gt;&lt;span lang=&quot;EN-IN&quot;&gt;With this publication, we launch a new column for &lt;em&gt;AI Magazine&lt;/em&gt; on the role of open-source software in artificial intelligence. As the column editor, I would like to extend my welcome and invite &lt;em&gt;AI Magazine readers&lt;/em&gt; to send short articles for future columns, which may appear in the traditional print version of &lt;em&gt;AI Magazine&lt;/em&gt;, or on the &lt;em&gt;AI Magazine&lt;/em&gt; interactive site currently under development. This introductory column serves to highlight my interests in open-source software and to propose a few topics for future columns.&lt;/span&gt;&lt;/p&gt;
                  &lt;/div&gt;},
  number       = {1},
  journal      = {AI Magazine},
  author       = {Spohrer, Jim},
  year         = {2021},
  month        = {Apr.},
  pages        = {93-94}
}

@article{gundersen2018reproducible,
  title   = {On reproducible AI: Towards reproducible research, open science, and digital scholarship in AI publications},
  author  = {Gundersen, Odd Erik and Gil, Yolanda and Aha, David W},
  journal = {AI magazine},
  volume  = {39},
  number  = {3},
  pages   = {56--68},
  year    = {2018}
}


@inproceedings{dosovitskiy2017carla,
  title        = {CARLA: An open urban driving simulator},
  author       = {Dosovitskiy, Alexey and Ros, German and Codevilla, Felipe and Lopez, Antonio and Koltun, Vladlen},
  booktitle    = {Conference on robot learning},
  pages        = {1--16},
  year         = {2017},
  organization = {PMLR}
}

@inproceedings{amershi2019SE4AI,
  author    = {Amershi, Saleema and Begel, Andrew and Bird, Christian and DeLine, Robert and Gall, Harald and Kamar, Ece and Nagappan, Nachiappan and Nushi, Besmira and Zimmermann, Thomas},
  booktitle = {2019 IEEE/ACM 41st International Conference on Software Engineering: Software Engineering in Practice (ICSE-SEIP)},
  title     = {Software Engineering for Machine Learning: A Case Study},
  year      = {2019},
  volume    = {},
  number    = {},
  pages     = {291-300},
  doi       = {10.1109/ICSE-SEIP.2019.00042}
}

@article{brockman2016openai,
  title   = {Openai gym},
  author  = {Brockman, Greg and Cheung, Vicki and Pettersson, Ludwig and Schneider, Jonas and Schulman, John and Tang, Jie and Zaremba, Wojciech},
  journal = {arXiv preprint arXiv:1606.01540},
  year    = {2016}
}


@article{mchugh2012interrater,
  title     = {Interrater reliability: the kappa statistic},
  author    = {McHugh, Mary L},
  journal   = {Biochemia medica},
  volume    = {22},
  number    = {3},
  pages     = {276--282},
  year      = {2012},
  publisher = {Medicinska naklada}
}

@inproceedings{10.1145/3522664.3528620,
  author    = {Zhang, Haiyin and Cruz, Lu\'{\i}s and van Deursen, Arie},
  title     = {Code Smells for Machine Learning Applications},
  year      = {2022},
  isbn      = {9781450392754},
  publisher = {Association for Computing Machinery},
  address   = {New York, NY, USA},
  url       = {https://doi.org/10.1145/3522664.3528620},
  doi       = {10.1145/3522664.3528620},
  abstract  = {The popularity of machine learning has wildly expanded in recent years. Machine learning techniques have been heatedly studied in academia and applied in the industry to create business value. However, there is a lack of guidelines for code quality in machine learning applications. In particular, code smells have rarely been studied in this domain. Although machine learning code is usually integrated as a small part of an overarching system, it usually plays an important role in its core functionality. Hence ensuring code quality is quintessential to avoid issues in the long run. This paper proposes and identifies a list of 22 machine learning-specific code smells collected from various sources, including papers, grey literature, GitHub commits, and Stack Overflow posts. We pinpoint each smell with a description of its context, potential issues in the long run, and proposed solutions. In addition, we link them to their respective pipeline stage and the evidence from both academic and grey literature. The code smell catalog helps data scientists and developers produce and maintain high-quality machine learning application code.},
  booktitle = {Proceedings of the 1st International Conference on AI Engineering: Software Engineering for AI},
  pages     = {217–228},
  numpages  = {12},
  keywords  = {code smell, technical debt, anti-pattern, code quality, machine learning},
  location  = {Pittsburgh, Pennsylvania},
  series    = {CAIN '22}
}

@article{barabasi1999emergence,
  title     = {Emergence of scaling in random networks},
  author    = {Barab{\'a}si, Albert-L{\'a}szl{\'o} and Albert, R{\'e}ka},
  journal   = {science},
  volume    = {286},
  number    = {5439},
  pages     = {509--512},
  year      = {1999},
  publisher = {American Association for the Advancement of Science}
}

@inproceedings{SoftwareHeritage,
  author    = {Pietri, Antoine and Spinellis, Diomidis and Zacchiroli, Stefano},
  title     = {The Software Heritage Graph Dataset: Large-Scale Analysis of Public Software Development History},
  year      = {2020},
  isbn      = {9781450375177},
  publisher = {Association for Computing Machinery},
  address   = {New York, NY, USA},
  url       = {https://doi.org/10.1145/3379597.3387510},
  doi       = {10.1145/3379597.3387510},
  abstract  = {Software Heritage is the largest existing public archive of software source code and accompanying development history. It spans more than five billion unique source code files and one billion unique commits, coming from more than 80 million software projects. These software artifacts were retrieved from major collaborative development platforms (e.g., GitHub, GitLab) and package repositories (e.g., PyPI, Debian, NPM), and stored in a uniform representation linking together source code files, directories, commits, and full snapshots of version control systems (VCS) repositories as observed by Software Heritage during periodic crawls. This dataset is unique in terms of accessibility and scale, and allows to explore a number of research questions on the long tail of public software development, instead of solely focusing on "most starred" repositories as it often happens.},
  booktitle = {Proceedings of the 17th International Conference on Mining Software Repositories},
  pages     = {1–5},
  numpages  = {5},
  location  = {Seoul, Republic of Korea},
  series    = {MSR '20}
}

@article{Jesus2023,
  author   = {Jesus M. Gonzalez-Barahona and Sergio Montes-Leon and Gregorio Robles and Stefano Zacchiroli},
  title    = {The software heritage license dataset (2022 edition)},
  journal  = {Empirical Software Engineering},
  volume   = {28},
  number   = {6},
  pages    = {147},
  year     = {2023},
  doi      = {10.1007/s10664-023-10377-w},
  url      = {https://doi.org/10.1007/s10664-023-10377-w},
  issn     = {1573-7616},
  abstract = {When software is released publicly, it is common to include with it either the full text of the license or licenses under which it is published, or a detailed reference to them. Therefore public licenses, including FOSS (free, open source software) licenses, are usually publicly available in source code repositories}
}


@article{wei2023greener,
  title   = {Greener yet Powerful: Taming Large Code Generation Models with Quantization},
  author  = {Wei, Xiaokai and Gonugondla, Sujan and Ahmad, Wasi and Wang, Shiqi and Ray, Baishakhi and Qian, Haifeng and Li, Xiaopeng and Kumar, Varun and Wang, Zijian and Tian, Yuchen and others},
  journal = {arXiv preprint arXiv:2303.05378},
  year    = {2023}
}

@article{fan2021makes,
  title     = {What makes a popular academic AI repository?},
  author    = {Fan, Yuanrui and Xia, Xin and Lo, David and Hassan, Ahmed E and Li, Shanping},
  journal   = {Empirical Software Engineering},
  volume    = {26},
  number    = {1},
  pages     = {1--35},
  year      = {2021},
  publisher = {Springer}
}


@article{WANG2022106845,
  title    = {Personalizing label prediction for GitHub issues},
  journal  = {Information and Software Technology},
  volume   = {145},
  pages    = {106845},
  year     = {2022},
  issn     = {0950-5849},
  doi      = {https://doi.org/10.1016/j.infsof.2022.106845},
  url      = {https://www.sciencedirect.com/science/article/pii/S0950584922000192},
  author   = {Jun Wang and Xiaofang Zhang and Lin Chen and Xiaoyuan Xie},
  keywords = {Deep learning, Issue labeling, Data analysis, Language model}
}




@article{github-disc,
  author     = {Hata, Hideaki and Novielli, Nicole and Baltes, Sebastian and Kula, Raula Gaikovina and Treude, Christoph},
  title      = {GitHub Discussions: An Exploratory Study of Early Adoption},
  year       = {2022},
  issue_date = {Jan 2022},
  publisher  = {Kluwer Academic Publishers},
  address    = {USA},
  volume     = {27},
  number     = {1},
  issn       = {1382-3256},
  url        = {https://doi.org/10.1007/s10664-021-10058-6},
  doi        = {10.1007/s10664-021-10058-6},
  abstract   = {Discussions is a new feature of GitHub for asking questions or discussing topics outside of specific Issues or Pull Requests. Before being available to all projects in December 2020, it had been tested on selected open source software projects. To understand how developers use this novel feature, how they perceive it, and how it impacts the development processes, we conducted a mixed-methods study based on early adopters of GitHub discussions from January until July 2020. We found that: (1) errors, unexpected behavior, and code reviews are prevalent discussion categories; (2) there is a positive relationship between project member involvement and discussion frequency; (3) developers consider GitHub Discussions useful but face the problem of topic duplication between Discussions and Issues; (4) Discussions play a crucial role in advancing the development of projects; and (5) positive sentiment in Discussions is more frequent than in Stack Overflow posts. Our findings are a first step towards data-informed guidance for using GitHub Discussions, opening up avenues for future work on this novel communication channel.},
  journal    = {Empirical Softw. Engg.},
  month      = {jan},
  numpages   = {32},
  keywords   = {Sentiment, GitHub discussions, Empirical study, Communications, Exploratory study}
}

@article{ntoutsi2020bias,
  title     = {Bias in data-driven artificial intelligence systems—An introductory survey},
  author    = {Ntoutsi, Eirini and Fafalios, Pavlos and Gadiraju, Ujwal and Iosifidis, Vasileios and Nejdl, Wolfgang and Vidal, Maria-Esther and Ruggieri, Salvatore and Turini, Franco and Papadopoulos, Symeon and Krasanakis, Emmanouil and others},
  journal   = {Wiley Interdisciplinary Reviews: Data Mining and Knowledge Discovery},
  volume    = {10},
  number    = {3},
  pages     = {e1356},
  year      = {2020},
  publisher = {Wiley Online Library}
}

@article{kullback1951information,
  title     = {On information and sufficiency},
  author    = {Kullback, Solomon and Leibler, Richard A},
  journal   = {The annals of mathematical statistics},
  volume    = {22},
  number    = {1},
  pages     = {79--86},
  year      = {1951},
  publisher = {JSTOR}
}

@inproceedings{wolf2020ai,
  title        = {AI models and their worlds: Investigating data-driven, AI/ML ecosystems through a work practices lens},
  author       = {Wolf, Christine T},
  booktitle    = {International conference on information},
  pages        = {651--664},
  year         = {2020},
  organization = {Springer}
}

@article{jiao2019survey,
  title     = {A survey on the new generation of deep learning in image processing},
  author    = {Jiao, Licheng and Zhao, Jin},
  journal   = {IEEE Access},
  volume    = {7},
  pages     = {172231--172263},
  year      = {2019},
  publisher = {IEEE}
}


@inproceedings{10.1145/1718918.1718973,
  author    = {Breu, Silvia and Premraj, Rahul and Sillito, Jonathan and Zimmermann, Thomas},
  title     = {Information Needs in Bug Reports: Improving Cooperation between Developers and Users},
  year      = {2010},
  isbn      = {9781605587950},
  publisher = {Association for Computing Machinery},
  address   = {New York, NY, USA},
  url       = {https://doi.org/10.1145/1718918.1718973},
  doi       = {10.1145/1718918.1718973},
  abstract  = {For many software projects, bug tracking systems play a central role in supporting collaboration between the developers and the users of the software. To better understand this collaboration and how tool support can be improved, we have quantitatively and qualitatively analysed the questions asked in a sample of 600 bug reports from the MOZILLA and ECLIPSE projects. We categorised the questions and analysed response rates and times by category and project. Our results show that the role of users goes beyond simply reporting bugs: their active and ongoing participation is important for making progress on the bugs they report. Based on the results, we suggest four ways in which bug tracking systems can be improved.},
  booktitle = {Proceedings of the 2010 ACM Conference on Computer Supported Cooperative Work},
  pages     = {301–310},
  numpages  = {10},
  keywords  = {information needs, question time, response rate, bug reports, questions, response time},
  location  = {Savannah, Georgia, USA},
  series    = {CSCW '10}
}

@inproceedings{10.1145/2568225.2568233,
  author    = {Begel, Andrew and Zimmermann, Thomas},
  title     = {Analyze This! 145 Questions for Data Scientists in Software Engineering},
  year      = {2014},
  isbn      = {9781450327565},
  publisher = {Association for Computing Machinery},
  address   = {New York, NY, USA},
  url       = {https://doi.org/10.1145/2568225.2568233},
  doi       = {10.1145/2568225.2568233},
  abstract  = {In this paper, we present the results from two surveys related to data science applied to software engineering. The first survey solicited questions that software engineers would like data scientists to investigate about software, about software processes and practices, and about software engineers. Our analyses resulted in a list of 145 questions grouped into 12 categories. The second survey asked a different pool of software engineers to rate these 145 questions and identify the most important ones to work on first. Respondents favored questions that focus on how customers typically use their applications. We also saw opposition to questions that assess the performance of individual employees or compare them with one another. Our categorization and catalog of 145 questions can help researchers, practitioners, and educators to more easily focus their efforts on topics that are important to the software industry.},
  booktitle = {Proceedings of the 36th International Conference on Software Engineering},
  pages     = {12–23},
  numpages  = {12},
  keywords  = {Data Science, Software Engineering, Analytics},
  location  = {Hyderabad, India},
  series    = {ICSE 2014}
}


@article{allen1970control,
  title     = {Control flow analysis},
  author    = {Allen, Frances E},
  journal   = {ACM Sigplan Notices},
  volume    = {5},
  number    = {7},
  pages     = {1--19},
  year      = {1970},
  publisher = {ACM New York, NY, USA}
}

@article{kavi1986formal,
  title     = {A formal definition of data flow graph models},
  author    = {Kavi, Krishna M. and Buckles, Bill P. and Bhat, U. Narayan},
  journal   = {IEEE Transactions on computers},
  volume    = {35},
  number    = {11},
  pages     = {940--948},
  year      = {1986},
  publisher = {IEEE Computer Society}
}

@article{yang2020estimating,
  title     = {Estimating the deep replicability of scientific findings using human and artificial intelligence},
  author    = {Yang, Yang and Youyou, Wu and Uzzi, Brian},
  journal   = {Proceedings of the National Academy of Sciences},
  volume    = {117},
  number    = {20},
  pages     = {10762--10768},
  year      = {2020},
  publisher = {National Acad Sciences}
}

@misc{preston-werner_2009,
  title   = {GitHub issue tracker!},
  url     = {https://github.blog/2009-04-15-github-issue-tracker/},
  journal = {The GitHub Blog},
  author  = {Preston-Werner, Tom},
  year    = {2009},
  month   = {Apr}
}


@inproceedings{10.1145/3180155.3180220,
  author    = {Tian, Yuchi and Pei, Kexin and Jana, Suman and Ray, Baishakhi},
  title     = {DeepTest: Automated Testing of Deep-Neural-Network-Driven Autonomous Cars},
  year      = {2018},
  isbn      = {9781450356381},
  publisher = {Association for Computing Machinery},
  address   = {New York, NY, USA},
  url       = {https://doi.org/10.1145/3180155.3180220},
  doi       = {10.1145/3180155.3180220},
  abstract  = {Recent advances in Deep Neural Networks (DNNs) have led to the development of DNN-driven autonomous cars that, using sensors like camera, LiDAR, etc., can drive without any human intervention. Most major manufacturers including Tesla, GM, Ford, BMW, and Waymo/Google are working on building and testing different types of autonomous vehicles. The lawmakers of several US states including California, Texas, and New York have passed new legislation to fast-track the process of testing and deployment of autonomous vehicles on their roads.However, despite their spectacular progress, DNNs, just like traditional software, often demonstrate incorrect or unexpected corner-case behaviors that can lead to potentially fatal collisions. Several such real-world accidents involving autonomous cars have already happened including one which resulted in a fatality. Most existing testing techniques for DNN-driven vehicles are heavily dependent on the manual collection of test data under different driving conditions which become prohibitively expensive as the number of test conditions increases.In this paper, we design, implement, and evaluate DeepTest, a systematic testing tool for automatically detecting erroneous behaviors of DNN-driven vehicles that can potentially lead to fatal crashes. First, our tool is designed to automatically generated test cases leveraging real-world changes in driving conditions like rain, fog, lighting conditions, etc. DeepTest systematically explore different parts of the DNN logic by generating test inputs that maximize the numbers of activated neurons. DeepTest found thousands of erroneous behaviors under different realistic driving conditions (e.g., blurring, rain, fog, etc.) many of which lead to potentially fatal crashes in three top performing DNNs in the Udacity self-driving car challenge.},
  booktitle = {Proceedings of the 40th International Conference on Software Engineering},
  pages     = {303–314},
  numpages  = {12},
  keywords  = {deep learning, autonomous vehicle, testing, self-driving cars, neuron coverage, deep neural networks},
  location  = {Gothenburg, Sweden},
  series    = {ICSE '18}
}

@inproceedings{pathak2016context,
  title     = {Context encoders: Feature learning by inpainting},
  author    = {Pathak, Deepak and Krahenbuhl, Philipp and Donahue, Jeff and Darrell, Trevor and Efros, Alexei A},
  booktitle = {Proceedings of the IEEE conference on computer vision and pattern recognition},
  pages     = {2536--2544},
  year      = {2016}
}
@misc{car,
  doi       = {10.48550/ARXIV.1604.07316},
  url       = {https://arxiv.org/abs/1604.07316},
  author    = {Bojarski, Mariusz and Del Testa, Davide and Dworakowski, Daniel and Firner, Bernhard and Flepp, Beat and Goyal, Prasoon and Jackel, Lawrence D. and Monfort, Mathew and Muller, Urs and Zhang, Jiakai and Zhang, Xin and Zhao, Jake and Zieba, Karol},
  keywords  = {Computer Vision and Pattern Recognition (cs.CV), Machine Learning (cs.LG), Neural and Evolutionary Computing (cs.NE), FOS: Computer and information sciences, FOS: Computer and information sciences},
  title     = {End to End Learning for Self-Driving Cars},
  publisher = {arXiv},
  year      = {2016},
  copyright = {arXiv.org perpetual, non-exclusive license}
}


@article{crevier1997knowledge,
  title     = {Knowledge-based image understanding systems: A survey},
  author    = {Crevier, Daniel and Lepage, Richard},
  journal   = {Computer vision and image understanding},
  volume    = {67},
  number    = {2},
  pages     = {161--185},
  year      = {1997},
  publisher = {Elsevier}
}

@inproceedings{Senti4SD,
  author    = {Calefato, Fabio and Lanubile, Filippo and Maiorano, Federico and Novielli, Nicole},
  title     = {Sentiment Polarity Detection for Software Development},
  year      = {2018},
  isbn      = {9781450356381},
  publisher = {Association for Computing Machinery},
  address   = {New York, NY, USA},
  url       = {https://doi.org/10.1145/3180155.3182519},
  doi       = {10.1145/3180155.3182519},
  booktitle = {Proceedings of the 40th International Conference on Software Engineering},
  pages     = {128},
  numpages  = {1},
  keywords  = {communication channels, sentiment analysis, word embedding, social software engineering, stack overflow},
  location  = {Gothenburg, Sweden},
  series    = {ICSE '18}
}

@article{sonnenburg2007need,
  author  = {Sonnenburg, Soren and Braun, Mikio L and Ong, Cheng Soon and Bengio, Samy and Bottou, Leon and Holmes, Geoffrey and LeCunn, Yann and Muller, Klaus-Robert and Pereira, Fernando and Rasmussen, Carl Edward and others},
  title   = {The Need for Open Source Software in Machine Learning},
  journal = {Journal of Machine Learning Research},
  year    = {2007},
  volume  = {8},
  number  = {81},
  pages   = {2443-2466},
  url     = {http://jmlr.org/papers/v8/sonnenburg07a.html}
}


@article{hata2022github,
  title     = {GitHub Discussions: An exploratory study of early adoption},
  author    = {Hata, Hideaki and Novielli, Nicole and Baltes, Sebastian and Kula, Raula Gaikovina and Treude, Christoph},
  journal   = {Empirical Software Engineering},
  volume    = {27},
  number    = {1},
  pages     = {1--32},
  year      = {2022},
  publisher = {Springer}
}



@inproceedings{10.1145/3522664.3528621,
  author    = {Shome, Arumoy and Cruz, Lu\'{\i}s and van Deursen, Arie},
  title     = {Data Smells in Public Datasets},
  year      = {2022},
  isbn      = {9781450392754},
  publisher = {Association for Computing Machinery},
  address   = {New York, NY, USA},
  url       = {https://doi.org/10.1145/3522664.3528621},
  doi       = {10.1145/3522664.3528621},
  abstract  = {The adoption of Artificial Intelligence (AI) in high-stakes domains such as healthcare, wildlife preservation, autonomous driving and criminal justice system calls for a data-centric approach to AI. Data scientists spend the majority of their time studying and wrangling the data, yet tools to aid them with data analysis are lacking. This study identifies the recurrent data quality issues in public datasets. Analogous to code smells, we introduce a novel catalogue of data smells that can be used to indicate early signs of problems or technical debt in machine learning systems. To understand the prevalence of data quality issues in datasets, we analyse 25 public datasets and identify 14 data smells.},
  booktitle = {Proceedings of the 1st International Conference on AI Engineering: Software Engineering for AI},
  pages     = {205–216},
  numpages  = {12},
  location  = {Pittsburgh, Pennsylvania},
  series    = {CAIN '22}
}

@article{8812912,
  author  = {Wan, Zhiyuan and Xia, Xin and Lo, David and Murphy, Gail C.},
  journal = {IEEE Transactions on Software Engineering},
  title   = {How does Machine Learning Change Software Development Practices?},
  year    = {2021},
  volume  = {47},
  number  = {9},
  pages   = {1857-1871},
  doi     = {10.1109/TSE.2019.2937083}
}

@article{shneiderman2020bridging,
  title     = {Bridging the gap between ethics and practice: guidelines for reliable, safe, and trustworthy human-centered AI systems},
  author    = {Shneiderman, Ben},
  journal   = {ACM Transactions on Interactive Intelligent Systems (TiiS)},
  volume    = {10},
  number    = {4},
  pages     = {1--31},
  year      = {2020},
  publisher = {ACM New York, NY, USA}
}

@inproceedings{MDPFuzz,
  author    = {Pang, Qi and Yuan, Yuanyuan and Wang, Shuai},
  title     = {MDPFuzz: Testing Models Solving Markov Decision Processes},
  year      = {2022},
  isbn      = {9781450393799},
  publisher = {Association for Computing Machinery},
  address   = {New York, NY, USA},
  url       = {https://doi.org/10.1145/3533767.3534388},
  doi       = {10.1145/3533767.3534388},
  abstract  = {The Markov decision process (MDP) provides a mathematical frame- work for modeling sequential decision-making problems, many of which are crucial to security and safety, such as autonomous driving and robot control. The rapid development of artificial intelligence research has created efficient methods for solving MDPs, such as deep neural networks (DNNs), reinforcement learning (RL), and imitation learning (IL). However, these popular models solving MDPs are neither thoroughly tested nor rigorously reliable. We present MDPFuzz, the first blackbox fuzz testing framework for models solving MDPs. MDPFuzz forms testing oracles by checking whether the target model enters abnormal and dangerous states. During fuzzing, MDPFuzz decides which mutated state to retain by measuring if it can reduce cumulative rewards or form a new state sequence. We design efficient techniques to quantify the “freshness” of a state sequence using Gaussian mixture models (GMMs) and dynamic expectation-maximization (DynEM). We also prioritize states with high potential of revealing crashes by estimating the local sensitivity of target models over states. MDPFuzz is evaluated on five state-of-the-art models for solving MDPs, including supervised DNN, RL, IL, and multi-agent RL. Our evaluation includes scenarios of autonomous driving, aircraft collision avoidance, and two games that are often used to benchmark RL. During a 12-hour run, we find over 80 crash-triggering state sequences on each model. We show inspiring findings that crash-triggering states, though they look normal, induce distinct neuron activation patterns compared with normal states. We further develop an abnormal behavior detector to harden all the evaluated models and repair them with the findings of MDPFuzz to significantly enhance their robustness without sacrificing accuracy.},
  booktitle = {Proceedings of the 31st ACM SIGSOFT International Symposium on Software Testing and Analysis},
  pages     = {378–390},
  numpages  = {13},
  keywords  = {Deep learning testing, Markov decision procedure},
  location  = {Virtual, South Korea},
  series    = {ISSTA 2022}
}

@inproceedings{Reluplex,
  author    = {Katz, Guy
               and Barrett, Clark
               and Dill, David L.
               and Julian, Kyle
               and Kochenderfer, Mykel J.},
  editor    = {Majumdar, Rupak
               and Kun{\v{c}}ak, Viktor},
  title     = {Reluplex: An Efficient SMT Solver for Verifying Deep Neural Networks},
  booktitle = {Computer Aided Verification},
  year      = {2017},
  publisher = {Springer International Publishing},
  address   = {Cham},
  pages     = {97--117},
  abstract  = {Deep neural networks have emerged as a widely used and effective means for tackling complex, real-world problems. However, a major obstacle in applying them to safety-critical systems is the great difficulty in providing formal guarantees about their behavior. We present a novel, scalable, and efficient technique for verifying properties of deep neural networks (or providing counter-examples). The technique is based on the simplex method, extended to handle the non-convex Rectified Linear Unit (ReLU) activation function, which is a crucial ingredient in many modern neural networks. The verification procedure tackles neural networks as a whole, without making any simplifying assumptions. We evaluated our technique on a prototype deep neural network implementation of the next-generation airborne collision avoidance system for unmanned aircraft (ACAS Xu). Results show that our technique can successfully prove properties of networks that are an order of magnitude larger than the largest networks verified using existing methods.},
  isbn      = {978-3-319-63387-9},
  url       = {https://link.springer.com/chapter/10.1007/978-3-319-63387-9_5}
}

@inproceedings{8918993,
  author    = {Kallis, Rafael and Di Sorbo, Andrea and Canfora, Gerardo and Panichella, Sebastiano},
  booktitle = {2019 IEEE International Conference on Software Maintenance and Evolution (ICSME)},
  title     = {Ticket Tagger: Machine Learning Driven Issue Classification},
  year      = {2019},
  volume    = {},
  number    = {},
  pages     = {406-409},
  doi       = {10.1109/ICSME.2019.00070}
}
@inproceedings{6698918,
  author    = {Bissyandé, Tegawendé F. and Lo, David and Jiang, Lingxiao and Réveillère, Laurent and Klein, Jacques and Traon, Yves Le},
  booktitle = {2013 IEEE 24th International Symposium on Software Reliability Engineering (ISSRE)},
  title     = {Got issues? Who cares about it? A large scale investigation of issue trackers from GitHub},
  year      = {2013},
  volume    = {},
  number    = {},
  pages     = {188-197},
  doi       = {10.1109/ISSRE.2013.6698918}
}

@article{paleyes2021towards,
  title   = {Towards better data discovery and collection with flow-based programming},
  author  = {Paleyes, Andrei and Cabrera, Christian and Lawrence, Neil D},
  journal = {arXiv preprint arXiv:2108.04105},
  year    = {2021}
}


@inproceedings{10.1145/3522664.3528590,
  author    = {Foidl, Harald and Felderer, Michael and Ramler, Rudolf},
  title     = {Data Smells: Categories, Causes and Consequences, and Detection of Suspicious Data in AI-Based Systems},
  year      = {2022},
  isbn      = {9781450392754},
  publisher = {Association for Computing Machinery},
  address   = {New York, NY, USA},
  url       = {https://doi.org/10.1145/3522664.3528590},
  doi       = {10.1145/3522664.3528590},
  abstract  = {High data quality is fundamental for today's AI-based systems. However, although data quality has been an object of research for decades, there is a clear lack of research on potential data quality issues (e.g., ambiguous, extraneous values). These kinds of issues are latent in nature and thus often not obvious. Nevertheless, they can be associated with an increased risk of future problems in AI-based systems (e.g., technical debt, data-induced faults). As a counterpart to code smells in software engineering, we refer to such issues as Data Smells. This article conceptualizes data smells and elaborates on their causes, consequences, detection, and use in the context of AI-based systems. In addition, a catalogue of 36 data smells divided into three categories (i.e., Believability Smells, Understandability Smells, Consistency Smells) is presented. Moreover, the article outlines tool support for detecting data smells and presents the result of an initial smell detection on more than 240 real-world datasets.},
  booktitle = {Proceedings of the 1st International Conference on AI Engineering: Software Engineering for AI},
  pages     = {229–239},
  numpages  = {11},
  location  = {Pittsburgh, Pennsylvania},
  series    = {CAIN '22}
}


@inproceedings{7081875,
  author    = {Cabot, Jordi and Cánovas Izquierdo, Javier Luis and Cosentino, Valerio and Rolandi, Belén},
  booktitle = {2015 IEEE 22nd International Conference on Software Analysis, Evolution, and Reengineering (SANER)},
  title     = {Exploring the use of labels to categorize issues in Open-Source Software projects},
  year      = {2015},
  volume    = {},
  number    = {},
  pages     = {550-554},
  doi       = {10.1109/SANER.2015.7081875}
}

@article{KALLIS2021102598,
  title    = {Predicting issue types on GitHub},
  journal  = {Science of Computer Programming},
  volume   = {205},
  pages    = {102598},
  year     = {2021},
  issn     = {0167-6423},
  doi      = {https://doi.org/10.1016/j.scico.2020.102598},
  url      = {https://www.sciencedirect.com/science/article/pii/S0167642320302069},
  author   = {Rafael Kallis and Andrea {Di Sorbo} and Gerardo Canfora and Sebastiano Panichella},
  keywords = {Software maintenance and evolution, Issue reports management, Labeling unstructured data},
  abstract = {Software maintenance and evolution involves critical activities for the success of software projects. To support such activities and keep code up-to-date and error-free, software communities make use of issue trackers, i.e., tools for signaling, handling, and addressing the issues occurring in software systems. However, in popular projects, tens or hundreds of issue reports are daily submitted. In this context, identifying the type of each submitted report (e.g., bug report, feature request, etc.) would facilitate the management and the prioritization of the issues to address. To support issue handling activities, in this paper, we propose Ticket Tagger, a GitHub app analyzing the issue title and description through machine learning techniques to automatically recognize the types of reports submitted on GitHub and assign labels to each issue accordingly. We empirically evaluated the tool's prediction performance on about 30,000 GitHub issues. Our results show that the Ticket Tagger can identify the correct labels to assign to GitHub issues with reasonably high effectiveness. Considering these results and the fact that the tool is designed to be easily integrated in the GitHub issue management process, Ticket Tagger consists in a useful solution for developers.}
}

@article{10.1145/3533378,
  author     = {Paleyes, Andrei and Urma, Raoul-Gabriel and Lawrence, Neil D.},
  title      = {Challenges in Deploying Machine Learning: A Survey of Case Studies},
  year       = {2022},
  issue_date = {July 2023},
  publisher  = {Association for Computing Machinery},
  address    = {New York, NY, USA},
  volume     = {55},
  number     = {6},
  issn       = {0360-0300},
  url        = {https://doi.org/10.1145/3533378},
  doi        = {10.1145/3533378},
  abstract   = {In recent years, machine learning has transitioned from a field of academic research interest to a field capable of solving real-world business problems. However, the deployment of machine learning models in production systems can present a number of issues and concerns. This survey reviews published reports of deploying machine learning solutions in a variety of use cases, industries, and applications and extracts practical considerations corresponding to stages of the machine learning deployment workflow. By mapping found challenges to the steps of the machine learning deployment workflow, we show that practitioners face issues at each stage of the deployment process. The goal of this article is to lay out a research agenda to explore approaches addressing these challenges.},
  journal    = {ACM Comput. Surv.},
  month      = {dec},
  articleno  = {114},
  numpages   = {29},
  keywords   = {Machine learning applications, sofware deployment}
}

@inproceedings{jiang-etal-2023-low,
  title     = {{``}Low-Resource{''} Text Classification: A Parameter-Free Classification Method with Compressors},
  author    = {Jiang, Zhiying  and
               Yang, Matthew  and
               Tsirlin, Mikhail  and
               Tang, Raphael  and
               Dai, Yiqin  and
               Lin, Jimmy},
  editor    = {Rogers, Anna  and
               Boyd-Graber, Jordan  and
               Okazaki, Naoaki},
  booktitle = {Findings of the Association for Computational Linguistics: ACL 2023},
  month     = jul,
  year      = {2023},
  address   = {Toronto, Canada},
  publisher = {Association for Computational Linguistics},
  url       = {https://aclanthology.org/2023.findings-acl.426},
  doi       = {10.18653/v1/2023.findings-acl.426},
  pages     = {6810--6828},
  abstract  = {Deep neural networks (DNNs) are often used for text classification due to their high accuracy. However, DNNs can be computationally intensive, requiring millions of parameters and large amounts of labeled data, which can make them expensive to use, to optimize, and to transfer to out-of-distribution (OOD) cases in practice. In this paper, we propose a non-parametric alternative to DNNs that{'}s easy, lightweight, and universal in text classification: a combination of a simple compressor like \textit{gzip} with a $k$-nearest-neighbor classifier. Without any training parameters, our method achieves results that are competitive with non-pretrained deep learning methods on six in-distribution datasets.It even outperforms BERT on all five OOD datasets, including four low-resource languages. Our method also excels in the few-shot setting, where labeled data are too scarce to train DNNs effectively.}
}

@inproceedings{10.1145/3382494.3410681,
  author    = {Serban, Alex and van der Blom, Koen and Hoos, Holger and Visser, Joost},
  title     = {Adoption and Effects of Software Engineering Best Practices in Machine Learning},
  year      = {2020},
  isbn      = {9781450375801},
  publisher = {Association for Computing Machinery},
  address   = {New York, NY, USA},
  url       = {https://doi.org/10.1145/3382494.3410681},
  doi       = {10.1145/3382494.3410681},
  abstract  = {Background. The increasing reliance on applications with machine learning (ML) components calls for mature engineering techniques that ensure these are built in a robust and future-proof manner.Aim. We aim to empirically determine the state of the art in how teams develop, deploy and maintain software with ML components.Method. We mined both academic and grey literature and identified 29 engineering best practices for ML applications. We conducted a survey among 313 practitioners to determine the degree of adoption for these practices and to validate their perceived effects. Using the survey responses, we quantified practice adoption, differentiated along demographic characteristics, such as geography or team size. We also tested correlations and investigated linear and non-linear relationships between practices and their perceived effect using various statistical models.Results. Our findings indicate, for example, that larger teams tend to adopt more practices, and that traditional software engineering practices tend to have lower adoption than ML specific practices. Also, the statistical models can accurately predict perceived effects such as agility, software quality and traceability, from the degree of adoption for specific sets of practices. Combining practice adoption rates with practice importance, as revealed by statistical models, we identify practices that are important but have low adoption, as well as practices that are widely adopted but are less important for the effects we studied.Conclusion. Overall, our survey and the analysis of responses received provide a quantitative basis for assessment and step-wise improvement of practice adoption by ML teams.},
  booktitle = {Proceedings of the 14th ACM / IEEE International Symposium on Empirical Software Engineering and Measurement (ESEM)},
  articleno = {3},
  numpages  = {12},
  keywords  = {survey, best practices, machine learning engineering},
  location  = {Bari, Italy},
  series    = {ESEM '20}
}

@inproceedings{10.1145/3522664.3528596,
  author    = {Song, Qunying and Borg, Markus and Engstr\"{o}m, Emelie and Ard\"{o}, H\r{a}kan and Rico, Sergio},
  title     = {Exploring ML Testing in Practice: Lessons Learned from an Interactive Rapid Review with Axis Communications},
  year      = {2022},
  isbn      = {9781450392754},
  publisher = {Association for Computing Machinery},
  address   = {New York, NY, USA},
  url       = {https://doi.org/10.1145/3522664.3528596},
  doi       = {10.1145/3522664.3528596},
  abstract  = {There is a growing interest in industry and academia in machine learning (ML) testing. We believe that industry and academia need to learn together to produce rigorous and relevant knowledge. In this study, we initiate a collaboration between stakeholders from one case company, one research institute, and one university. To establish a common view of the problem domain, we applied an interactive rapid review of the state of the art. Four researchers from Lund University and RISE Research Institutes and four practitioners from Axis Communications reviewed a set of 180 primary studies on ML testing. We developed a taxonomy for the communication around ML testing challenges and results and identified a list of 12 review questions relevant for Axis Communications. The three most important questions (data testing, metrics for assessment, and test generation) were mapped to the literature, and an in-depth analysis of the 35 primary studies matching the most important question (data testing) was made. A final set of the five best matches were analysed and we reflect on the criteria for applicability and relevance for the industry. The taxonomies are helpful for communication but not final. Furthermore, there was no perfect match to the case company's investigated review question (data testing). However, we extracted relevant approaches from the five studies on a conceptual level to support later context-specific improvements. We found the interactive rapid review approach useful for triggering and aligning communication between the different stakeholders.},
  booktitle = {Proceedings of the 1st International Conference on AI Engineering: Software Engineering for AI},
  pages     = {10–21},
  numpages  = {12},
  keywords  = {AI engineering, interactive rapid review, machine learning, taxonomy, testing},
  location  = {Pittsburgh, Pennsylvania},
  series    = {CAIN '22}
}



@inproceedings{levinson2011towards,
  author    = {Levinson, Jesse and Askeland, Jake and Becker, Jan and Dolson, Jennifer and Held, David and Kammel, Soeren and Kolter, J. Zico and Langer, Dirk and Pink, Oliver and Pratt, Vaughan and Sokolsky, Michael and Stanek, Ganymed and Stavens, David and Teichman, Alex and Werling, Moritz and Thrun, Sebastian},
  booktitle = {2011 IEEE Intelligent Vehicles Symposium (IV)},
  title     = {Towards fully autonomous driving: Systems and algorithms},
  year      = {2011},
  volume    = {},
  number    = {},
  pages     = {163-168},
  doi       = {10.1109/IVS.2011.5940562},
  url       = {https://doi.org/10.1109/IVS.2011.5940562},
  abstract  = {In order to achieve autonomous operation of a vehicle in urban situations with unpredictable traffic, several realtime systems must interoperate, including environment perception, localization, planning, and control. In addition, a robust vehicle platform with appropriate sensors, computational hardware, networking, and software infrastructure is essential. We previously published an overview of Junior, Stanford's entry in the 2007 DARPA Urban Challenge. This race was a closed-course competition which, while historic and inciting much progress in the field, was not fully representative of the situations that exist in the real world. In this paper, we present a summary of our recent research towards the goal of enabling safe and robust autonomous operation in more realistic situations. First, a trio of unsupervised algorithms automatically calibrates our 64-beam rotating LIDAR with accuracy superior to tedious hand measurements. We then generate high-resolution maps of the environment which are subsequently used for online localization with centimeter accuracy. Improved perception and recognition algorithms now enable Junior to track and classify obstacles as cyclists, pedestrians, and vehicles; traffic lights are detected as well. A new planning system uses this incoming data to generate thousands of candidate trajectories per second, choosing the optimal path dynamically. The improved controller continuously selects throttle, brake, and steering actuations that maximize comfort and minimize trajectory error. All of these algorithms work in sun or rain and during the day or night. With these systems operating together, Junior has successfully logged hundreds of miles of autonomous operation in a variety of real-life conditions.}
}



@inproceedings{li2019structural,
  author    = {Li, Zenan and Ma, Xiaoxing and Xu, Chang and Cao, Chun},
  booktitle = {2019 IEEE/ACM 41st International Conference on Software Engineering: New Ideas and Emerging Results (ICSE-NIER)},
  title     = {Structural Coverage Criteria for Neural Networks Could Be Misleading},
  year      = {2019},
  volume    = {},
  number    = {},
  pages     = {89-92},
  doi       = {10.1109/ICSE-NIER.2019.00031},
  url       = {https://doi.org/10.1109/ICSE-NIER.2019.00031},
  abstract  = {There is a dramatically increasing interest in the quality assurance for DNN-based systems in the software engineering community. An emerging hot topic in this direction is structural coverage criteria for testing neural networks, which are inspired by coverage metrics used in conventional software testing. In this short paper, we argue that these criteria could be misleading because of the fundamental differences between neural networks and human written programs. Our preliminary exploration shows that (1) adversarial examples are pervasively distributed in the finely divided space defined by such coverage criteria, while available natural samples are very sparse, and as a consequence, (2) previously reported fault-detection "capabilities" conjectured from high coverage testing are more likely due to the adversary-oriented search but not the real "high" coverage.}
}



@inproceedings{Sun_ICSE,
  author    = {Sun, Zeyu and Zhang, Jie M. and Harman, Mark and Papadakis, Mike and Zhang, Lu},
  title     = {Automatic Testing and Improvement of Machine Translation},
  year      = {2020},
  isbn      = {9781450371216},
  publisher = {Association for Computing Machinery},
  address   = {New York, NY, USA},
  url       = {https://doi.org/10.1145/3377811.3380420},
  doi       = {10.1145/3377811.3380420},
  abstract  = {This paper presents TransRepair, a fully automatic approach for testing and repairing the consistency of machine translation systems. TransRepair combines mutation with metamorphic testing to detect inconsistency bugs (without access to human oracles). It then adopts probability-reference or cross-reference to post-process the translations, in a grey-box or black-box manner, to repair the inconsistencies. Our evaluation on two state-of-the-art translators, Google Translate and Transformer, indicates that TransRepair has a high precision (99%) on generating input pairs with consistent translations. With these tests, using automatic consistency metrics and manual assessment, we find that Google Translate and Transformer have approximately 36% and 40% inconsistency bugs. Black-box repair fixes 28% and 19% bugs on average for Google Translate and Transformer. Grey-box repair fixes 30% bugs on average for Transformer. Manual inspection indicates that the translations repaired by our approach improve consistency in 87% of cases (degrading it in 2%), and that our repairs have better translation acceptability in 27% of the cases (worse in 8%).},
  booktitle = {Proceedings of the ACM/IEEE 42nd International Conference on Software Engineering},
  pages     = {974–985},
  numpages  = {12},
  keywords  = {machine translation, testing and repair, translation consistency},
  location  = {Seoul, South Korea},
  series    = {ICSE '20}
}

@misc{austin2021program,
  title         = {Program Synthesis with Large Language Models},
  author        = {Jacob Austin and Augustus Odena and Maxwell Nye and Maarten Bosma and Henryk Michalewski and David Dohan and Ellen Jiang and Carrie Cai and Michael Terry and Quoc Le and Charles Sutton},
  year          = {2021},
  eprint        = {2108.07732},
  archiveprefix = {arXiv},
  primaryclass  = {cs.PL}
}

@inproceedings{wang2023-recode,
  title     = {{R}e{C}ode: Robustness Evaluation of Code Generation Models},
  author    = {Wang, Shiqi  and
               Li, Zheng  and
               Qian, Haifeng  and
               Yang, Chenghao  and
               Wang, Zijian  and
               Shang, Mingyue  and
               Kumar, Varun  and
               Tan, Samson  and
               Ray, Baishakhi  and
               Bhatia, Parminder  and
               Nallapati, Ramesh  and
               Ramanathan, Murali Krishna  and
               Roth, Dan  and
               Xiang, Bing},
  booktitle = {Proceedings of the 61st Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)},
  month     = jul,
  year      = {2023},
  address   = {Toronto, Canada},
  publisher = {Association for Computational Linguistics},
  url       = {https://aclanthology.org/2023.acl-long.773},
  doi       = {10.18653/v1/2023.acl-long.773},
  pages     = {13818--13843}
}

@misc{zhang2023rnns,
  title         = {RNNS: Representation Nearest Neighbor Search Black-Box Attack on Code Models},
  author        = {Jie Zhang and Wei Ma and Qiang Hu and Xiaofei Xie and Yves Le Traon and Yang Liu},
  year          = {2023},
  eprint        = {2305.05896},
  archiveprefix = {arXiv},
  primaryclass  = {cs.CR}
}

@article{10.1145/3591227,
  author     = {Gao, Fengjuan and Wang, Yu and Wang, Ke},
  title      = {Discrete Adversarial Attack to Models of Code},
  year       = {2023},
  issue_date = {June 2023},
  publisher  = {Association for Computing Machinery},
  address    = {New York, NY, USA},
  volume     = {7},
  number     = {PLDI},
  url        = {https://doi.org/10.1145/3591227},
  doi        = {10.1145/3591227},
  abstract   = {The pervasive brittleness of deep neural networks has attracted significant attention in recent years. A particularly interesting finding is the existence of adversarial examples, imperceptibly perturbed natural inputs that induce erroneous predictions in state-of-the-art neural models. In this paper, we study a different type of adversarial examples specific to code models, called discrete adversarial examples, which are created through program transformations that preserve the semantics of original inputs.In particular, we propose a novel, general method that is highly effective in attacking a broad range of code models. From the defense perspective, our primary contribution is a theoretical foundation for the application of adversarial training — the most successful algorithm for training robust classifiers — to defending code models against discrete adversarial attack. Motivated by the theoretical results, we present a simple realization of adversarial training that substantially improves the robustness of code models against adversarial attacks in practice. We extensively evaluate both our attack and defense methods. Results show that our discrete attack is significantly more effective than state-of-the-art whether or not defense mechanisms are in place to aid models in resisting attacks. In addition, our realization of adversarial training improves the robustness of all evaluated models by the widest margin against state-of-the-art adversarial attacks as well as our own.},
  journal    = {Proc. ACM Program. Lang.},
  month      = {jun},
  articleno  = {113},
  numpages   = {24},
  keywords   = {Adversarial Training, Discrete Adversarial Attack, Models of code}
}

@misc{wang2022robustpre,
  title         = {Robust and Accurate Authorship Attribution via Program Normalization},
  author        = {Yizhen Wang and Mohannad Alhanahnah and Ke Wang and Mihai Christodorescu and Somesh Jha},
  year          = {2022},
  eprint        = {2007.00772},
  archiveprefix = {arXiv},
  primaryclass  = {cs.LG}
}

@article{wang2022robust,
  title   = {Robust learning against relational adversaries},
  author  = {Wang, Yizhen and Alhanahnah, Mohannad and Meng, Xiaozhu and Wang, Ke and Christodorescu, Mihai and Jha, Somesh},
  journal = {Advances in Neural Information Processing Systems},
  volume  = {35},
  pages   = {16246--16260},
  year    = {2022}
}

@inproceedings{10.1145/3551349.3556941,
  author    = {Li, Zhong and Pan, Minxue and Pei, Yu and Zhang, Tian and Wang, Linzhang and Li, Xuandong},
  title     = {Robust Learning of Deep Predictive Models from Noisy and Imbalanced Software Engineering Datasets},
  year      = {2023},
  isbn      = {9781450394758},
  publisher = {Association for Computing Machinery},
  address   = {New York, NY, USA},
  url       = {https://doi.org/10.1145/3551349.3556941},
  doi       = {10.1145/3551349.3556941},
  abstract  = {With the rapid development of Deep Learning, deep predictive models have been widely applied to improve Software Engineering tasks, such as defect prediction and issue classification, and have achieved remarkable success. They are mostly trained in a supervised manner, which heavily relies on high-quality datasets. Unfortunately, due to the nature and source of software engineering data, the real-world datasets often suffer from the issues of sample mislabelling and class imbalance, thus undermining the effectiveness of deep predictive models in practice. This problem has become a major obstacle for deep learning-based Software Engineering. In this paper, we propose RobustTrainer, the first approach to learning deep predictive models on raw training datasets where the mislabelled samples and the imbalanced classes coexist. RobustTrainer consists of a two-stage training scheme, where the first learns feature representations robust to sample mislabelling and the second builds a classifier robust to class imbalance based on the learned representations in the first stage. We apply RobustTrainer to two popular Software Engineering tasks, i.e., Bug Report Classification and Software Defect Prediction. Evaluation results show that RobustTrainer effectively tackles the mislabelling and class imbalance issues and produces significantly better deep predictive models compared to the other six comparison approaches.},
  booktitle = {Proceedings of the 37th IEEE/ACM International Conference on Automated Software Engineering},
  articleno = {86},
  numpages  = {13},
  keywords  = {Mislabelling, Imbalanced Data, Predictive Models, Deep Learning},
  location  = {Rochester, MI, USA},
  series    = {ASE '22}
}


 @misc{github-copilot,
  title   = {GitHub copilot · your AI pair programmer},
  url     = {https://github.com/features/copilot},
  journal = {GitHub}
} 

@misc{torres_2022,
  title   = {GitHub copilot adds 400K subscribers in first month},
  url     = {https://www.ciodive.com/news/github-copilot-microsoft-software-developer/628587/},
  journal = {CIO Dive},
  author  = {Torres, Roberto},
  year    = {2022},
  month   = {Aug}
}



@misc{ding_2021,
  title     = {GitHub Copilot provided me with a picture of someone's ID card? PIC.TWITTER.COM/RRLE1UXF6U},
  url       = {https://twitter.com/DeltonDing/status/1423651446340259840},
  journal   = {Twitter},
  publisher = {Twitter},
  author    = {Ding, Delton},
  year      = {2021},
  month     = {Aug}
}


@misc{business_today_2023,
  title   = {Samsung employees accidentally leaked company secrets via chatgpt: Here's what happened},
  url     = {https://gizmodo.com/chatgpt-ai-samsung-employees-leak-data-1850307376},
  journal = {Business Today},
  year    = {2023},
  month   = {Apr}
} 

@misc{gain_2022,
  title   = {US programmer sues Microsoft and OpenAI for open-source piracy},
  url     = {https://www.nytimes.com/2022/11/23/technology/copilot-microsoft-ai-lawsuit.html},
  journal = {Silicon Republic},
  author  = {Gain, Vish},
  year    = {2022},
  month   = {Nov}
}

@misc{openai_help_center,
  title   = {What is chatgpt?},
  url     = {https://help.openai.com/en/articles/6783457-what-is-chatgpt},
  journal = {OpenAI Help Center}
}

@misc{codewhisperer,
  title = {Ai code generator - amazon CodeWhisperer faqs - AWS},
  url   = {https://aws.amazon.com/codewhisperer/faqs/}
}

@misc{blake_2023,
  title     = {Someone just used chatgpt to generate free Windows Keys},
  url       = {https://www.digitaltrends.com/computing/chatgpt-generates-free-windows-keys/},
  journal   = {Digital Trends},
  publisher = {Digital Trends},
  author    = {Blake, Alex},
  year      = {2023},
  month     = {Apr}
}